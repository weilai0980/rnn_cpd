{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import sys \n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "from datetime  import datetime \n",
    "\n",
    "import numpy as np  # learn \n",
    "import pandas as pd # learn\n",
    "from pandas import *\n",
    "from numpy import *\n",
    "\n",
    "from scipy import stats # look at scipy\n",
    "from scipy import linalg\n",
    "from scipy import *\n",
    "\n",
    " \n",
    "import matplotlib as mplt # learn matplolib \n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "# import seaborn as sns \n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.set(rc={\"figure.figsize\": (14, 6)})\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# import sklearn as sk\n",
    "import itertools\n",
    "\n",
    "\n",
    "# from pyspark import SparkContext, SparkConf\n",
    "# from pyspark.sql import SQLContext\n",
    "# from pyspark.sql.types import *\n",
    "\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment 0 : 290 92.2266345095 290\n",
      "segment 1 : 580 2.92067017591 870\n",
      "segment 2 : 970 98.8875861624 1840\n",
      "1840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa62bdd6c50>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcFOWdx/HPMM4gKCCIyiUMgiQqwQMVBAyjoBJMEM2K\nuJrFI16gGBMvNFE08Yr3AbqJ4rUeEA+E1VVBHTWKIOIJIpcIw6lcghwCU/vH049V1V3d09PVM9U9\n/X2/Xv2qo6urqqu7n189Z4OIiIiIiIiIiIiIiIiIiIiIiIiIiNRj44BVwOeedbcDXwKfAi8AzTzP\njQLmA3OB4+voHEVEpBYcDRyKPwAcBzSIzd8aewAcCHwClABlwALPdiIikiPSTZjfBdbFrZsCVMXm\npwPtYvMnAc8A24HFmABwZKizFBGRrMvWnfk5wCux+TZApee5SqBtlo4jIiJZko0AcC3wI/B0im2c\nLBxHRESyaJeQrz8LGAj086xbBuzrWW4XW+fTqVMnZ+HChSEPLyJScBYCnbOxozA5gAHAFZgy/62e\n9ZOAoUAp0BHYH5gR/+KFCxfiOI4eWXpcf/31kZ9DfXroeup65uoD6BQi3fZJNwfwDNAXaAksBa7H\nNPUsxVQGA0wDhgNzgAmx6Y7YOhUBiYjkmHQDwOkB68al2P7m2ENERHKU2ufXE+Xl5VGfQr2i65ld\nup65qSjCYzux8iwREUlTUVERZCntVg5ARKRAKQCIiBQoBQARkQKlACAiUqAUAERECpQCgIhIgVIA\nEBEpUAoAIiIFSgFARKRAKQCI5KE2bWDUqKjPQvKdAoBIHlqxAt57L+qzkHynACD1yuefww8/RH0W\ndSMbQ2lVVcH27eH3Uwh27ICLLor6LLJLAUDqlW7d4MYboz6LupGNAPCnP0Hz5uH3UwjWrIGHHor6\nLLJLAUDqnc2boznu1q3Vb5NN2QgAH31UODmmTG3YAEVF5lHf5F0AaNMGPvss6rMQ8Vu+HBo1Sr3N\nddeZ72+2pAoAP/sZDB+eneNMnQrLPP/q/eKLsGVLeq9t3Bg2bcrOeURl/fqoz6D25F0AWLECPvww\n6rOQfDB1qpl+9FH2971jBzzxhLtsEwnHSV6m/u675vt7003wwANm3aJF8M036R93+nQ3MU4VAObN\ng4qK6vfn3cell5pze/ll8/6s446Ddu3gsMPM8imnmCCQji1bYO1a/7qqqvRemw07dsB334Xbhz1f\n5QByRH38ICR7iopg3TqTcG3cCIcfnv1jzJ4Nw4a5yzaReP55KC1N/do//xmuucbMd+6c/Pxat06s\nz+jZ0z2u45iAkiwQVJfQ3n23CRTWffeZc/v1r+EPf0gMZB9/7M4XF6fet1f877W42OSY1qwxy+vW\npR8Ea3o3fvPNsNdeiesrK+H779PbhwKASJ6xP9pt28z0/POzu//4BNAeb9Gimu3HcZIXp6xcCS+8\nEPwaq00baJDkV7xzZ+pj//GPsHp18HNjxsD11yeu/9OfzDTZMW+6CV591cyvXGmm7dsnbjd2LLRs\naeZPPhnKylKfK5jPsqYV1pWVZvrUU/7rtu++MGhQevuwn629nvXpjwwVAKRe2L4dzjvPzC9Z4v5I\nbeL6z3+G2//OnfDtt+6yDQAbNphjvf66f311Nm505xs0MMvHHgsTJ/q3C6pYtq+dPj31MWpS1HLB\nBYnrbALuddddZlpcDJMmuXfxd94JL71kchC/+pWpiG/dOvnxbrrJnV+40EzXrUvcbtkyc329RWvV\nBbaHH4Z77/WvO/NM/+cH8Mkn7nxVVeLzlj1eq1butvHneMcdqc9JEjmZAMcZNy6jl0o9tHWr43z4\noeMsX26TCfN45RUz7dPHXdeyZeLrZ892nCVLHGf79uTHqKpynDvuMPuwvvrKLN9yi+PMnese4+67\n/ds5juOsW2emRx3lP0fHMdNmzRzn6afd9Zs3u8916eLfl/f18fuK365Dh5SXLum+vI/Zs4PXv/hi\n4vvwPioqEs9v0yZ320aNzHTLFsfZbTd3u6D3O3Cg4zRtaq4jOM6oUf5tVqww+9m503FmzHCc0lL3\nmOed5+77iy8c5403/O/JGjvWLP/tb/5979jhOL//vf+9/Pijf5tZsxznkENSX+tsArKWB8mbHEBR\nEfz4ozsvAjBhAhxxRGK23N75//vf7rrvvjNl214HHWSKKC691F33v/8L06a5y+edB5dfHnz87dvh\nv//bXf70U//za9e6xRbJmqc2aOAvUhk50p237+u779K/o3/kETOtqjJ1DG+9ld7rghx0UPB67/l+\n/nni82PGJK7bfXe3yGnIEDNt1crfDNVbJ2H3O22aKa//4AOzfMst5r099ZTJubRubYrCpkyBI490\n04nKSv/3YuRI6Ncv+D2tWGGmf/6zf/2jj5ochdczz8BJJ5nj/uY35lySFYnVF+OAVYD3o24BTAHm\nAa8De3ieGwXMB+YCxyfZZ9oRr6rKRN7vvzfTRx+tvegq+eWll8x3orLSf5f2wgvp3S1717/6qn+d\n1bOnu+7llx2nc2fHmTMn9Z3zoEGOc8UV5i7c7uvgg/3b2JxDixaOM2GC/7mRI810//0dZ9o0M79t\nW+r3dNVVjtOvn7uuTRv/+aR67zV9NGyY+vkTT/Qvb9pkpkuWmOmwYdV/PnbZ5ha8j1mzEtdNmpS4\n7txzU5/niBGOM3Om41xyibtuzBj3Lr+614PjTJ7sOIcfnq1vdPWIIAfwKDAgbt3VmADQBXgjtgxw\nIHBabDoAGFuD4wSydz62aVpNcgDvvgv/8z9hji65qrIS5swx8/E5gFNOSf3aWbMSv0fxw0g895wp\n895tN3fd66/DggXVNy2dNMl872zrlvPOS8wd2FzF2rXwxRf+5+67z0znz4ejjjLz3qaZ8ebOhfHj\n4Y033HXeHMOkSWa6ejXcc0/qc0+HrVxPdT5eX31lpvauPtV7iRdUSX7//YnrgnJY9vsBwa2zxowx\nrbC8+xsxwrTyAjc3lcoHHxRGqUQZ/hzAXGCf2Hyr2DKYu/+rPNu9CvQM2F/aEc/e+axcaaaPPZZ8\n20WL/HcRXbsm3vlI/dCrl3sXZj/3dB6Ok3jHnerRo4c7P3x4uDtn7+Pkk2u2/bffJn+uS5ea7eu6\n67L3PjJ5DB2a+vNxnJrv01vfE/YxfXrNz6GuQG7UAeyDKRYiNrXBoA1Q6dmuEmhbkx3PmOGPqLYW\n3rYWSMXW5NsWEtW1yU7mhBPg9NMze63UvcceS3/bjz6Ciy9Of3tvaxtvy5Gwarov2+ImSLLmnMnU\n5HrVhlQD0G3enF4ntnje+p6w7rgD/vM/s7e/XLVLlvZTXVQKfG706NE/zZeXl7PffuXMnZvYHMxm\nF2fONNN0slsVFdCjhxsAVq50m3EFWbsWmjUzzdtWrTJZfW/WX3JPSYk7X5MB4MJ0DHv//cxfG+/r\nr2u2/c9/nvw5W/GZriVLarZ9tj3/fPLnrrwyuBK5Lv3rX9Ee36uiooKKTCJilpWRWARkk9TWuEVA\nV+PWB4ApAuoRsL+ErM3gwSYr9eyz/iyVbf51221m+sQTybNH06e7WbIePRynb19/Fu2wwxxn6tSg\nbJXj3HyzmW/SxCyXlARvK7mhf/9oizH0SP2wv9dCedQVyI0ioEnAsNj8MGCiZ/1QoBToCOwPzEhn\nh947Oi9bBOTtPBPv1FPNUK2O59JMnw4NG/q3mzXLdFgJsnSp/zjbt0P//mZ+xgzTFK+oCP7jP/yD\nY0k0dslW/lVqxZVX1s5+a2Noj0KVbgB4Bngf+BmwFDgbuBU4DtMM9NjYMsAcYEJs+n/AcKqJWG++\naVpJxA/aNHeuSXDtGCS2RcU55ySOHfLcc4ntdcFfB2CLjryjE27c6LYycFKcZY8epnUAmOxrNssb\nJTPJbhjywTPPRH0G+Sv+pk4yl+49VLLq0P5J1t8ce1RryRL4+9/htdfcdY8+aqbdu5upbT5nB4La\nscNs88gjpkOGvXPfti0xEQ+qBN60yXQu6dUL9t4bDjzQrE8WAGyTNm+3/FTBQupGtgLAYYeZnGFd\nyvT7M3WqmyutS8XF1Q/BUFfif9OdOqXXQEQSRd5/rUMHf+IP7rJt12u/eN62x7Nnm3bgY8a4bZyD\nKsKCBtOqqnKHqF292m3zm+xHaeuqa9J2WfJHOgORJetLkmlDgXR69d55Z80DRW0lhNloEderl395\n993Tf22/fm7C36GD/7n/+i93XsVDNRN5AEiHTXi9d+BBP6B58+CqqxLXx4v/Udn9JhuVcfx4M9V/\np+aWbNQB3H8/XHut+d7YIr54kyfDGWcEP5eqZVkq9vubqqPR3nv7ly+91H3Pxwf0r+/RA/bbL7Pz\nOeQQ0yopvrOaFf8+vYlwebmZ2tE9k7niCv/ynnv6lzt1Sv7aa65xn7cthGznLVsktG4ddOzovqZf\nv9TnIxEHgKDRBoMEBYCgO3uAd96pfn8vvODPLdhK3yefhMWLk4/o6M0BvPWWAkLUesa6F550krvu\nF7+oWaJ8yimmCOjWW82ftPTpk7jNr39tpocemvjcgw+mfyxwixttABg2DJo2hQMOSNw2vrlzSQkc\nfbT5jg8cmLi99zrEO/xwGDw49XmVlZn/VA7Su7e/aaTN+XTr5hbVpmqe/ctfuq95+20ztfV47dub\n8Xl6907+eu+1b9zY3MTZvhz299q4sb9YsKjIzb2nwxuM7edU30UaAOLvCJKxRUHZ/Gu5ZB2BKiuT\nl3V6A8A//pG6LbPUvkaNzDj/3puB225zB/ZKR3yFoncohXjeegJ7p3nccWYwOq/4Aeds/xUwQebJ\nJ9272eJiM6S0LYa0GjVyE1arpMQMOnb00XDJJXDWWf7nUw1F/eGH7r94BeUS4utTGjSAvn3d5aoq\n2HVX//mBuX7V3Qj16GESfVvkY19rj9msmRkiIlXntJKS6nN8xcX+QFFU5OYCLroo+DXe/ga//a07\n7+38V92w2/ks0gCQ7hg9tsmlrezNhuXLg9enGuMk/ouuOoFoOY75kTdoYBIZSByVcfLk1PuIDwDp\n9Bz/5S/9iVF8HULjxv5lb0J+zDFmbPo+ffxFkfF3z8uWJXb88h6zQQPYf//kz4M/wfbyJva2B3H8\na4uL/aOI7rabv9jVXqcmTdzfRVWVGRenRQt3u3Hj3P8QsDkAOzqqPY/XXqv+T9dLSsyxgjiOGS20\nuNj8Yc2zz7rP9e5tAvDYscGvHTDAba7q3b+3fuLII83D6ze/SX6u+SQv6gBsoEjVDyBbUrWwsMPR\nWnX536YSzCYa9g4vPhHp0yexLN0rKME/7TQzfe654Nfs3GnuHMeNC37eG1T23ddMP/00efGKl+3R\nHHQ3H59IX3klvPeeuxwf/P7yl+Bj7BMbtGXiRPfvEu06MGX5HTq41/LII02dQ1AAKC11c0MNG/p7\n3wOcfbZb+Wv3F/+ZpfrjGKukxOS24usN7P5s4l1U5H5+NqjYADxjBuyxR+Jr7XULGtLZ5t7icwEP\nPmhyF7bFYr7KiwCQqxQAcsfvfmem3h9x06bmBx8/MqW1117BTUlt8eDgwe4/fXk1bmwSo7PPDt6v\n3WfXru4fx3frlryC1cv+fWJQcUf8ul12SWxZ42X/d9jrm29g1Cgzv3ixO73uOnebL7/0J3idOiUG\n1tJS05R63Dhz1/3NN25iWVYW3DrKlvXbItZUgXnECBOAbZBt0MCU5wf9wbsdLTVe/DkfcYRbT+LN\ntZ16qhs0vMaPN5XjQUpKTJPcfM8J5E0AOPfcqM8gkQJAtLxFKPF3cV27upXE3v+R9VYQr14dXOxg\nP9fiYpPQe82fn7oT19lnu384cvLJbguZdNnz8+YAbEBK1u8hvs5j5szEegmrfXs3J92mjZl26ODP\ntbRs6S/GsU480Q2IpaXm+rZuba55+/bunfxrrwX/yXuzZmbY686dTe4j1e/ngQdMmXxQwuzlOMkr\nj4Oa9z72mHnN11+bSt/27U0jAG+xkTVkSPJ6FftZ5PsfweRNZ3pv865coc5g0YtPwO0PMmi8fzB3\nth06pG6Blupz7dw5cd1f/2ruLM88Ey67zK2rqmnHqXXr3LJn793+/febBDFZALBBw762e3dT3JHM\nEUeY3vSnnpreednraIth3nsv9e+xadPU+2vQwFwv+x8BqdgWPzW1Zk31fTTOOSd4/WWXVb9/+/nY\n79vQoemfWy7JmwDQrFnUZ5BIOYDcY3+QQYllo0Zu4pSqE1JNP9ef/cw8OnY0OQ/bRr6mAWCPPUxi\n16VL8J1lda1gUjWj9CorS++PTpJJVexUExdfnLivJ57IbCjoeEE5mHRUVqbXjDg+B/D005kdL2p5\nk4HJxfE/8j37Vx8l+0wOPdRUZqaq8LMyzdn16mXulm2QyeQGoajI3BkH5V5SDX3hOMF9CS68sObn\n4NW7NwwaFG4fyTRunNjv4ne/CxecwmrbNnmxj7eTafxnka//CJYXOYC99vK3LDjgAFNRFTWNRhmt\n+IT6wgvh4IODt7WVmrYDYKoAkI2c3bPP+tvRh9W8eWJTxHSk08ImFQ166LJ1JuAGiVR9L/JBXiRh\npaX+AJDpv3xlaseO4MQ+n0ejrC+8d16peuXaz8r23UgVALp1S784JZnqKi9ryo5dJdEpLzfFZ7b1\nFJhcTHwnvnwSaSHGAw+kt12TJv4frLc4KL5dcLLxXDKJ1G++adplFxebv4gD0wnIytdsXyGz34NU\nAWDvvXXnK4m6dTNNiuMrufN52IhIA0CqnrTebtnxFSzeO29vM7333nN/4PF/Kbf//tXf1T30kDvf\npYvptWk70/zxj2bo6nyt7BHDBm3V30gmGjY0Q3fUF5H+DLzZWm+xzn33Qbt2Zr57d9MZw/u898fr\nvQvv1csNAAMGJHadnzrVf/w2bcxAX0GDfB17rH+5qMj06mzbtu6LoCRYJpW19vtRKLm3Sy5JPnCi\nSKQBwNtUyw5UBSar9cMPZn7mTPNjPeEE9/mgH6/NsnvHBv/uO/8Qz7vu6g5EZfczebL5NzLwJyip\nEhf7nPoBRK+mCXmDBoX1uTVvbjqkiQSJNADE/7GD1bdvYhtq7wBb3hyA/THb4h1v1+1mzUyi//LL\n7nhCw4e7z9vEIyhBTycAiIjks0gDwEknwaJFZt4mxrb33u23+4fR9SourlnPu4ED3WIeW4H8wANw\n771m3ibo3rFJlMjnPn1GIuFEGgCKihK7lNs22HvumTgeuh09sEEDdzyWmjbXs0Pkjhhh/gzE65RT\n3AG07PDCQVQElDsKpSxfpDbkRD+A554zQ6sOHJh6/I6xY02nsKOPNss2Aa5JbmD48MRBoux+iorc\nYXFzcfA5EZFsyokAYJt8vvxy9dvecEPiuqD/Ik3WzG/PPd2hg62gUSVT6dIlN3oii4iEUS9bQ7/9\ndvIK5uqkU6TwwQfu/8RKdFQEJxJONnIAo4AzgSrgc+BsYDdgPNABWAwMAdZn4Vhp8fbWTcfpp9es\ng1DTpuahBCh6qgMQyVzYHEAZcB5wGPALoBgYClwNTAG6AG/ElnNWy5bun254/zwkFSU8IpLvwgaA\n74HtQGNMbqIxsBwYBDwe2+ZxYHDI49SZIUPcpqkiIvVZ2ACwFrgTWIJJ+Ndj7vz3AVbFtlkVW84L\nDRqk/+9jKgKKlq6/SDhh6wA6AX/AFAVtAP6FqQ/wcmKPBKNHj/5pvry8nPKa/oFqhFQElBv0OUh9\nV1FRQUU2/iYtQNgAcDjwPrAmtvwCcBSwEmgVm7YGVge92BsAREQkUfzN8Q1BbeEzFLYIaC7QE2gE\nFAH9gTnAZGBYbJthwMSQxxFJoCIgkXDC5gA+BZ4AZmKagc4C/gE0ASYA5+I2A613lABFT0VAIpnL\nRj+Av8ceXmsxuYF6SwmPiOS7etkTWEREqqcAEIKKgKKl6y8SjgJAhlQElBv0OYhkTgFARKRAKQCE\noCIIEclnCgAZUtFD9BSARcJRAJC8pkAskjkFABGRAqUAEIKKIKKl6y8SjgJAhlT0kBv0OYhkTgFA\nRKRAKQCEoCIIEclnCgAZUtFD9BSARcJRAJC8pkAskjkFgBB0Byoi+UwBIEO68xSRfKcAIHlLOTCR\ncBQAJK8pJyaSOQWAEHQHKiL5TAEgQ7rzjJ4CsEg4CgCS1xSIRTKnABCC7kBFJJ8pAGRId54iku+y\nEQD2AJ4DvgTmAD2AFsAUYB7wemwbkaxSDkwknGwEgHuBV4ADgG7AXOBqTADoArwRWxbJOuXERDIX\nNgA0A44GxsWWdwAbgEHA47F1jwODQx4nJ+kOVETyWdgA0BH4FngUmAX8E9gN2AdYFdtmVWy5XtGd\np4jku12y8PrDgIuBD4F7SCzucWKPBKNHj/5pvry8nPLy8pCnI4VEOTApBBUVFVRUVNTKvsPex7YC\npmFyAgB9gFHAfsAxwEqgNfAW8PO41zpOHv+Czz8funeHCy6I+kwK1623wvr1ZipSKIpM8UNWyiDC\nFgGtBJZiKnsB+gOzgcnAsNi6YcDEkMfJOSoCEpF8F7YICOAS4CmgFFgInA0UAxOAc4HFwJAsHEfE\nJ48zkCI5IRsB4FPgiID1/bOw75ymBCh6yomJZE49gTOkhEdE8p0CgIhIgVIAkLylIjiRcBQAQlAC\nFD0VxYlkTgEgQ0p4RCTfKQCIiBQoBYAQVAQULV1/kXAUADKkIqDcoM9BJHMKACIiBUoBIAQVQURL\n118kHAWADKnoITfocxDJnAKAiEiBUgAQESlQCgAhqAw6Wrr+IuEoAGRIZc+5QZ+DSOYUAERECpQC\nQAgqgoiWrr9IOAoAGVLRQ27Q5yCSOQUAEZECpQAgIlKgFABCUBl0tHT9RcJRAMiQyp5zgz4Hkcwp\nAIiIFKhsBYBi4GNgcmy5BTAFmAe8DuyRpePkFBVBiEg+y1YAuBSYA9gk8WpMAOgCvBFbrldU9BA9\nBWCRcLIRANoBA4GHAZssDgIej80/DgzOwnFEEigQi2QuGwHgbuAKoMqzbh9gVWx+VWy53tEdqIjk\ns11Cvv7XwGpM+X95km0c3KIhn9GjR/80X15eTnl5sl3kHt15Rs9x9DlI/VdRUUFFRUWt7DtsAOiF\nKe4ZCOwKNAWexNz1twJWAq0xQSKBNwCIZEIBQOq7+JvjG264IWv7DlsEdA2wL9ARGAq8CfwOmAQM\ni20zDJgY8jgiIpJl2e4HYIt6bgWOwzQDPTa2XO+oDkBE8lnYIiCvt2MPgLVA/yzuO+eo6CF6CsAi\n4agnsOQ1BWKRzCkAhKA7UBHJZwoAGdKdp4jkOwUAyVvKgYmEowAQghKg6CknJpI5BYAMKeERkXyn\nACB5SzkwkXAUACSvKScmkjkFgBB0Byoi+UwBIEO68xSRfKcAIHlLOTCRcBQAQlACFD3lxEQypwCQ\nISU8IpLvFABERAqUAoDkLRXBiYSjABCCEqDoqShOJHMKABlSwiMi+U4BQPKWcmAi4SgAhKAEKHrK\niYlkTgEgQ0p4RCTfKQCIiBQoBYAQVAQULV1/kXAUADKkIqDcoM9BJHNhA8C+wFvAbOALYGRsfQtg\nCjAPeB3YI+RxREQky8IGgO3AZcBBQE9gBHAAcDUmAHQB3ogti4hIDgkbAFYCn8TmNwFfAm2BQcDj\nsfWPA4NDHicnqQw6Wrr+IuFksw6gDDgUmA7sA6yKrV8VW65XVPacG/Q5iGRulyztZ3fgeeBSYGPc\nc07skWD06NE/zZeXl1NeXp6l0xERqR8qKiqoqKiolX1nIwCUYBL/J4GJsXWrgFaYIqLWwOqgF3oD\nQD5SEUS0dP2lEMTfHN9www1Z23fYIqAi4BFgDnCPZ/0kYFhsfhhuYKg3VPSQG/Q5iGQubA6gN3Am\n8BnwcWzdKOBWYAJwLrAYGBLyOCIikmVhA8C/SZ6L6B9y3zlPRRAiks/UEzhDKnqIngKwSDgKAJLX\nFIhFMqcAICJSoBQAQlARhIjkMwWADKnoIXoKwCLhKABIXlMgFsmcAkAIugMVkXymAJAh3XlGTwFY\nJBwFgCzZvBk2bYr6LNJz8smwfXvUZ5EdCsQimVMACMF7B9qvH/ziF9GdS01MnAjr10d9FiISNQWA\nDMXfec6ZA4sXp37NunXQvXutnZKP40BVVfLni4vr5jwy5TiwdWvUZyFSvykA1KEFC2DWrNrZ96xZ\nMGOGmyu5++7gRH7nTjPN9aKThx+GRo3c5Z07Ydky/zaqAxAJRwGgDtnEN5smTzbT7t2hRw945RWz\n/Mknwdv/+KOZenMHV14J48dn/9zCWLTIv/zgg9CuXeJ2uR7IRHKZAkAI3jvQ77+vfvsdO7J7/O3b\nYdAgf4Xuli2J5+ZlA4A3GN1+u8kx1JVvvjHnV1RkinmCKs/jcy+XXFI35yZSSBQAMpTJnWeqMnlr\n9uz0ijbuuw86dzbzEz1/t9Mg9ol697Fhg7sclAMAaNiw+mPGe+45ePFFN+h4rVlj1r/zTuJzZWXm\ndWByKk2amPO7/HL417/M+l2y9WelIpKUAkAt+ve/4amnTLDYssV/120T4nfegccfd9d37QqffZZ6\nvxs3wmuvwZIlZtmbs7jwwsTt99jDLSqy+w4KAJs3w8qV5o7cG0B27IDWrWHSJP9rTj0VTjkFjj8+\n8ZgtW5pWUX37uu/Tm1P59lsztXf/a9bAnXfC3/5mltOppFYdgEg4CgAhLFwIu+6a/M7+8svhzDPN\n/KZNbgBYssS94+7bF846y/+6rVtNGfi55ybu88cfoWlTfwuZefPc+W+/hY8+SmznX1lppv1jf9Oz\ndKmZ7rabmX72GQwZYhL6Jk3gscfM+hdfhJISExjefdfd3513uvNffBH8/m05/qZN5n2WlsLvf2/W\n2UC1caOZXnCBmdrmqd4cQKrWQKoDEMmcAkCG5s6FJ5+Ebdvcu1mAH34widKmTdCqlbt+2zZ44QUz\nv26dmf71r+7z3rt4xzF37OPGJR7XHuvNN911o0f7tzn8cJgwwczbnMajj8Kzz7rb9Oxppps3m+mq\nVSZwWJ98Aq++Cl9/7a77+GO3svjVVxPPbeVKGDkS1q513weYgGI98oj/NRs2mOmcOWa6YwesXu0m\n7FVV/tawF61nAAAJcElEQVRAYIJb8+bJK7pFJPc5+ezIIx3HJHHBjw8+cJyzznKXP/7YnX/22cTt\nW7VynKoqM//++45zzz1m3nEc56OPHGfDBjN/wgmpj1uThz1eTR+O4zgnnuguN29u1t10k1nu2zf9\nfQ0daqbnnJPe9kuX+pfvuqvOP3qRSAFZK/xUDiBD1VWa9uwJzZq5y0OHBs9bK1fCIYeY+fiy7e7d\nTXl6UREsX57Z+QapruNaMqtW+ZfXrTPFQNdea5bffjv9fdlcSbq9qPfdN/19i0hqCgAZKi2tfpt7\n73Xnv/qq+u1tBa03AFx0kZnaCl9bpJMN++2X2etatXKLjqyww2B4i9FqIpvXQ6TQqLFdhmpzMLXn\nn4eZM838Qw/5n0snkNSFt97K7v5uvjmz1/3wQ3bPQ6SQKABkqDbvPOuyU1a+adkSvvvOXd62Lbpz\nEcl3tVkENACYC8wHrqrF40RCRQ916+CDzdSb+AP85S91fy4i9UVtBYBi4AFMEDgQOB04oJaOFYn4\nMvD6rLw8+tFDkzX53H33uj0PkfqktgLAkcACYDGwHXgWOKmWjhWJVOPpX3yxf9nbHwDg/ffN1A7b\ncOCBmZ3D8uWml29Y1VVoX3aZad/fpk3w81demfy106aZfgmpxLfzT8bb+UxEwqutANAWWOpZroyt\nqze8idZVcQVcJ8WFur328i/vuquZ3nWXv4MYJB+VM6hTWOvWwcMwWLfe6l9u1gxefz1xu5KS5Puw\nz99xh9sSybrxRjNt2dJdt3Chf5smTeCKKxJf16kTHHWUWU63NdKIEeltJyLpqa0AkFZHhdGjR//0\nqKioqKVTqR3TpsGxx5r5Y45x1x9wALRv79/2gLjCL9uHoKrK3H3b4RgGDoQ+fcx8x47+1wwb5l+2\nd+Pjx8PgwcHnOGQITJ3qLq9fD8cdZ+a9QatXL9Oz2WrZ0t/f4Oc/N7mV4mIz6mnTpma9HefHm4PY\nbz844wwzP3myee/x5zdypPlvBJsTChq/KEh8TuWll9J7nUg+q6io8KWV+aAn4B0sYBSJFcFRd6gL\n7Ywz3J6xP/zgOIsWuc917myeu/FGx9myxd97deNGM73jDnf7+fPNdtu2Oc6ZZzrOgAGJvW8XLTLz\nPXo4zoQJ7ms//9xx/vnPxF6zy5Y5zvTp/n04jpl/6CHHmTfPcRYscJy1a/3P7b6746xZY+ZXrkx8\n3/fdZ55bv95Mx471H+Oll/zHi+9xvGmT/3je16fqfWy3/+1v/etECgl50BN4JrA/UAaUAqcBk1K9\nIN81buy/a58/30ybN3eLfC680LRisRWX3kHkOnc225WWmjGGnn/ejPgJbh1BWZkpLvrgAzMSp9W1\nqzvImldpaXB/hQ8/hHPOgf33N0UxzZv7n9+6FVq0MEnvPvskvr5rVzO1PZ1tjsYO2hZ/zKIi/3uN\nH+q5Wzcz7d3bTDt2hOHDE49rtWiR/DkRSV9tBYAdwMXAa8AcYDzwZS0dKzLpjETp7dV72GGw557u\ncqr/B2jc2C3ft2XlRUVw8smpj3fIIW4RTcOGwQHg8MOTl/v37w8HHZT6GMcc439fdl82YQ86pg0C\nU6b4h9FwHJPwP/gg3HabWXfZZTBmjLvNDTf4t9dwECLZUZsdwf4v9qi3brkFTjst+fNt2rijbn79\ndWLClc4fxEDNhlkoKzP1E40amRyAHWU06I9ZgrzySs3/uczWcdhWTb16BVdOFxW5w1HH89YD2JZN\nW7aYYBEfaM8/H/beu2bnKCKJohxNPVacVZiKisyfn9gB1JLZts0k5OnkNm6+2dydH3UUfPmlSZhX\nrDCVyx9/nJ3zDrJ2rcnZZOPjXLoU2rZ1g4mI+BWZxCArabcCQERKS80/bA0YEPWZhLdliymyKuCP\nU6TOKACIiBSobAYAZbRFRAqUAoCISIFSABARKVAKACIiBUoBQESkQCkAiIgUKAUAEZECpQAgIlKg\nFABERAqUAoCISIFSABARKVAKACIiBUoBQESkQCkAiIgUKAUAEZECpQAgIlKgFABERAqUAoCISIFS\nABARKVBhAsDtwJfAp8ALQDPPc6OA+cBc4PgQxxARkVoSJgC8DhwEHAzMwyT6AAcCp8WmA4CxIY8j\naaioqIj6FOoVXc/s0vXMTWES5ilAVWx+OtAuNn8S8AywHVgMLACODHEcSYN+YNml65ldup65KVt3\n5ucAr8Tm2wCVnucqgbZZOo6IiGTJLtU8PwVoFbD+GmBybP5a4Efg6RT7cWp+aiIiUpuKQr7+LOA8\noB+wNbbu6tj01tj0VeB6TDGR1wKgU8jji4gUmoVA56hPYgAwG2gZt/5A4BOgFOiIOdmwgUZERHLI\nfOAb4OPYY6znuWswd/hzgRPq/tRERERERCSnDMDkDuYDV0V8LvliMfAZJrc1I7auBaaifh6mX8Ye\nnu3VGc9vHLAK+NyzLpPr1z22j/nAvbV4vrku6HqOxrT6s6UCv/I8p+uZ3L7AW5gi9S+AkbH19fL7\nWYwpHioDSjD1BQdEeUJ54mvMF8Lr78CVsfmrcCvebT1MCeY6L0Cd8Y4GDsWfYNXk+tl6rBm4/Vpe\nwdzMFKKg63k98MeAbXU9U2sFHBKb3x34CpMm1svv51GYlkHW1bgthyS5r4E949bNBfaJzbeKLYO5\nO/DmrF4Fetbq2eWHMvwJVk2vX2vM8CfWUOCh2jjRPFFGYgD4U8B2up41MxHoTx18P6O4K2wLLPUs\nq6NYehxgKjAT0/QWzJdjVWx+Fe6XRZ3x0lPT6xe/fhm6rvEuwYwP9ghukYWuZ/rKMDmr6dTB9zOK\nAKBOYZnpjfli/AoYgcmCezmkvra67qlVd/2keg9imn4fAqwA7oz2dPLO7sDzwKXAxrjnauX7GUUA\nWIap9LD2xR+1JNiK2PRb4EVMOd8q3J7arYHVsfn4a9wutk78anL9KmPr28Wt13V1rcZNqB7GLYvW\n9axeCSbxfxJTBAT19Pu5C6ZzWBmms5gqgavXGGgSm98NeA9T8/933LLAq0msJFJnPL8yEiuBa3r9\npgM9Yss5WclWh8rwX8/WnvnLcIeH0fVMrQh4Arg7bn29/X7+ClPTvQB3GGlJriPmA/8E00zMXrMW\nmHqBoGZi6ozn9wywHDNu1VLgbDK7fraZ3QLgvlo/69wVfz3PwSRin2HqACbillmDrmcqfTAjK3+C\n24R2APp+ioiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIjI/wPxicJYUq+KuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa63479cad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# block1: synthetic data\n",
    "\n",
    "seg_num=3\n",
    "seg_len_min= 100\n",
    "seg_len_max=1000\n",
    "\n",
    "mean_min=1\n",
    "mean_max=100\n",
    "var_min = 1\n",
    "var_max=5\n",
    "\n",
    "tcnt=0\n",
    "ts=[]\n",
    "true_cp_list=[]\n",
    "\n",
    "for i in range(seg_num):\n",
    "    seg_len = int(np.random.uniform([seg_len_min, seg_len_max, 1])[1])\n",
    "    seg_mean = np.random.uniform([mean_min, mean_max, 1])[1]\n",
    "    seg_var = np.random.uniform([var_min, var_max, 1])[1]\n",
    "    \n",
    "    print \"segment\",i,\":\",seg_len, seg_mean, tcnt+seg_len\n",
    "    \n",
    "    tmp= np.random.normal( seg_mean, seg_var, seg_len )\n",
    "#     print len(tmp)\n",
    "    \n",
    "    true_cp_list.append( tcnt )\n",
    "    tcnt= tcnt + seg_len   \n",
    "\n",
    "    \n",
    "    [ts.append(i) for i in tmp]\n",
    "    \n",
    "#     for j in range(seg_len):\n",
    "#         ts.append( np.random.normal( seg_mean, seg_var, 1 )  )\n",
    "        \n",
    "print len(ts)\n",
    "\n",
    "plt.plot(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1199, 1) (1, 1199, 1)\n"
     ]
    }
   ],
   "source": [
    "# block2: data pre-processing\n",
    "\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# parameter\n",
    "seg_num=1\n",
    "\n",
    "tmptrnx =[]\n",
    "tmptrny =[]\n",
    "\n",
    "def extract_load_data( ts_df, st_idx, ed_idx):\n",
    "    tmpdta = ts_df.iloc[st_idx: ed_idx]\n",
    "    cnt= len(tmpdta)\n",
    "    tmpx=[]\n",
    "    tmpy=[]\n",
    "    for i in range(cnt-1):\n",
    "        tmpx.append( tmpdta.iloc[i].as_matrix() )\n",
    "        tmpy.append( tmpdta.iloc[i+1].as_matrix() )\n",
    "\n",
    "    return tmpx, tmpy, tmpdta.iloc[cnt-1].as_matrix()\n",
    "\n",
    "ts_df= pd.DataFrame(ts)\n",
    "\n",
    "\n",
    "# tmpPre = 0\n",
    "# tmpCur=0\n",
    "# for i in range(seg_num):\n",
    "#     tmpCur = true_cp_list[i+1]\n",
    "    \n",
    "#     print tmpCur\n",
    "    \n",
    "#     tmpx,tmpy, tmpy1 = extract_load_data( ts_df, tmpPre,tmpCur)\n",
    "#     tmptrnx.append(tmpx)\n",
    "#     tmptrny.append(tmpy)\n",
    "\n",
    "#     tmpPre= tmpCur\n",
    "    \n",
    "tmpPre = 0\n",
    "tmpCur = 1200\n",
    "# true_cp_list[1]\n",
    "    \n",
    "tmpx,tmpy, tmpy1 = extract_load_data( ts_df, tmpPre,tmpCur)\n",
    "tmptrnx.append(tmpx)\n",
    "tmptrny.append(tmpy)\n",
    "\n",
    "\n",
    "# qualified format for rnn\n",
    "dtax = np.array( tmptrnx )\n",
    "dtay = np.array( tmptrny )\n",
    "\n",
    "print dtax.shape, dtay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1199, 1) (1, 1199, 1)\n",
      "at time step: 0 : [array([[[ 13.66684151]]], dtype=float32)] [[[ 95.30649733]]]\n",
      "at time step: 20 : [array([[[ 84.20682526]]], dtype=float32)] [[[ 97.9415651]]]\n",
      "at time step: 40 : [array([[[ 91.68638611]]], dtype=float32)] [[[ 91.3551239]]]\n",
      "at time step: 60 : [array([[[ 95.50965118]]], dtype=float32)] [[[ 88.31500364]]]\n",
      "at time step: 80 : [array([[[ 92.48911285]]], dtype=float32)] [[[ 95.06581268]]]\n",
      "at time step: 100 : [array([[[ 94.26474762]]], dtype=float32)] [[[ 90.94664025]]]\n",
      "at time step: 120 : [array([[[ 89.53691101]]], dtype=float32)] [[[ 98.65984026]]]\n",
      "at time step: 140 : [array([[[ 93.50161743]]], dtype=float32)] [[[ 89.07881086]]]\n",
      "at time step: 160 : [array([[[ 95.80799866]]], dtype=float32)] [[[ 96.53740832]]]\n",
      "at time step: 180 : [array([[[ 95.85580444]]], dtype=float32)] [[[ 97.3946391]]]\n",
      "at time step: 200 : [array([[[ 89.38064575]]], dtype=float32)] [[[ 93.28581152]]]\n",
      "at time step: 220 : [array([[[ 92.41944122]]], dtype=float32)] [[[ 95.56663612]]]\n",
      "at time step: 240 : [array([[[ 90.93598938]]], dtype=float32)] [[[ 100.63285509]]]\n",
      "at time step: 260 : [array([[[ 91.35380554]]], dtype=float32)] [[[ 94.62890672]]]\n",
      "at time step: 280 : [array([[[ 91.04334259]]], dtype=float32)] [[[ 98.56573777]]]\n",
      "at time step: 300 : [array([[[ 4.43472099]]], dtype=float32)] [[[ 3.67559903]]]\n",
      "at time step: 320 : [array([[[ 6.08601141]]], dtype=float32)] [[[ 5.3522527]]]\n",
      "at time step: 340 : [array([[[-0.70387238]]], dtype=float32)] [[[-2.80698649]]]\n",
      "at time step: 360 : [array([[[ 5.83995008]]], dtype=float32)] [[[ 1.35915541]]]\n",
      "at time step: 380 : [array([[[ 1.69609606]]], dtype=float32)] [[[ 6.6005537]]]\n",
      "at time step: 400 : [array([[[-0.33546972]]], dtype=float32)] [[[ 2.05721431]]]\n",
      "at time step: 420 : [array([[[ 3.99562359]]], dtype=float32)] [[[ 1.40463404]]]\n",
      "at time step: 440 : [array([[[-0.88160306]]], dtype=float32)] [[[ 2.1276204]]]\n",
      "at time step: 460 : [array([[[-3.36912894]]], dtype=float32)] [[[-0.02668124]]]\n",
      "at time step: 480 : [array([[[ 3.17567396]]], dtype=float32)] [[[ 7.77376073]]]\n",
      "at time step: 500 : [array([[[ 11.21109009]]], dtype=float32)] [[[ 3.8288261]]]\n",
      "at time step: 520 : [array([[[ 0.11532253]]], dtype=float32)] [[[ 0.90913646]]]\n",
      "at time step: 540 : [array([[[ 5.22633743]]], dtype=float32)] [[[ 5.01884802]]]\n",
      "at time step: 560 : [array([[[-1.80120087]]], dtype=float32)] [[[ 6.72437055]]]\n",
      "at time step: 580 : [array([[[-1.06528282]]], dtype=float32)] [[[ 4.21937226]]]\n",
      "at time step: 600 : [array([[[ 7.06993675]]], dtype=float32)] [[[ 2.69930221]]]\n",
      "at time step: 620 : [array([[[-0.96038944]]], dtype=float32)] [[[ 0.50883363]]]\n",
      "at time step: 640 : [array([[[-2.58443356]]], dtype=float32)] [[[ 6.48104104]]]\n",
      "at time step: 660 : [array([[[-2.01574206]]], dtype=float32)] [[[ 3.93181611]]]\n",
      "at time step: 680 : [array([[[ 0.62280798]]], dtype=float32)] [[[-2.81890382]]]\n",
      "at time step: 700 : [array([[[ 5.34737253]]], dtype=float32)] [[[ 3.16800378]]]\n",
      "at time step: 720 : [array([[[ 3.00764322]]], dtype=float32)] [[[ 2.39006836]]]\n",
      "at time step: 740 : [array([[[-5.52307796]]], dtype=float32)] [[[ 6.79965231]]]\n",
      "at time step: 760 : [array([[[-0.72264946]]], dtype=float32)] [[[ 0.71234117]]]\n",
      "at time step: 780 : [array([[[ 1.65579915]]], dtype=float32)] [[[ 7.87719019]]]\n",
      "at time step: 800 : [array([[[-1.57450962]]], dtype=float32)] [[[-3.03610068]]]\n",
      "at time step: 820 : [array([[[ 5.21548128]]], dtype=float32)] [[[ 4.21192507]]]\n",
      "at time step: 840 : [array([[[ 13.18247128]]], dtype=float32)] [[[ 2.73973128]]]\n",
      "at time step: 860 : [array([[[ 0.44855297]]], dtype=float32)] [[[ 5.67445737]]]\n",
      "at time step: 880 : [array([[[ 89.97970581]]], dtype=float32)] [[[ 97.44856172]]]\n",
      "at time step: 900 : [array([[[ 98.12428284]]], dtype=float32)] [[[ 101.35994077]]]\n",
      "at time step: 920 : [array([[[ 98.72955322]]], dtype=float32)] [[[ 100.48823727]]]\n",
      "at time step: 940 : [array([[[ 91.5774765]]], dtype=float32)] [[[ 96.22629984]]]\n",
      "at time step: 960 : [array([[[ 102.99571228]]], dtype=float32)] [[[ 93.25735467]]]\n",
      "at time step: 980 : [array([[[ 106.32593536]]], dtype=float32)] [[[ 101.03640739]]]\n",
      "at time step: 1000 : [array([[[ 104.56739044]]], dtype=float32)] [[[ 102.73518734]]]\n",
      "at time step: 1020 : [array([[[ 94.62983704]]], dtype=float32)] [[[ 97.00544458]]]\n",
      "at time step: 1040 : [array([[[ 94.29568481]]], dtype=float32)] [[[ 92.85616139]]]\n",
      "at time step: 1060 : [array([[[ 99.78235626]]], dtype=float32)] [[[ 98.0801994]]]\n",
      "at time step: 1080 : [array([[[ 108.02882385]]], dtype=float32)] [[[ 91.58913282]]]\n",
      "at time step: 1100 : [array([[[ 89.15146637]]], dtype=float32)] [[[ 102.47029296]]]\n",
      "at time step: 1120 : [array([[[ 99.94702148]]], dtype=float32)] [[[ 99.57408755]]]\n",
      "at time step: 1140 : [array([[[ 96.56167603]]], dtype=float32)] [[[ 104.31477827]]]\n",
      "at time step: 1160 : [array([[[ 101.31600952]]], dtype=float32)] [[[ 105.89814434]]]\n",
      "at time step: 1180 : [array([[[ 94.1245575]]], dtype=float32)] [[[ 99.90691678]]]\n",
      "at time step: 1197 : [array([[[ 99.42592621]]], dtype=float32)] []\n"
     ]
    }
   ],
   "source": [
    "# block3: real-time rnn training on keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense \n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# parameters\n",
    "timesteps =1 \n",
    "input_dim=1\n",
    "in_out_neurons = 1 \n",
    "hidden_neurons = 400\n",
    "trn_size= dtax.shape[1]-1\n",
    "trnx = dtax \n",
    "trny = dtay \n",
    "\n",
    "print trnx.shape, trny.shape\n",
    "\n",
    "rl_model = Sequential()\n",
    "rl_model.add(LSTM(hidden_neurons, return_sequences=True, stateful= True,\\\n",
    "                  batch_input_shape = (1,timesteps,input_dim ) ))\n",
    "rl_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "rl_model.add(Activation(\"linear\")) \n",
    "\n",
    "rms = RMSprop(lr=0.04, rho=0.9, epsilon=1e-06)\n",
    "rl_model.compile(loss=\"mean_squared_error\", optimizer= rms )\n",
    "#                  \"rmsprop\")\n",
    "\n",
    "for i in range(trn_size): \n",
    "    cur_trnx= trnx[:,i:i+1,:] \n",
    "    cur_trny= trny[:,i:i+1,:]\n",
    "    \n",
    "#     print 'data instance:', i, 'of size:', cur_trnx.shape, cur_trny.shape\n",
    "\n",
    "    rl_model.train_on_batch(cur_trnx,cur_trny) \n",
    "\n",
    "    if i%20 ==0:\n",
    "        vali_testx=  trnx[:, i+1:i+2,:]\n",
    "        print \"at time step:\",i,\":\", rl_model.predict_on_batch( vali_testx ),\\\n",
    "        trnx[:, i+2:i+3,:]\n",
    "\n",
    "    if i == trn_size-1:\n",
    "        vali_testx=  trnx[:, i+1:i+2,:]\n",
    "        print \"at time step:\",i,\":\", rl_model.predict_on_batch( vali_testx ),\\\n",
    "        trnx[:, i+2:i+3,:]\n",
    "    \n",
    "#     rl_model.fit(cur_trnx, cur_trny, batch_size=1, nb_epoch=10)\n",
    "#     validation_split=0.05)\n",
    "\n",
    "#     predicted = model.predict(X_test)\n",
    "#     rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "#     model.predict( X_test[0:10] )\n",
    "\n",
    "    \n",
    "#     and maybe plot it\n",
    "# pd.DataFrame(predicted).to_csv(\"predicted.csv\")\n",
    "# pd.DataFrame(y_test).to_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1199, 1) (1, 1199, 1)\n",
      "initial phase: -76.7947938353 -76.7947938353 0.0\n",
      "initial phase: -53.4075701424 -65.1011819888 136.740558016\n",
      "initial phase: -41.9843688224 -57.3955776 209.913050004\n",
      "initial phase: -31.5724386969 -50.9397928743 282.46625678\n",
      "initial phase: -27.6329274402 -46.2784197874 312.886601642\n",
      "initial phase: -16.2994517972 -41.2819251224 385.56362939\n",
      "initial phase: -13.4446427229 -37.3051704939 425.370575158\n",
      "initial phase: -13.6869056117 -34.3528873836 433.211082206\n",
      "initial phase: -9.93739862192 -31.640055299 443.952180871\n",
      "initial phase: 3.3546980001 -28.1405799691 509.773911046\n",
      "initial phase: -0.556618743818 -25.6329471304 526.313052759\n",
      "initial phase: -5.1331661923 -23.9246320522 514.555376165\n",
      "initial phase: -8.96691181512 -22.7740381879 490.860588273\n",
      "initial phase: -1.30015601468 -21.2401894612 486.384112593\n",
      "initial phase: 5.80054614165 -19.4374737543 499.455479964\n",
      "initial phase: 3.60899710138 -17.9970693259 499.36098623\n",
      "initial phase: -6.69499840672 -17.3322416247 477.058744524\n",
      "initial phase: 5.58314275902 -16.0591647145 478.107802868\n",
      "initial phase: -5.64034371084 -15.5108057143 458.356790971\n",
      "initial phase: 4.09364439822 -14.5305832087 453.694838473\n",
      "initial phase: -7.94762283565 -14.2171089052 434.055645134\n",
      "initial phase: -0.117449652469 -13.5762153028 422.951479884\n",
      "initial phase: 4.53802922159 -12.7886394539 418.208350897\n",
      "initial phase: 1.48280917357 -12.1939957611 408.915828735\n",
      "initial phase: 3.81968467368 -11.5534485437 402.406413291\n",
      "initial phase: -10.0434757051 -11.4953726653 387.01356374\n",
      "initial phase: 0.620248503523 -11.0466459554 377.914975212\n",
      "initial phase: 3.19282164216 -10.5380935412 371.400901877\n",
      "initial phase: -2.71684898682 -10.2683954531 360.63061187\n",
      "initial phase: -8.73092645516 -10.2171464865 348.685758715\n",
      "initial phase: 4.53084223037 -9.74140491498 344.227732301\n",
      "initial phase: 2.92178922245 -9.34568009819 338.325157716\n",
      "initial phase: -15.0351279902 -9.51808761006 329.024059414\n",
      "initial phase: -1.64622277051 -9.28656217361 321.115814111\n",
      "initial phase: -4.33372382052 -9.14505250638 312.621926086\n",
      "initial phase: 13.0601057441 -8.52824255497 317.25389176\n",
      "initial phase: -6.90386877973 -8.48434056105 308.748848116\n",
      "initial phase: 4.96404957546 -8.13043555746 305.258082237\n",
      "initial phase: 3.74421171795 -7.82595742219 300.953815447\n",
      "initial phase: -0.681575764054 -7.64734788074 294.674123425\n",
      "initial phase: -1.45431365798 -7.49629826555 288.399589133\n",
      "initial phase: -5.36066696988 -7.44544990136 281.63894005\n",
      "initial phase: -4.82149320608 -7.38442765264 275.245593282\n",
      "initial phase: 0.699472436325 -7.20070265061 270.4414713\n",
      "initial phase: -7.64226391577 -7.21051512317 264.43589735\n",
      "initial phase: -9.27761415374 -7.25545205862 258.778160653\n",
      "initial phase: 8.48861165513 -6.9204719796 258.433978395\n",
      "initial phase: -0.837063090654 -6.79373429442 253.804871898\n",
      "initial phase: 7.27417602636 -6.50663408379 252.58165412\n",
      "initial phase: -8.44836186583 -6.54546863943 247.603919051\n",
      "initial phase: 7.81784317422 -6.26383507446 246.714813492\n",
      "initial phase: 1.5101372995 -6.11433560573 243.110152496\n",
      "initial phase: 0.543305208991 -5.9887197413 239.343694448\n",
      "initial phase: -2.87058574109 -5.93097651907 235.088120634\n",
      "initial phase: 1.37110715933 -5.79821136128 231.765626873\n",
      "initial phase: -5.24783611276 -5.78838323185 227.632267532\n",
      "initial phase: 2.80249797799 -5.63766601764 224.910796983\n",
      "initial phase: -4.71799973857 -5.62180970248 221.047355717\n",
      "initial phase: 10.7690427224 -5.34399864443 221.777171437\n",
      "initial phase: -11.9064838121 -5.45337339723 218.786692602\n",
      "initial phase: 10.1279056053 -5.19794259391 219.114719228\n",
      "initial phase: 5.09661492309 -5.03190134363 217.262362357\n",
      "initial phase: -5.08829814615 -5.03279653097 213.813803115\n",
      "initial phase: 3.60512762009 -4.89782896611 211.620585786\n",
      "initial phase: 2.0507810704 -4.79092727324 209.09627467\n",
      "initial phase: -2.19029556534 -4.75152376252 206.029070679\n",
      "initial phase: 2.04256379261 -4.65011947065 203.63267673\n",
      "initial phase: -0.277704651114 -4.58581925272 200.915091251\n",
      "initial phase: -0.684706283273 -4.52928138359 198.220642418\n",
      "initial phase: 0.471925459244 -4.45783557155 195.741129735\n",
      "initial phase: -13.227587123 -4.58135319904 194.052174715\n",
      "initial phase: 5.82950680057 -4.43675792127 192.841459021\n",
      "initial phase: 3.03573693747 -4.33439497799 190.954223594\n",
      "initial phase: 7.54894418249 -4.17380931366 190.256267271\n",
      "initial phase: 8.12362268364 -4.0098435537 189.708990053\n",
      "initial phase: -2.09273766429 -3.98461847621 187.260541972\n",
      "initial phase: -0.332748516134 -3.93719159361 184.99953438\n",
      "initial phase: -0.782834779828 -3.89675112164 182.753673724\n",
      "initial phase: 3.45410018124 -3.80370237097 181.115665542\n",
      "initial phase: -8.65680302159 -3.8643661291 179.142446955\n",
      "initial phase: 1.25466766957 -3.80116818097 177.25033026\n",
      "initial phase: -13.1495340304 -3.91517264255 176.141499264\n",
      "initial phase: 2.57470967746 -3.8369812893 174.52065132\n",
      "initial phase: -15.2198975687 -3.97249219738 173.967170634\n",
      "initial phase: 19.8936073115 -3.6917145561 178.542729081\n",
      "initial phase: -1.42283643884 -3.66533225241 176.525813041\n",
      "initial phase: 1.55111201502 -3.6053731229 174.805959068\n",
      "initial phase: -2.63501295541 -3.59434630282 172.830106111\n",
      "initial phase: 8.07070242833 -3.46327833955 172.399930174\n",
      "initial phase: -4.48456972833 -3.47462602164 170.495835914\n",
      "initial phase: 2.16696874604 -3.41263047475 168.968165605\n",
      "initial phase: -0.0769367220327 -3.37637293396 167.251184552\n",
      "initial phase: -5.51568482273 -3.3993762876 165.501466912\n",
      "initial phase: -1.0086941005 -3.37394349837 163.800967898\n",
      "initial phase: 6.12929353502 -3.27390942434 163.017387884\n",
      "initial phase: -10.4746738498 -3.3489173871 161.853778569\n",
      "initial phase: 9.77340238164 -3.21363574 161.942090822\n",
      "initial phase: -6.35641839284 -3.24570495075 160.389378632\n",
      "initial phase: 9.19092790765 -3.12008239662 160.315824457\n",
      "initial phase: -9.81509816038 -3.18703255426 159.15641625\n",
      "at time step: 100 : 94.1512 90.9466402462 0.0 159.15641625 0.999973583168\n",
      "at time step: 101 : 90.2643 84.939201671 0.0 167.737886222 0.999999999997\n",
      "at time step: 102 : 90.276 96.9353977287 0.0 166.369677071 9.08807876444e-18\n",
      "at time step: 103 : 93.5682 91.9837045075 0.0 165.183509441 0.97760050052\n",
      "at time step: 104 : 88.4646 96.3225278324 0.0 163.623253964 3.22075631129e-23\n",
      "at time step: 105 : 99.5623 91.4496562839 0.0 162.647626746 1.0\n",
      "at time step: 106 : 95.9441 89.0501842066 0.0 161.733802919 1.0\n",
      "at time step: 107 : 86.4688 90.7965851627 0.0 160.668094519 5.68910921667e-08\n",
      "at time step: 108 : 91.9939 92.2504273674 0.0 159.356357608 0.3776857798\n",
      "at time step: 109 : 95.7643 97.4616324847 0.0 157.896561746 0.0205317630091\n",
      "at time step: 110 : 98.6982 89.6388092181 0.0 156.487096735 1.0\n",
      "at time step: 111 : 98.1592 84.8124615036 0.0 155.8102771 1.0\n",
      "at time step: 112 : 87.1215 96.6217907977 0.0 156.002003142 1.77619099968e-29\n",
      "at time step: 113 : 96.764 90.1548603966 0.0 155.427175376 1.0\n",
      "at time step: 114 : 89.0155 92.38487042 0.0 154.450590287 4.39297584233e-05\n",
      "at time step: 115 : 95.1872 87.1053605156 0.0 153.208735489 1.0\n",
      "at time step: 116 : 88.077 93.0635836999 0.0 152.447040042 5.43683493541e-09\n",
      "at time step: 117 : 93.6963 95.9227870266 0.0 151.359597164 0.00566362036972\n",
      "at time step: 118 : 96.4145 94.384835859 0.0 150.120345581 0.98896923748\n",
      "at time step: 119 : 90.1299 88.1277186732 0.0 148.893510329 0.987442143881\n",
      "at time step: 120 : 85.6567 98.6598402623 0.0 147.686148207 1.79168874181e-47\n",
      "at time step: 121 : 95.7383 95.7919566958 0.0 147.851694896 0.47634008977\n",
      "at time step: 122 : 94.4913 88.709523126 0.0 146.651273004 0.999999999884\n",
      "at time step: 123 : 90.496 92.8609776269 0.0 145.72855567 0.0050227717828\n",
      "at time step: 124 : 96.4818 92.9489819272 0.0 144.600260262 0.999931912996\n",
      "at time step: 125 : 101.815 94.4068052391 0.0 143.542867338 1.0\n",
      "at time step: 126 : 94.1606 94.6836396992 0.0 142.836572387 0.288795434353\n",
      "at time step: 127 : 92.9107 96.1129013108 0.0 141.717442151 0.000358933623139\n",
      "at time step: 128 : 97.0361 94.7697576155 0.0 140.68977581 0.991249073748\n",
      "at time step: 129 : 94.9136 91.2097464632 0.0 139.639284838 0.999941792371\n",
      "at time step: 130 : 90.4014 90.4245284597 0.0 138.670157582 0.490454605209\n",
      "at time step: 131 : 93.8611 89.5727460022 0.0 137.612416374 0.99999446697\n",
      "at time step: 132 : 89.981 90.7648165264 0.0 136.708158673 0.212528833664\n",
      "at time step: 133 : 99.0595 92.1206620912 0.0 135.685909905 0.999999999999\n",
      "at time step: 134 : 93.6639 86.9903817893 0.0 135.029993558 0.99999999999\n",
      "at time step: 135 : 86.1125 101.285900656 0.0 134.359880168 4.58822948711e-52\n",
      "at time step: 136 : 97.0564 83.4254154109 0.0 135.054805261 1.0\n",
      "at time step: 137 : 89.404 100.52414331 0.0 135.427689081 1.0235868645e-28\n",
      "at time step: 138 : 98.6813 88.2584894201 0.0 135.345731856 1.0\n",
      "at time step: 139 : 87.249 95.1154804991 0.0 135.154392808 4.35285808461e-15\n",
      "at time step: 140 : 95.5709 89.0788108591 0.0 134.633436056 0.999999999903\n",
      "at time step: 141 : 89.2135 94.954930281 0.0 133.978523066 1.09262670481e-08\n",
      "at time step: 142 : 94.6933 89.5318643884 0.0 133.267624141 0.999999713654\n",
      "at time step: 143 : 96.2806 96.944633734 0.0 132.522299268 0.261339768536\n",
      "at time step: 144 : 94.0377 97.2820709846 0.0 131.606339846 0.000962217240959\n",
      "at time step: 145 : 100.424 99.3776777896 0.0 130.77082494 0.839709046891\n",
      "at time step: 146 : 103.176 94.1047361553 0.0 129.883072863 1.0\n",
      "at time step: 147 : 91.6202 94.1330983813 0.0 129.555506195 0.00916103459132\n",
      "at time step: 148 : 92.739 92.1962970029 0.0 128.726289978 0.693627963719\n",
      "at time step: 149 : 93.727 95.3559400724 0.0 127.86460512 0.0656473020692\n",
      "at time step: 150 : 95.9019 87.3137326265 0.0 127.029759856 1.0\n",
      "at time step: 151 : 89.7592 91.6872848421 0.0 126.673842681 0.0386983351209\n",
      "at time step: 152 : 84.5836 94.9670840833 0.0 125.867973013 1.71246686719e-21\n",
      "at time step: 153 : 93.1767 96.8696904531 0.0 125.745548909 0.000407066433731\n",
      "at time step: 154 : 100.919 89.6669878955 0.0 125.021579597 1.0\n",
      "at time step: 155 : 99.2593 93.2150012784 0.0 125.027144171 0.999999971585\n",
      "at time step: 156 : 87.8653 87.6185825532 0.0 124.463609633 0.587205488566\n",
      "at time step: 157 : 85.372 101.64549875 0.0 123.672724618 1.37998087994e-47\n",
      "at time step: 158 : 99.156 97.7577459886 0.0 124.555503054 0.892782579008\n",
      "at time step: 159 : 88.3435 95.1142057878 0.0 123.794895448 1.15513095132e-09\n",
      "at time step: 160 : 94.5284 96.537408321 0.0 123.305982835 0.0388913418953\n",
      "at time step: 161 : 95.0904 96.1768828106 0.0 122.566801334 0.171564765526\n",
      "at time step: 162 : 95.5117 86.4564858096 0.0 121.81761301 1.0\n",
      "at time step: 163 : 87.8257 99.5475666977 0.0 121.570277299 2.17975574317e-24\n",
      "at time step: 164 : 99.6273 93.4939893995 0.0 121.664775327 0.999999936348\n",
      "at time step: 165 : 87.3533 98.4841041754 0.0 121.159093048 7.27085059599e-22\n",
      "at time step: 166 : 97.8302 91.1544220672 0.0 121.172454309 0.999999994135\n",
      "at time step: 167 : 94.1588 94.9099196469 0.0 120.716603733 0.261527925775\n",
      "at time step: 168 : 93.8214 92.3702825471 0.0 120.002979567 0.889975453288\n",
      "at time step: 169 : 92.673 95.9084522679 0.0 119.305308199 0.00327938832553\n",
      "at time step: 170 : 95.4025 92.1260834294 0.0 118.664800832 0.996903226556\n",
      "at time step: 171 : 87.3438 88.3538242906 0.0 118.033623535 0.20069141548\n",
      "at time step: 172 : 80.6428 98.0411000398 0.0 117.353643269 3.92843168848e-47\n",
      "at time step: 173 : 93.5431 92.6454466694 0.0 118.414928715 0.77115138664\n",
      "at time step: 174 : 91.7877 94.8013122075 0.0 117.749043092 0.00658617747378\n",
      "at time step: 175 : 96.7419 91.517655211 0.0 117.127817249 0.999990401677\n",
      "at time step: 176 : 92.2014 87.8356649022 0.0 116.616806967 0.999810106289\n",
      "at time step: 177 : 88.8287 88.2112793362 0.0 116.06590659 0.691452283881\n",
      "at time step: 178 : 89.4365 87.1034359141 0.0 115.416585469 0.969855748735\n",
      "at time step: 179 : 89.5832 99.2833232678 0.0 114.802051242 3.97714389436e-15\n",
      "at time step: 180 : 94.3502 97.3946391037 0.0 114.68426422 0.00754728803671\n",
      "at time step: 181 : 91.8301 87.2177428387 0.0 114.104462784 0.999874935988\n",
      "at time step: 182 : 86.6888 84.5863341202 0.0 113.594042807 0.951645395039\n",
      "at time step: 183 : 83.3835 95.3602738742 0.0 112.997972515 2.45030730745e-21\n",
      "at time step: 184 : 96.154 94.9281825517 0.0 113.159328775 0.83180845145\n",
      "at time step: 185 : 90.0995 95.1385467944 0.0 112.559949586 4.23691616046e-05\n",
      "at time step: 186 : 95.3797 88.6958748084 0.0 112.090616287 0.99999989407\n",
      "at time step: 187 : 86.8809 91.5790635056 0.0 111.729547928 0.000140873763001\n",
      "at time step: 188 : 88.9243 90.2281347701 0.0 111.253295202 0.157924042107\n",
      "at time step: 189 : 92.9119 94.6208642986 0.0 110.674222178 0.0954762210539\n",
      "at time step: 190 : 94.2096 89.0590315058 0.0 110.107064425 0.999955891212\n",
      "at time step: 191 : 88.506 93.9416877173 0.0 109.668832987 1.90373961124e-05\n",
      "at time step: 192 : 92.0297 85.7473437542 0.0 109.251450573 0.99999892606\n",
      "at time step: 193 : 87.9434 90.1593029012 0.0 108.889616143 0.0480097335896\n",
      "at time step: 194 : 90.3457 97.495778306 0.0 108.354564644 4.55668293294e-08\n",
      "at time step: 195 : 102.301 97.2055127833 0.0 108.059855494 0.999925636477\n",
      "at time step: 196 : 101.115 90.6386875535 0.0 107.641662878 1.0\n",
      "at time step: 197 : 89.4898 94.329334333 0.0 107.650229976 0.000173453408931\n",
      "at time step: 198 : 89.2801 94.8785912041 0.0 107.227047045 1.89482128975e-05\n",
      "at time step: 199 : 94.5309 88.0603035385 0.0 106.845524181 0.999998938038\n",
      "at time step: 200 : 86.4149 93.2858115175 0.0 106.520378429 2.66096209693e-07\n",
      "at time step: 201 : 89.5775 95.8669625129 0.0 106.225168804 2.41285116787e-06\n",
      "at time step: 202 : 93.1772 95.7851701502 0.0 105.895321934 0.0294948847669\n",
      "at time step: 203 : 92.7925 87.5675959674 0.0 105.407974481 0.999916728531\n",
      "at time step: 204 : 90.5299 97.6126570593 0.0 105.024598045 1.86794415801e-07\n",
      "at time step: 205 : 95.0819 93.4062434231 0.0 104.756448394 0.884511437175\n",
      "at time step: 206 : 90.2791 92.3893698309 0.0 104.262674041 0.0666382634858\n",
      "at time step: 207 : 89.3385 92.0392537394 0.0 103.780464805 0.0279198423685\n",
      "at time step: 208 : 92.1439 91.185437819 0.0 103.316521931 0.750323593773\n",
      "at time step: 209 : 88.0707 87.8536234483 0.0 102.826726763 0.560499915625\n",
      "at time step: 210 : 78.5258 91.0656898148 0.0 102.337319862 1.03057665065e-18\n",
      "at time step: 211 : 89.7027 95.7029424442 0.0 102.594033659 1.43232956634e-05\n",
      "at time step: 212 : 94.8211 82.6876766939 0.0 102.282638575 1.0\n",
      "at time step: 213 : 79.6538 92.9137725395 0.0 102.491159758 1.82243857283e-20\n",
      "at time step: 214 : 91.0319 88.6110129479 0.0 102.833240294 0.953342355047\n",
      "at time step: 215 : 90.007 99.4895154718 0.0 102.385899867 2.99997047761e-11\n",
      "at time step: 216 : 96.8884 91.8973300222 0.0 102.326380515 0.999704013568\n",
      "at time step: 217 : 93.8858 95.6884168164 0.0 101.971015841 0.108287025705\n",
      "at time step: 218 : 89.0903 90.4777189987 0.0 101.518622552 0.171873947782\n",
      "at time step: 219 : 91.0185 92.6386812298 0.0 101.063884746 0.135528923299\n",
      "at time step: 220 : 97.0357 95.566636117 0.0 100.616421023 0.839770484982\n",
      "at time step: 221 : 102.24 88.8732687313 0.0 100.170918759 1.0\n",
      "at time step: 222 : 91.9141 91.3626552351 0.0 100.520878634 0.644708684348\n",
      "at time step: 223 : 92.068 89.135641745 0.0 100.075078721 0.975256366747\n",
      "at time step: 224 : 85.8581 85.4327538573 0.0 99.6665360832 0.611700251706\n",
      "at time step: 225 : 86.2942 88.9894569216 0.0 99.2245449946 0.0367374365187\n",
      "at time step: 226 : 86.3853 92.3461235845 0.0 98.8175035047 4.04787637911e-05\n",
      "at time step: 227 : 90.2189 93.778670597 0.0 98.5381606573 0.00950492324041\n",
      "at time step: 228 : 91.1802 92.6730726196 0.0 98.161995784 0.163653704067\n",
      "at time step: 229 : 95.9093 89.068336972 0.0 97.7432731724 0.999996076595\n",
      "at time step: 230 : 85.2906 81.6276799486 0.0 97.5209317524 0.991463906739\n",
      "at time step: 231 : 86.4425 94.6814383463 0.0 97.1574756248 4.56559732769e-08\n",
      "at time step: 232 : 98.3297 93.6917817235 0.0 97.0302683857 0.998647423421\n",
      "at time step: 233 : 88.1668 84.9309121322 0.0 96.7070082765 0.981451747523\n",
      "at time step: 234 : 79.8821 99.5626249254 0.0 96.3386813268 7.41199534787e-37\n",
      "at time step: 235 : 95.6326 94.1098886157 0.0 97.5700967405 0.836747757862\n",
      "at time step: 236 : 91.9781 88.413284553 0.0 97.173431422 0.988916631789\n",
      "at time step: 237 : 84.8306 91.5546112499 0.0 96.8168535054 8.6307782138e-06\n",
      "at time step: 238 : 91.1259 96.2976897478 0.0 96.5994563419 0.000492300242111\n",
      "at time step: 239 : 96.0246 89.2075334676 0.0 96.3075155998 0.999992457499\n",
      "at time step: 240 : 86.6732 100.632855091 0.0 96.099531196 5.07611866828e-19\n",
      "at time step: 241 : 95.9449 90.403844823 0.0 96.5068207098 0.999772929292\n",
      "at time step: 242 : 88.1262 93.0506764108 0.0 96.2377244452 0.000949994370019\n",
      "at time step: 243 : 93.9398 95.2635921125 0.0 95.9415908841 0.202752880504\n",
      "at time step: 244 : 93.7543 90.8211508097 0.0 95.5559497266 0.966787902812\n",
      "at time step: 245 : 92.9233 90.0788269008 0.0 95.200926908 0.961896491552\n",
      "at time step: 246 : 90.8479 96.7736760543 0.0 94.8468308847 0.000116853527394\n",
      "at time step: 247 : 99.7216 88.8868073902 0.0 94.6045570039 0.99999999999\n",
      "at time step: 248 : 89.3702 99.0211067117 0.0 94.6951129572 1.23413865154e-09\n",
      "at time step: 249 : 93.3818 97.0958007886 0.0 94.6892633102 0.0110014696981\n",
      "at time step: 250 : 90.5517 97.5433156806 0.0 94.366957719 8.71271224363e-06\n",
      "at time step: 251 : 96.8687 92.336142727 0.0 94.1851912896 0.997252691511\n",
      "at time step: 252 : 96.0146 90.0653407771 0.0 93.8934144423 0.999859097516\n",
      "at time step: 253 : 97.2815 91.2829819652 0.0 93.661961411 0.99986877409\n",
      "at time step: 254 : 96.3544 89.9377040797 0.0 93.4348707411 0.999950243946\n",
      "at time step: 255 : 84.3866 89.9197331395 0.0 93.2298477074 0.000410455764945\n",
      "at time step: 256 : 94.4457 94.6505824492 0.0 92.9854250248 0.45086620336\n",
      "at time step: 257 : 95.1893 91.0071079168 0.0 92.6242420581 0.993976045332\n",
      "at time step: 258 : 96.22 96.7319410646 0.0 92.332765275 0.379709438354\n",
      "at time step: 259 : 100.106 90.6933448143 0.0 91.9775377689 0.999999989837\n",
      "at time step: 260 : 89.2018 94.6289067242 0.0 91.9632305656 0.000624026246179\n",
      "at time step: 261 : 91.9737 93.4881904467 0.0 91.7246026429 0.184645856385\n",
      "at time step: 262 : 89.1592 89.0861222215 0.0 91.383660185 0.517220300528\n",
      "at time step: 263 : 94.2143 98.3957521539 0.0 91.0362473288 0.00694471030994\n",
      "at time step: 264 : 99.5002 90.0443846013 0.0 90.7573910465 0.999999985232\n",
      "at time step: 265 : 84.9497 93.759146684 0.0 90.7512901837 1.26627153265e-07\n",
      "at time step: 266 : 89.9561 88.5432056237 0.0 90.7020447745 0.795333259882\n",
      "at time step: 267 : 89.6584 89.1758144991 0.0 90.3708785236 0.610557615694\n",
      "at time step: 268 : 85.0023 92.57290681 0.0 90.0345674855 5.72018254994e-06\n",
      "at time step: 269 : 93.0766 89.0317505872 0.0 89.9121388185 0.990318474695\n",
      "at time step: 270 : 91.626 91.6422592594 0.0 89.6402899999 0.496251911756\n",
      "at time step: 271 : 93.2672 92.2670794264 0.0 89.3097385952 0.717059549025\n",
      "at time step: 272 : 94.7021 92.5515115196 0.0 88.9850576728 0.890668126993\n",
      "at time step: 273 : 91.5599 98.662448123 0.0 88.6759983993 2.58341602993e-05\n",
      "at time step: 274 : 94.199 92.5101933719 0.0 88.5358627431 0.831464879005\n",
      "at time step: 275 : 99.374 94.3047524321 0.0 88.224916772 0.99795581772\n",
      "at time step: 276 : 90.7604 91.260719872 0.0 87.9980675853 0.388777003057\n",
      "at time step: 277 : 92.9602 88.3707542625 0.0 87.6816215778 0.995090423673\n",
      "at time step: 278 : 85.5529 94.7530805561 0.0 87.4417184245 1.23618498703e-07\n",
      "at time step: 279 : 92.6767 90.9034798965 0.0 87.4308698592 0.839563747569\n",
      "at time step: 280 : 94.0881 98.565737769 0.0 87.1308903549 0.00624809212687\n",
      "at time step: 281 : 98.0673 91.4652552408 0.0 86.8919529913 0.999879322649\n",
      "at time step: 282 : 88.3052 83.5308476868 0.0 86.7380945334 0.995949724159\n",
      "at time step: 283 : 87.0979 89.9745563581 0.0 86.5124062155 0.055860502816\n",
      "at time step: 284 : 80.2889 88.5606904236 0.0 86.2371040831 2.58073440189e-06\n",
      "at time step: 285 : 91.1831 89.2959376264 0.0 86.1738542769 0.850297375129\n",
      "at time step: 286 : 88.6412 95.2524791181 0.0 85.8857954391 0.000145621706563\n",
      "at time step: 287 : 99.9756 90.9953438373 0.0 85.7383515724 0.999999540738\n",
      "at time step: 288 : 98.565 0.045515730607 0.0 85.7202215051 1.0\n",
      "at time step: 289 : 43.2423 1.74941506592 0.0 118.893453243 1.0\n",
      "at time step: 290 : -18.2552 5.88389854211 0.0 124.515563625 1.18079215988e-56\n",
      "at time step: 291 : 10.3618 3.89423326634 0.0 126.103590613 0.999989665161\n",
      "at time step: 292 : -4.26782 4.17175782365 0.0 125.821347168 1.51271197443e-08\n",
      "at time step: 293 : 6.48731 0.32851366125 0.0 125.634675885 0.999972452584\n",
      "at time step: 294 : -2.97644 4.94172515153 0.0 125.336751125 1.17049585278e-07\n",
      "at time step: 295 : 7.76906 -2.5881552215 0.0 125.124131113 0.999999999992\n",
      "at time step: 296 : -5.52279 6.46523814219 0.0 125.0633129 3.28938991528e-15\n",
      "at time step: 297 : 7.8533 2.30750235119 0.0 125.125697139 0.999840669404\n",
      "at time step: 298 : -1.56377 1.01810265153 0.0 124.810297164 0.0473699002041\n",
      "at time step: 299 : 5.04318 5.5354125555 0.0 124.415436642 0.375423261779\n",
      "at time step: 300 : 6.0358 3.67559902591 0.0 124.001597801 0.935418252959\n",
      "at time step: 301 : 3.71876 0.758502784434 0.0 123.608080416 0.971086684616\n",
      "at time step: 302 : 0.950365 3.83952270664 0.0 123.227764293 0.0324799676186\n",
      "at time step: 303 : 8.41148 1.66771273972 0.0 122.84862546 0.999991227487\n",
      "at time step: 304 : 1.74549 5.16650383479 0.0 122.593716474 0.0149104665238\n",
      "at time step: 305 : 4.78312 4.16796540559 0.0 122.230506098 0.651518584866\n",
      "at time step: 306 : 3.50253 2.75097793998 0.0 121.832417996 0.682327563518\n",
      "at time step: 307 : 2.85694 -0.130359896359 0.0 121.437407583 0.969865620875\n",
      "at time step: 308 : -3.03108 -0.446508041974 0.0 121.072016064 0.0525681266528\n",
      "at time step: 309 : -4.24123 7.98491428452 0.0 120.701839182 1.07522101562e-14\n",
      "at time step: 310 : 11.2386 5.64657384698 0.0 120.793181444 0.999759074155\n",
      "at time step: 311 : 4.36743 4.96366591262 0.0 120.506553476 0.355263931464\n",
      "at time step: 312 : 1.07576 11.0527789365 0.0 120.121772567 2.99635595821e-10\n",
      "at time step: 313 : 13.6518 3.08250010133 0.0 120.055006522 0.99999999997\n",
      "at time step: 314 : 0.148438 -0.537820266994 0.0 120.028310775 0.664323482778\n",
      "at time step: 315 : -1.63502 5.66403633147 0.0 119.649888266 3.4217644155e-06\n",
      "at time step: 316 : 7.49087 4.56466477325 0.0 119.439316169 0.963991974761\n",
      "at time step: 317 : 0.720565 2.90447654426 0.0 119.089994264 0.0903544074856\n",
      "at time step: 318 : 1.40562 2.3668387372 0.0 118.73053353 0.278487086219\n",
      "at time step: 319 : 1.50731 5.13946747087 0.0 118.36127182 0.0134676457436\n",
      "at time step: 320 : 6.9726 5.35225269718 0.0 118.032499869 0.837464081097\n",
      "at time step: 321 : 4.9654 0.0543790697082 0.0 117.67307955 0.998527542232\n",
      "at time step: 322 : -4.352 -0.273700015407 0.0 117.382328971 0.00690124097\n",
      "at time step: 323 : 6.50372 3.83615654111 0.0 117.070482444 0.94585939237\n",
      "at time step: 324 : 4.04272 5.1503494921 0.0 116.731207513 0.253077650799\n",
      "at time step: 325 : 2.11117 2.19459237284 0.0 116.375865416 0.480092390006\n",
      "at time step: 326 : 3.144 1.21888887906 0.0 116.018917096 0.874607712371\n",
      "at time step: 327 : 6.13764 5.9423373052 0.0 115.675418039 0.546237399932\n",
      "at time step: 328 : 8.82365 1.44142610523 0.0 115.322899573 0.999993992536\n",
      "at time step: 329 : -1.89638 4.33440693555 0.0 115.137515921 0.000113909777934\n",
      "at time step: 330 : 9.85056 2.68740352515 0.0 114.906404491 0.999988152256\n",
      "at time step: 331 : -1.39562 4.85084396574 0.0 114.714160051 0.00011785784372\n",
      "at time step: 332 : 7.21571 1.32487277058 0.0 114.486273609 0.999729179146\n",
      "at time step: 333 : -5.08036 4.20362492688 0.0 114.246720958 2.6950837118e-08\n",
      "at time step: 334 : 5.68727 0.383554839843 0.0 114.162265067 0.99903487097\n",
      "at time step: 335 : -2.26084 -1.00712007982 0.0 113.905970077 0.232371902338\n",
      "at time step: 336 : 4.78737 1.82221198003 0.0 113.571878221 0.9576378637\n",
      "at time step: 337 : -2.61859 2.28845096213 0.0 113.260895734 0.00222229724369\n",
      "at time step: 338 : 8.65925 3.7792764149 0.0 112.996910462 0.997610604764\n",
      "at time step: 339 : 2.71006 1.69984329528 0.0 112.7338373 0.71990513837\n",
      "at time step: 340 : -0.396952 -2.80698649415 0.0 112.405466537 0.917084819466\n",
      "at time step: 341 : -8.97431 2.52387511237 0.0 112.092823635 2.16442614065e-11\n",
      "at time step: 342 : 1.61555 6.9396893427 0.0 112.150560169 0.001148558915\n",
      "at time step: 343 : 5.69242 6.54505817923 0.0 111.907119574 0.313122361358\n",
      "at time step: 344 : 7.01045 5.11477939603 0.0 111.584155621 0.859852323656\n",
      "at time step: 345 : 1.73936 4.11323678556 0.0 111.271115381 0.0888046143221\n",
      "at time step: 346 : 1.74401 6.20754974014 0.0 110.965792509 0.0057396451196\n",
      "at time step: 347 : 5.42775 -0.512529286111 0.0 110.703303325 0.999603507077\n",
      "at time step: 348 : -5.02641 1.42646000149 0.0 110.486463221 0.000138478888522\n",
      "at time step: 349 : 6.68027 2.03942245725 0.0 110.289142808 0.995457775615\n",
      "at time step: 350 : 1.41751 6.69039707979 0.0 110.035731591 0.00155564166585\n",
      "at time step: 351 : 15.115 7.10678532931 0.0 109.801400925 0.999996250941\n",
      "at time step: 352 : 6.15196 3.13562737422 0.0 109.671362986 0.953876395192\n",
      "at time step: 353 : 10.3715 4.84235507551 0.0 109.386896473 0.998957569009\n",
      "at time step: 354 : 0.56056 2.16783799687 0.0 109.164081586 0.186050954869\n",
      "at time step: 355 : 6.55904 3.57655822193 0.0 108.864076916 0.950692484086\n",
      "at time step: 356 : 1.53231 1.107644642 0.0 108.583215752 0.592715100064\n",
      "at time step: 357 : 7.58935 3.01558212729 0.0 108.279634827 0.994114151054\n",
      "at time step: 358 : -1.95376 -2.42484641669 0.0 108.035449922 0.602101103462\n",
      "at time step: 359 : 3.19817 3.35714007886 0.0 107.735294748 0.465300880207\n",
      "at time step: 360 : 2.25807 1.35915540503 0.0 107.436101765 0.68831108872\n",
      "at time step: 361 : 3.40033 0.668659989118 0.0 107.140727187 0.931646487427\n",
      "at time step: 362 : -7.17529 2.49311771741 0.0 106.865320844 7.47623620115e-08\n",
      "at time step: 363 : 10.8067 5.57908180843 0.0 106.827789105 0.997715339691\n",
      "at time step: 364 : 3.33429 4.1574271511 0.0 106.609884978 0.32798931759\n",
      "at time step: 365 : 6.76273 -1.22184207265 0.0 106.319860024 0.999991813552\n",
      "at time step: 366 : -6.1856 1.68954801296 0.0 106.203087491 1.10690965961e-05\n",
      "at time step: 367 : 11.0883 5.16239316001 0.0 106.082706187 0.999278677896\n",
      "at time step: 368 : 1.80333 10.1522387742 0.0 105.890062346 3.75835226824e-06\n",
      "at time step: 369 : 16.172 -0.859112854894 0.0 105.791744402 1.0\n",
      "at time step: 370 : -2.91603 1.77060560068 0.0 106.288159721 0.00600408629263\n",
      "at time step: 371 : 2.49847 1.653285671 0.0 106.062825935 0.674331636282\n",
      "at time step: 372 : 5.87327 3.65600768027 0.0 105.779785077 0.881466755341\n",
      "at time step: 373 : 8.62483 4.85946892679 0.0 105.509343239 0.977390607953\n",
      "at time step: 374 : 1.79398 1.71109483235 0.0 105.265075427 0.517537020389\n",
      "at time step: 375 : -3.92265 3.6880032963 0.0 104.98448792 2.82605679234e-05\n",
      "at time step: 376 : 7.94703 4.54291513488 0.0 104.858912292 0.963886363869\n",
      "at time step: 377 : 3.01442 3.10935450273 0.0 104.611836439 0.480058014846\n",
      "at time step: 378 : 2.38335 2.44644177827 0.0 104.335190644 0.486778419243\n",
      "at time step: 379 : 6.64967 2.02455517381 0.0 104.059910442 0.992314304771\n",
      "at time step: 380 : 0.77975 6.60055370378 0.0 103.842214351 0.00117181129026\n",
      "at time step: 381 : 7.97297 -0.138015020017 0.0 103.658505449 0.999988352422\n",
      "at time step: 382 : -1.0449 -4.11029998085 0.0 103.559150164 0.944762645706\n",
      "at time step: 383 : -6.71843 4.80221955151 0.0 103.313680784 1.09185241047e-09\n",
      "at time step: 384 : 4.05791 5.03705232891 0.0 103.389437536 0.305704534976\n",
      "at time step: 385 : 5.74383 4.82140451802 0.0 103.124275012 0.683460888251\n",
      "at time step: 386 : -0.43692 4.03283514652 0.0 102.859318741 0.0105178973122\n",
      "at time step: 387 : 3.564 4.88028334579 0.0 102.645029253 0.248918863427\n",
      "at time step: 388 : 2.98036 1.07650855847 0.0 102.385067223 0.835960370298\n",
      "at time step: 389 : -5.03021 3.31045291182 0.0 102.131171883 9.61241453441e-06\n",
      "at time step: 390 : 11.0922 5.8686021267 0.0 102.047239627 0.996230113342\n",
      "at time step: 391 : 6.41613 3.04522474913 0.0 101.856312232 0.957328249703\n",
      "at time step: 392 : 12.0457 1.213078784 0.0 101.625566013 0.999999982618\n",
      "at time step: 393 : -3.07783 6.09348741755 0.0 101.664878886 1.54556426243e-06\n",
      "at time step: 394 : 8.5997 6.51060214184 0.0 101.620547121 0.855646753953\n",
      "at time step: 395 : 9.74072 0.806736748335 0.0 101.374841295 0.999996994065\n",
      "at time step: 396 : 1.55018 6.93613836505 0.0 101.319918962 0.00322139094739\n",
      "at time step: 397 : 4.47621 2.08313605034 0.0 101.138098223 0.886450385833\n",
      "at time step: 398 : -2.0226 5.29798893502 0.0 100.898518796 0.000113936296493\n"
     ]
    }
   ],
   "source": [
    "#  block4: change point detection based on real-time learning of rnn\n",
    "\n",
    "significance_level = 0.05\n",
    "\n",
    "cur_seg_stPos=0\n",
    "cur_seg_cnt=0\n",
    "ini_run_len=100\n",
    "\n",
    "\n",
    "#  residual statistics\n",
    "resi_mean=0.0\n",
    "resi_sqr = 0.0\n",
    "resi_var=0.0\n",
    "\n",
    "# parameter about the hazard function\n",
    "hconst = 0.3\n",
    "hrange= seg_len_max\n",
    "hpiece_num=50\n",
    "hpiece =[]\n",
    "hpiece_event=[]\n",
    "hpiece_psum=[]\n",
    "\n",
    "\n",
    "# detected change-points\n",
    "detect_cp_list=[]\n",
    "\n",
    "\n",
    "# data instances for training RNN\n",
    "xtrain= dtax\n",
    "ytrain= dtay\n",
    "total_len=len(xtrain) \n",
    "print xtrain.shape, ytrain.shape\n",
    "\n",
    "\n",
    "# initialize the network structure\n",
    "in_dim = 1\n",
    "hidden_neurons = 800\n",
    "timesteps =1\n",
    "input_dim=1\n",
    "\n",
    "cp_model = Sequential()\n",
    "cp_model.add(LSTM(hidden_neurons, return_sequences=True, stateful= True,\\\n",
    "               batch_input_shape = (1,timesteps,input_dim )   ))\n",
    "cp_model.add(Dropout(0.25))\n",
    "cp_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "cp_model.add(Activation(\"linear\"))\n",
    "rms = RMSprop(lr=0.04, rho=0.9, epsilon=1e-06)\n",
    "cp_model.compile(loss=\"mean_squared_error\", optimizer=rms )\n",
    "\n",
    "\n",
    "# initialize the model\n",
    "cur_trnx= xtrain[:,0:1,:]\n",
    "cur_trny= ytrain[:,0:1,:]\n",
    "cp_model.train_on_batch(cur_trnx,cur_trny) \n",
    "\n",
    "\n",
    "\n",
    "# ---------------hazard function component------------\n",
    "def hazard_bsearch( arr, t):\n",
    "    \n",
    "    tmplen=len(arr)\n",
    "    l= 0\n",
    "    r= tmplen\n",
    "    \n",
    "    while( l< r-1):\n",
    "        mid= int(l+ (r-l)/2.0)\n",
    "        tmpval= arr[mid][0]\n",
    "        \n",
    "        if tmpval> t:\n",
    "            r= mid\n",
    "        else:\n",
    "            l=mid\n",
    "    \n",
    "    if t<= arr[l][0]:\n",
    "        return l\n",
    "    elif t>= arr[r][0]:\n",
    "        return r+1\n",
    "    else:\n",
    "        return r\n",
    "    \n",
    "def hazard_constant():\n",
    "    return hconst\n",
    "    \n",
    "def hazard_piece_ini():\n",
    "    tmpinter = hrange*1.0 / hpiece_num\n",
    "    tmph = 1.0 / hpiece_num\n",
    "    curh=0.0\n",
    "    \n",
    "    for i in range(hpiece_num):\n",
    "        curh= curh+ tmph\n",
    "        hpiece.append(  [tmpinter*(i+1), curh ]  )\n",
    "        \n",
    "        hpiece_event.append(  [tmpinter*(i+1), 0 ]  )\n",
    "        hpiece_psum.append(  0  )\n",
    "            \n",
    "def hazard_piece_qry( cond_t ):\n",
    "    tmpidx = hazard_bsearch( hpiece, cond_t)\n",
    "    return hpiece[tmpidx][1]\n",
    "    \n",
    "def hazard_update_event( t):\n",
    "    tmpidx = hazard_bsearch( hpiece_event, t)\n",
    "    hpiece_event[tmpidx][1] = hpiece_event[tmpidx][1]+1\n",
    "\n",
    "def hazard_update_piece():\n",
    "    \n",
    "    tmp_psum=[]\n",
    "    tmp=0.0\n",
    "    tmpsum=0.0\n",
    "    for i in range(hpiece_num):\n",
    "        tmp = tmp+ hpiece_event[i][1]\n",
    "        tmp_psum.append(tmp)\n",
    "    \n",
    "    tmpsum= tmp\n",
    "    \n",
    "    for i in range(hpiece_num):\n",
    "        if (tmpsum- tmp_psum[i]+hpiece_event[i][1])!=0 and hpiece_event[i][1]!=0:\n",
    "            hpiece[i][1] =  hpiece_event[i][1]*1.0/(tmpsum-tmp_psum[i]+hpiece_event[i][1])\n",
    "    \n",
    "def hazard_adjust_piece():\n",
    "    return 1\n",
    "    \n",
    "    \n",
    "\n",
    "#-------------------run-lenght  joint distribution ---------------------\n",
    "\n",
    "rlen_dist=[]\n",
    "\n",
    "def rlen_dist_ini():\n",
    "    for i in range(seg_len_max):\n",
    "        rlen_dist.append(0)\n",
    "    rlen_dist[0]=1\n",
    "\n",
    "def rlen_update( cur_rlen, pred_prob):\n",
    "    \n",
    "    rlen_dist[ cur_rlen ] = rlen_dist[ cur_rlen-1 ]*pred_prob* ( 1.0- hazard_piece_qry( cur_rlen-1 )) \n",
    "    \n",
    "    rlen_dist[ 0 ] = rlen_dist[ cur_rlen-1 ]*pred_prob* ( hazard_piece_qry( cur_rlen-1 )) \n",
    "\n",
    "    \n",
    "def rlen_evidence():\n",
    "    tmpval=0.0\n",
    "    for i in range(seg_len_max):\n",
    "        tmpval =  tmpval + rlen_dist[i]\n",
    "    return tmpval\n",
    "    \n",
    "def rlen_conditional(cur_rlen):\n",
    "    \n",
    "    return rlen_dist[cur_rlen]/rlen_evidence()\n",
    "\n",
    "def rlen_renormal():\n",
    "    return 1\n",
    "   \n",
    "# normalize the run-lenght distribution    \n",
    "    \n",
    "# --------------------------------------------------------------------\n",
    "    \n",
    "hazard_piece_ini()\n",
    "# print hpiece\n",
    "\n",
    "    \n",
    "# the main process\n",
    "for i in range(1,400):\n",
    "    \n",
    "    \n",
    "#   current data instance for training the model\n",
    "    cur_trnx= xtrain[:,i:i+1,:]\n",
    "    cur_trny= ytrain[:,i:i+1,:]\n",
    "    \n",
    "#       use so-far training model to predict first \n",
    "    vali_testx=  xtrain[:, i:i+1,:]\n",
    "    curPred= cp_model.predict_on_batch( vali_testx )\n",
    "    \n",
    "#       residual of the current data instance w.r.t. the predicted value\n",
    "    tmpresi =  curPred[0][0][0][0] - ytrain[0, i, 0]\n",
    "    \n",
    "    \n",
    "    if i - cur_seg_stPos <=  ini_run_len:\n",
    "        \n",
    "        resi_mean= ( resi_mean * cur_seg_cnt*1.0 + tmpresi)/(cur_seg_cnt+1)\n",
    "        cur_seg_cnt = cur_seg_cnt+1\n",
    "        resi_sqr = resi_sqr + tmpresi*tmpresi\n",
    "        resi_var= resi_sqr/cur_seg_cnt - resi_mean* resi_mean \n",
    "        \n",
    "#         if i - cur_seg_stPos>= ini_run_len-10:\n",
    "#             resi_mean= ( resi_mean * cur_seg_cnt*1.0 + tmpresi)/(cur_seg_cnt+1)\n",
    "#             cur_seg_cnt = cur_seg_cnt+1\n",
    "#             resi_sqr = resi_sqr + tmpresi*tmpresi\n",
    "#             resi_var= resi_sqr/cur_seg_cnt - resi_mean* resi_mean         \n",
    "        \n",
    "        \n",
    "#       update the model for the current segment\n",
    "        cp_model.train_on_batch(cur_trnx, cur_trny)\n",
    "    \n",
    "        print \"initial phase:\", tmpresi, resi_mean,resi_var\n",
    "#         curPred[0][0][0][0],ytrain[0, i, 0]\n",
    "\n",
    "        continue\n",
    "        \n",
    "#       z-value\n",
    "    resi_mean=0.0\n",
    "    tmp_zval = (tmpresi -  resi_mean)*1.0 / 1.0*sqrt(resi_var/cur_seg_cnt)\n",
    "    tmp_pro =  st.norm.cdf( tmp_zval)\n",
    "        \n",
    "    print \"at time step:\",cur_seg_cnt,\":\", curPred[0][0][0][0], ytrain[0, i, 0], resi_mean,resi_var,tmp_pro\n",
    "#     curPred, ytrain[:, i:i+1,:], tmp_zval   \n",
    "    \n",
    "    \n",
    "#---------------test component------------------------\n",
    "\n",
    "\n",
    "    resi_mean= ( resi_mean * cur_seg_cnt*1.0 + tmpresi)/(cur_seg_cnt+1)\n",
    "    cur_seg_cnt = cur_seg_cnt+1\n",
    "    resi_sqr = resi_sqr + tmpresi*tmpresi\n",
    "    resi_var= resi_sqr/cur_seg_cnt - resi_mean* resi_mean             \n",
    "        \n",
    "    cp_model.train_on_batch(cur_trnx, cur_trny) \n",
    "    \n",
    "    \n",
    "#------------------------------------------------------    \n",
    "        \n",
    "#     if tmp_pro <= significance_level or tmp_pro >= 1.0-significance_level:\n",
    "# #       initialize a new segment \n",
    "#         cur_seg_stPos =i\n",
    "#         cur_seg_cnt = 1\n",
    "            \n",
    "#         resi_mean= x[i]\n",
    "#         resi_sqr = x[i]*x[i]*1.0\n",
    "#         resi_var =  0.0\n",
    "            \n",
    "#         detect_cp_list.append(i)\n",
    "            \n",
    "#         cp_model.reset_states()\n",
    "#         cp_model.clear_previous(reset_weights=True)\n",
    "        \n",
    "# #       initialize a model for the new segment\n",
    "#         cp_model.train_on_batch(cur_trnx,cur_trny) \n",
    "    \n",
    "# #       update the hazard component\n",
    "#         hazard_update_event(  i - cur_seg_stPos )\n",
    "            \n",
    "#     else:\n",
    "        \n",
    "# #      stay in the current segment and update the residual statistics \n",
    "#         resi_mean= ( resi_mean * cur_seg_cnt*1.0 + tmpresi)/cur_seg_cnt\n",
    "#         cur_seg_cnt = cur_seg_cnt+1\n",
    "#         resi_sqr = resi_sqr + tmpresi*tmpresi\n",
    "#         resi_var= resi_sqr/cur_seg_cnt - resi_mean* resi_mean             \n",
    "        \n",
    "# #       update the model for the current segment\n",
    "#         cp_model.train_on_batch(cur_trnx, cur_trny) \n",
    "    \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 799, 1) (1, 799, 1)\n",
      "number of hidden neurons: 3500\n",
      "     data instance: 0 of size: (1, 1, 1) (1, 1, 1)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s - loss: 466818.3750\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s - loss: 461521.3750\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s - loss: 458589.4375\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s - loss: 456356.2500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s - loss: 454472.1562\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s - loss: 452797.9062\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s - loss: 451244.1250\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s - loss: 449809.9375\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s - loss: 448446.7812\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s - loss: 447134.6562\n",
      "     data instance: 1 of size: (1, 1, 1) (1, 1, 1)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s - loss: 446011.2812\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s - loss: 444787.3125\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s - loss: 443588.1250\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s - loss: 442411.7188\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s - loss: 441254.9062\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s - loss: 440114.6562\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s - loss: 438988.6562\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s - loss: 437875.3438\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s - loss: 436773.1250\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s - loss: 435680.8125\n",
      "number of hidden neurons: 3700\n",
      "     data instance: 0 of size: (1, 1, 1) (1, 1, 1)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s - loss: 464189.0625\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s - loss: 458329.0938\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s - loss: 454939.0625\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s - loss: 452274.0625\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s - loss: 450126.1562\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s - loss: 448202.7812\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s - loss: 446461.1562\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s - loss: 444830.0625\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s - loss: 443269.6250\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s - loss: 441763.5625\n",
      "     data instance: 1 of size: (1, 1, 1) (1, 1, 1)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s - loss: 440280.3750\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s - loss: 438878.3438\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s - loss: 437526.0625\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s - loss: 436199.0625\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s - loss: 434893.5625\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s - loss: 433606.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s - loss: 432335.7812\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s - loss: 431079.4375\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s - loss: 429835.8125\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s - loss: 428603.5625\n",
      "number of hidden neurons: 3900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2fdb5ad65157>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mrl_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTimeDistributedDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mrl_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mrl_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean_squared_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rmsprop\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Keras-0.3.2-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, class_mode, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         self._train = K.function(train_ins, [train_loss],\n\u001b[1;32m--> 551\u001b[1;33m                                  updates=updates, **kwargs)\n\u001b[0m\u001b[0;32m    552\u001b[0m         self._train_with_acc = K.function(train_ins,\n\u001b[0;32m    553\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Keras-0.3.2-py2.7.egg/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Invalid argument '%s' passed to K.function\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Keras-0.3.2-py2.7.egg/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         self.function = theano.function(inputs, outputs, updates=updates,\n\u001b[1;32m--> 446\u001b[1;33m                                         allow_input_downcast=True, **kwargs)\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1777\u001b[0m             defaults)\n\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1454\u001b[0m                         optimizer, inputs, outputs)\n\u001b[0;32m   1455\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m                     \u001b[0moptimizer_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph, start_from)\u001b[0m\n\u001b[0;32m   1853\u001b[0m         \u001b[0mnb_nodes_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1855\u001b[1;33m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_toposort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_from\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m         \u001b[0mio_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/graph.pyc\u001b[0m in \u001b[0;36mio_toposort\u001b[1;34m(inputs, outputs, orderings, clients)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     topo = general_toposort(outputs, deps=compute_deps,\n\u001b[0;32m   1024\u001b[0m                             \u001b[0mcompute_deps_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_deps_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m                             deps_cache=deps_cache, clients=clients)\n\u001b[0m\u001b[0;32m   1026\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopo\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mApply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/graph.pyc\u001b[0m in \u001b[0;36mgeneral_toposort\u001b[1;34m(r_out, deps, debug_print, compute_deps_cache, deps_cache, clients)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m     reachable, _clients = stack_search(deque(r_out), compute_deps_cache,\n\u001b[1;32m--> 932\u001b[1;33m                                        'dfs', True)\n\u001b[0m\u001b[0;32m    933\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclients\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_clients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/graph.pyc\u001b[0m in \u001b[0;36mstack_search\u001b[1;34m(start, expand, mode, build_inv)\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbuild_inv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexpand_l\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m                         \u001b[0mexpand_inv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m                 \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpand_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# block3: parameter selection for real-time rnn training on keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense \n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "# parameters\n",
    "timesteps =1 \n",
    "input_dim=1\n",
    "in_out_neurons = 1 \n",
    "hidden_neurons = 10000\n",
    "trn_size= 2 \n",
    "# dtax.shape[1]-10\n",
    "trnx = dtax \n",
    "trny = dtay \n",
    "\n",
    "print trnx.shape, trny.shape\n",
    "\n",
    "\n",
    "for num in range(3500,4000,200):\n",
    "    \n",
    "    print 'number of hidden neurons:', num\n",
    "\n",
    "    \n",
    "    rl_model = Sequential()\n",
    "    rl_model.add(LSTM( num, return_sequences=True, stateful= True,\\\n",
    "                  batch_input_shape = (1,timesteps,input_dim ) ))\n",
    "    rl_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "    rl_model.add(Activation(\"linear\")) \n",
    "    rl_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "    \n",
    "    for i in range(trn_size):\n",
    "        cur_trnx= trnx[:,i:i+1,:] \n",
    "        cur_trny= trny[:,i:i+1,:]\n",
    "    \n",
    "        print '     data instance:', i, 'of size:', cur_trnx.shape, cur_trny.shape\n",
    "\n",
    "        rl_model.train_on_batch(cur_trnx,cur_trny) \n",
    "\n",
    "#     if i%50 ==0:\n",
    "#         vali_testx=  trnx[:, i+1:i+2,:]\n",
    "#         print \"at time step:\",i,\":\", rl_model.predict_on_batch( vali_testx )\n",
    "\n",
    "#     if i == trn_size-1:\n",
    "#         vali_testx=  trnx[:, i+1:i+2,:]\n",
    "#         print \"at time step:\",i,\":\", rl_model.predict_on_batch( vali_testx )\n",
    "    \n",
    "        rl_model.fit(cur_trnx, cur_trny, batch_size=1, nb_epoch=10)\n",
    "#     validation_split=0.05)\n",
    "\n",
    "#     predicted = model.predict(X_test)\n",
    "#     rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "#     model.predict( X_test[0:10] )\n",
    "\n",
    "    \n",
    "#     and maybe plot it\n",
    "# pd.DataFrame(predicted).to_csv(\"predicted.csv\")\n",
    "# pd.DataFrame(y_test).to_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200.0, 12], [400.0, 0], [600.0, 5], [800.0, 0], [1000.0, 0], [1200.0, 0], [1400.0, 0], [1600.0, 0], [1800.0, 0], [2000.0, 0], [2200.0, 0], [2400.0, 0], [2600.0, 0], [2800.0, 0], [3000.0, 0], [3200.0, 0], [3400.0, 0], [3600.0, 0], [3800.0, 0], [4000.0, 0], [4200.0, 14], [4400.0, 0], [4600.0, 0], [4800.0, 0], [5000.0, 0], [5200.0, 0], [5400.0, 0], [5600.0, 0], [5800.0, 0], [6000.0, 0], [6200.0, 0], [6400.0, 0], [6600.0, 0], [6800.0, 0], [7000.0, 0], [7200.0, 0], [7400.0, 0], [7600.0, 0], [7800.0, 0], [8000.0, 0], [8200.0, 0], [8400.0, 0], [8600.0, 0], [8800.0, 0], [9000.0, 0], [9200.0, 0], [9400.0, 0], [9600.0, 0], [9800.0, 0], [10000.0, 5]]\n",
      "36.0\n",
      "[[200.0, 0.3333333333333333], [400.0, 0.0], [600.0, 0.20833333333333334], [800.0, 0.0], [1000.0, 0.0], [1200.0, 0.0], [1400.0, 0.0], [1600.0, 0.0], [1800.0, 0.0], [2000.0, 0.0], [2200.0, 0.0], [2400.0, 0.0], [2600.0, 0.0], [2800.0, 0.0], [3000.0, 0.0], [3200.0, 0.0], [3400.0, 0.0], [3600.0, 0.0], [3800.0, 0.0], [4000.0, 0.0], [4200.0, 0.7368421052631579], [4400.0, 0.0], [4600.0, 0.0], [4800.0, 0.0], [5000.0, 0.0], [5200.0, 0.0], [5400.0, 0.0], [5600.0, 0.0], [5800.0, 0.0], [6000.0, 0.0], [6200.0, 0.0], [6400.0, 0.0], [6600.0, 0.0], [6800.0, 0.0], [7000.0, 0.0], [7200.0, 0.0], [7400.0, 0.0], [7600.0, 0.0], [7800.0, 0.0], [8000.0, 0.0], [8200.0, 0.0], [8400.0, 0.0], [8600.0, 0.0], [8800.0, 0.0], [9000.0, 0.0], [9200.0, 0.0], [9400.0, 0.0], [9600.0, 0.0], [9800.0, 0.0], [10000.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "#  hazard comopnent test\n",
    "\n",
    "# parameter about the hazard function\n",
    "# hconst = 0.3\n",
    "# hpiece_num=50\n",
    "\n",
    "# hrange= seg_len_max\n",
    "# hpiece =[]\n",
    "# hpiece_event=[]\n",
    "# hpiece_psum=[]\n",
    "\n",
    "\n",
    "def hazard_bsearch( arr, t):\n",
    "    \n",
    "    tmplen=len(arr)\n",
    "    l= 0\n",
    "    r= tmplen\n",
    "    \n",
    "    while( l< r-1):\n",
    "        mid= int(l+ (r-l)/2.0)\n",
    "        tmpval= arr[mid][0]\n",
    "        \n",
    "        if tmpval> t:\n",
    "            r= mid\n",
    "        else:\n",
    "            l=mid\n",
    "    \n",
    "    if t<= arr[l][0]:\n",
    "        return l\n",
    "    elif t>= arr[r][0]:\n",
    "        return r+1\n",
    "    else:\n",
    "        return r\n",
    "    \n",
    "def hazard_constant():\n",
    "    return hconst\n",
    "    \n",
    "def hazard_piece_ini():\n",
    "    tmpinter = hrange*1.0 / hpiece_num\n",
    "    tmph = 1.0 / hpiece_num\n",
    "    curh=0.0\n",
    "    \n",
    "    for i in range(hpiece_num):\n",
    "        curh= curh+ tmph\n",
    "        hpiece.append(  [tmpinter*(i+1), curh ]  )\n",
    "        \n",
    "        hpiece_event.append(  [tmpinter*(i+1), 0 ]  )\n",
    "        hpiece_psum.append(  0  )\n",
    "            \n",
    "def hazard_piece_qry( cond_t ):\n",
    "    tmpidx = hazard_bsearch( hpiece, cond_t)\n",
    "    return hpiece[tmpidx][1]\n",
    "    \n",
    "def hazard_update_event( t):\n",
    "    tmpidx = hazard_bsearch( hpiece_event, t)\n",
    "    hpiece_event[tmpidx][1] = hpiece_event[tmpidx][1]+1\n",
    "\n",
    "def hazard_update_piece():\n",
    "\n",
    "#   mechanism for keepting default values\n",
    "    tmp_psum=[]\n",
    "    tmp=0.0\n",
    "    tmpsum=0.0\n",
    "    for i in range(hpiece_num):\n",
    "        tmp = tmp+ hpiece_event[i][1]\n",
    "        tmp_psum.append(tmp)\n",
    "    \n",
    "    tmpsum= tmp\n",
    "    \n",
    "    for i in range(hpiece_num):\n",
    "        hpiece[i][1] =  hpiece_event[i][1]*1.0/(tmpsum- tmp_psum[i]+hpiece_event[i][1])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# ...................test.........................\n",
    "\n",
    "# print hazard_constant()\n",
    "# hazard_piece_ini()\n",
    "# print hpiece\n",
    "# hazard_piece_qry(201)\n",
    "\n",
    "# hazard_update_event(4130)    \n",
    "print hpiece_event\n",
    "    \n",
    "hazard_update_piece()\n",
    "\n",
    "print hpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  keras: batch rnn training\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import *\n",
    "\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 2000\n",
    "\n",
    "trnx= dtax[:, :2400,:]\n",
    "trny= dtay[:, :2400,:]\n",
    "\n",
    "batch_model = Sequential()\n",
    "batch_model.add(LSTM(hidden_neurons,input_shape=trnx.shape[1:],return_sequences=True  ))\n",
    "\n",
    "# batch_model.add(GRU(hidden_neurons,input_shape=trnx.shape[1:],return_sequences=True  ))\n",
    "\n",
    "batch_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "# model.add(Dense( output_dim= 1 , input_dim = hidden_neurons))\n",
    "batch_model.add(Activation(\"linear\"))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = RMSprop(lr=0.1, rho=0.9, epsilon=1e-06)\n",
    "batch_model.compile(loss=\"mean_squared_error\", optimizer=rmsprop)\n",
    "\n",
    "\n",
    "batch_model.fit(trnx, trny, batch_size=1, nb_epoch=20)\n",
    "#                 , validation_split=0.05)\n",
    "\n",
    "# predicted = model.predict(X_test)\n",
    "# rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "\n",
    "# model.predict( X_test[0:10] )\n",
    "\n",
    "# and maybe plot it\n",
    "# pd.DataFrame(predicted).to_csv(\"predicted.csv\")\n",
    "# pd.DataFrame(y_test).to_csv(\"test_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 1) (1, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "#  keras: online mini-batch rnn training\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 400\n",
    "\n",
    "\n",
    "cur_trnx= trnx[:,:100,:]\n",
    "cur_trny= trnx[:,:100,:]\n",
    "\n",
    "print cur_trnx.shape, cur_trny.shape\n",
    "\n",
    "ol_model = Sequential()\n",
    "# model.add(LSTM(hidden_neurons,input_shape=trnx.shape[1:],return_sequences=True  ))\n",
    "\n",
    "ol_model.add(LSTM(hidden_neurons, return_sequences=True, stateful= True,\\\n",
    "               batch_input_shape = (1,100,1 )   ))\n",
    "\n",
    "ol_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "# model.add(Dense( output_dim= 1 , input_dim = hidden_neurons))\n",
    "ol_model.add(Activation(\"linear\"))\n",
    "ol_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "dtax = np.array( tmptrnx )\n",
    "dtay = np.array( tmptrny )\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    ol_model.train_on_batch(cur_trnx,cur_trny) \n",
    "\n",
    "# model.fit(cur_trnx, cur_trny, batch_size=1, nb_epoch=10) \n",
    "#     validation_split=0.05)\n",
    "\n",
    "\n",
    "# predicted = model.predict(X_test)\n",
    "# rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "\n",
    "# model.predict( X_test[0:10] )\n",
    "\n",
    "# and maybe plot it\n",
    "# pd.DataFrame(predicted).to_csv(\"predicted.csv\")\n",
    "# pd.DataFrame(y_test).to_csv(\"test_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:35: FutureWarning: slice indexers when using iloc should be integers and not floating point\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:36: FutureWarning: slice indexers when using iloc should be integers and not floating point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1601, 10, 2) (1601, 2)\n",
      "Epoch 1/5\n",
      "1601/1601 [==============================] - 3s - loss: 1.8959     \n",
      "Epoch 2/5\n",
      "1601/1601 [==============================] - 3s - loss: 0.0813     \n",
      "Epoch 3/5\n",
      "1601/1601 [==============================] - 3s - loss: 0.0402     \n",
      "Epoch 4/5\n",
      "1601/1601 [==============================] - 3s - loss: 0.0374     \n",
      "Epoch 5/5\n",
      "1601/1601 [==============================] - 3s - loss: 0.0345     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.58813047,  1.00146997],\n",
       "       [ 3.00854683,  1.5639205 ],\n",
       "       [ 2.48745203,  2.13518548],\n",
       "       [ 1.99927723,  2.64451599],\n",
       "       [ 1.54009545,  3.11776543],\n",
       "       [ 1.08250773,  3.59334445],\n",
       "       [ 0.71006352,  4.01679468],\n",
       "       [ 0.54891282,  4.19645119],\n",
       "       [ 0.68129766,  4.03115988],\n",
       "       [ 1.20303631,  3.5933826 ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  keras\n",
    "\n",
    "# http://danielhnyk.cz/predicting-sequences-vectors-keras-using-rnn-lstm/\n",
    "\n",
    "import pandas as pd\n",
    "from random import random\n",
    "\n",
    "flow = (list(range(1,10,1)) + list(range(10,1,-1)))*100\n",
    "pdata = pd.DataFrame({\"a\":flow, \"b\":flow})\n",
    "pdata.b = pdata.b.shift(9)\n",
    "data = pdata.iloc[10:] * random()  # some noise\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _load_data(data, n_prev = 10):\n",
    "    \"\"\"\n",
    "    data should be pd.DataFrame()\n",
    "    \"\"\"\n",
    "\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data.iloc[i:i+n_prev].as_matrix())\n",
    "        docY.append(data.iloc[i+n_prev].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY\n",
    "\n",
    "def train_test_split(df, test_size=0.1):\n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn])\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:])\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "in_out_neurons = 2\n",
    "hidden_neurons = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_neurons, input_dim=in_out_neurons, return_sequences=False  ))\n",
    "\n",
    "# model.add(LSTM(hidden_neurons, return_sequences=False, stateful= True,\\\n",
    "#                batch_input_shape = (100,10,2 )   ))\n",
    "model.add(Dense(in_out_neurons, input_dim=hidden_neurons))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(data)  # retrieve data\n",
    "\n",
    "# X_train = X_train[0:1600]\n",
    "# y_train = y_train[0:1600]\n",
    "\n",
    "# print len(X_train[:100]), len(y_train[:100])\n",
    "\n",
    "# model.train_on_batch(X_train[:100],y_train[:100] )\n",
    "# model.train_on_batch(X_train[:100],y_train[:100],(100, 2) )\n",
    "# model.train_on_batch(X_train[100:250],y_train[100:250],(150, 2) )\n",
    "\n",
    "print X_train.shape, y_train.shape\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=100, nb_epoch=5) \n",
    "#           validation_split=0.05)\n",
    "\n",
    "\n",
    "# predicted = model.predict(X_test)\n",
    "# rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "\n",
    "model.predict( X_test[0:10] )\n",
    "\n",
    "# and maybe plot it\n",
    "# pd.DataFrame(predicted).to_csv(\"predicted.csv\")\n",
    "# pd.DataFrame(y_test).to_csv(\"test_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXuQZOlZ3vnL+z0rb+dUVd97enpGmtEVCd0QuIUxAQSa\nDbwExoQtRQBhHBI2VrAOm0tYM8uAtcYbVmhBxMTuYmNxCbCIYIUQWtaClkACybu6WNJIM5ru6enu\n7K46l6zMqsqsvOf+8dWpyrplnsv3ZXYN+SgypqorK+vRmye/9z3v93zPCwsssMACCyywwAILLLDA\nAgsssMACCyywwAILLLDAAgsssMACCyywwAILLLDAAgsssMACCyzwskUE+BLwxyf8/EPAt4CvAK+f\nFakFFlhggQVORngGf+NngGeB0TE/+wHgYeAq8E+A35gBnwUWWGCBBaZAdXI4h0gA/wcQOubnTwC/\ntfv154ECsKyY0wILLLDAAlOgOjn8B+BfAsMTfn4WuDP2/V1EQllggQUWWGCOUJkcfhAwEPsNx901\nODj8s+PaTwsssMACC8wQUYWv/TZE2+gHgCSQB/4z8K6x51SB82Pfn9v9twO4cuXK6MaNG+qYLrDA\nAgu8PHEDsa/7wOLvcLxa6QeAT+x+/Rbgb074/dGDhve///3zpnAEDyKn0ejB5LXg5A4LTu7xIPIi\nQCdmFmolBw7Jn9p9gEgMN4EXgGeA98yQz0R0+h1EbOeH0WhEp9+ZKwfggeCwiMU+hqMh3UF33jQW\nsRjDgxAL2ZhVcvg0osUEIgk8M/azn0bc9rwW+OKM+EzF3/+Dv8+nX/r0XDn89d2/5gd/7wfnygHg\n+37n+/hC9Qtz5fCpFz/Fj3z0R+bKAeC7/tN38TXja3Pl8PHnP867/+jdc+UA8Mb//Y3cqM233fv7\nX/t93vMn868pH//w42x1tuZNQypmeedwqvBS/SVuN26f+PNr167NncNhqOLklcdhyOAVlMNh+OUk\nm8c43HJSyeEwJnG6Vb/Fnc07J/5cFcY5vdSYXSxOwnA05Fb9Fle/7epcecjGIjmcALNlYjbNE38+\ni+QwjcNhqOLklcdhyOAVlMNh+OE0HA2xWpZUHuNwy0l2LCbhJE47vR22u9sz4zGOcU5m08RszZ7D\nOOrtOoPRgAuvuzBXHrKhUq2kHKVSiY2NDWWv/z/t/m/eCP3rSUrgfRSLRWq1mtS/3eq12O5uYzQN\nqa/rFUbTwGgajEYjQiF38ZCNjZ0NBqPBAxOLecJZkOfNw2jNPxbO3583D9k41clhY2Nj7pvGDxJU\nLJpOZTjvC99oGvSGPRqdBoVkYW4cxv87LxhNg0anQaffIRFNzI3D+H/nBaNpYDbNuRYND0osZGPR\nVlpgIpwKcd637ns85tDGOMLhAYmF1bLmx6H5gMSiae4VDfPkMP7flwsWyWGBiTCaBqloau5V0YPA\n40Hg8KDweBA4PCg89ji0FncOC/wtgtE0eEx77IFYBObN40Hg8KDweBA4jEYjjKbBK7VX/q2PhQos\nksMpw6VLl/jUpz41s79nNA0e1x+f+yJgNs25fwAfhFh0B122u9tcLV/9Wx+LRqdBMprkwtKFv/Wx\nUIFFcjhlCIVCM914M5smryi/gkanQX/Yn9nfHUej0yAdS3M+f36uPW6zafK49jhmy5ybEMJqWWhp\njZXMynxj0TJ5lfaqub8fekZHT+tz34t6lfaqxZ7DAvLQ789nsfUCo2Wwkl2hmCxit+z5cGgaaBkN\nLaPNt0JsGVwqXCIcCrPd3Z4PhwclFk2DRyuP0mg36A16c+PwoMTCuat9OaknF8lBAS5dusQHPvAB\nHn/8cUqlEj/+4z9Op9Ph+vXrnDt3jn/37/4dq6ur/MRP/ASj0YgPfOADPPzww1QqFf7BP/gHB85u\nfOQjH+HixYtUKhV+5Vd+Zeb/X4ymgZ7RSQ11vvP7DCQfo/DEIYPO//VfDf7tv509h3EeWXS+/R0G\n23PID+Pvx+9/3OCDH5w9B4fHSnaFTLjM695m0Z2DvZETi+RA5z/+F4Nnnpn+O6p4XFi6CMMYr3/L\nFsOTptecMiySgyL87u/+Ln/2Z3/GjRs3eP7553n66acJhUKsr6+zsbHB7du3eeaZZ/jQhz7Exz72\nMT7zmc9w//59isUi733vewF49tlnec973sPv/M7vcO/ePWzb5u7duzP9/2E2Tf7od3XWX9RpDEy+\n+c2Z/vk9Dhl0fuFf6Gz2Tf7qr2bPweHxn39Dp3Ffp9Y2eeGF+XBI9nV+6V+LWHz2s7PnAKKV8mv/\ni07H1rm/aXLr1nw4RNs6//4pna2Byec+N3sODo9f+QWd0ZbOzXWTe/fmw0M2XtbJIRSS8/D+d0P8\n9E//NGfPnqVYLPILv/AL/N7v/R4A4XCYp556ilgsRjKZ5JlnnuHpp5/mzJkzxGIx3v/+9/PRj36U\nwWDARz/6Ud75znfy9re/nXg8zi/90i8RDs/2LTOaBh/9LY3veavGw6815rIgGk2DrTWN7/w2De3S\nfDg4PP7gP2l85xs0Hnr1/GJh39H4e2/TWL06Hw6OSuij/1njTa/SuPyq+cVi7abGD1zTOP+K+XDo\nD/ts7Gzwsd8v89qrGpcen9/1KRsv6+QwGsl5+MH58/szjC5cuMC93XJC0zTi8fjez27dusUP/dAP\nUSwWKRaLPPbYY0SjUdbX17l//z7nzu1PTU2n05TLZX+EfGA0GrG+bZAaaVzWdHLLBvOYuWQ0DTbv\n6/ydN+o0+gYvvQSDwWw59Id9Gu0GZ4olzhd1ls7MLxYbd3W+8w06W0PBYdZt7u3uNozCPHo5w5kl\nneL5+cXCvKXz9tfptELz4WC3bLLRIq97TYSVnE7l4nx4qMDLOjnME7dv3z7w9ZkzZ4CjFhcXLlzg\nk5/8JBsbG3uPVqvFmTNnWF1d5c6dfdfLVquFbc9uU3i7u01oFOVtb8ygZ3QSpTm1Ulom91/Q+e63\nVqi1a2j6kDszNgO1WzapUIm3vCmCntFJV+YTC6Nlcvc5nb/7Fh17xyQeB3PGIhmzZZIe6bz5zYg9\nGH1OsdgWsXjHm3U2uiabm7A1Y9dss2WS6Ou85S0iFvmV+cRCBRbJQQFGoxEf/vCHqVar1Go1fvmX\nf5kf/dEfPfa5//Sf/lN+/ud/fi+ZmKbJxz72MQB++Id/mI9//ON89rOfpdvt8m/+zb9hOMPdLqNp\nkOiLRUDLaISy87llvm0bdDY0Hns0Rj6R58IrajPnYTQNou39BTGcm08sXjINYl2dRy9lGYwGXHqk\nOZdYhJr7sYgV5hOLW6ZBMa5z9WyZ2k6Nh64MZl61G02D4ebuZyStkSwv2koLTEAoFOLHfuzH+N7v\n/V6uXLnC1atX+cVf/MVjzcF+5md+hieeeILv/d7vJZ/P89a3vpUvfEEM1nnsscf49V//dX7sx36M\nM2fOUCqVDrSrVMNoGgy2tL1FoBubz4V/c93gsQs64bD4AK5emT0Po2nQrWu85S2CwyA5p+RgGbz6\nikY4HEJLa5y9OvtK1Wga7Nj7sRil5xOLu3WD113ViIajLCWWOP/o7IuG9W2DrfX9z0go+/JpK51q\nV9YHGd/+7d/Ov/pX/+rAv127du1AuwlEInnf+97H+973vmNf513vehfvete79r7/+Z//eflkT8Dd\nusGOpfOGN8CXbJ1Gz6DXg40NKBZnRoP7mwb/4yt1QHwAS+cNbtx4bHYEEIty29Z5zWvAeklnGwPT\nhJ0dSKVmx8NoGvzQ4/ux0C4Z3LhxaXYEgBtrBr26zqOPwjef02lH9veBIpHZ8ai1Dd72uv1YLD9k\ncOOGNjsCwHN3DSJtnQsXQG/o9OL/jRdeEPtAczKJlYbFncMCJ+JLz5kUYjqZjPjwmS2Thx9m5pVR\no2/yXW/YXwRyy7Ovlr/4nDiNG4sJDlbL5OJFePHF2fLYHpm84037scivzj4WX37e5GxB3MnpGSHr\n1TRmug80HA3ZCdX47jdXgN2i4dzsY/Hfb5hcKOuEQoJDo28Si81+H0gFVCeHJPB54MvAs8Bxx5eu\nAQ3gS7uPX1TMaQGX+MoLBhfKohLT0uIU6sMPM9MPYLc3oBep8XffWt7jES/Ovo3x9VsGl/XdWGTm\nE4uN7RZDerz9Tdk9Hqk59Li/ecfg4dX5xuK2WYNOjje8PrbHI6PPPhYv3DN45NzRWLwcWkuqk0Mb\neAfwOuA1u1+//ZjnfRp4/e7jacWclOPFF1/ku7/7u+dNIzBurhs8clZUqYVkgVavxcUrnZl+AP/f\nr9cI95ZY1kQHVM/ojDKzl3DeMg1eeVHEQktrmC2TKw+PZhqLz33ZJNbVyeVEv0JP64Tzs18Q72wY\nvOqh/bsXo2lw5cpsk8NfftEgOdBxVOF6Wie6NPtY3GsYvO7h+cZCFWbRVmrt/jcORIDjDBhOeXfu\n5QmzZe4lh1AohJbRWL5szbQq+vK3TFJDfe97PSNOBudycP/+7HjUOiavOC94JKIJMrEMZy7XZxqL\n/35DnBR3oGd0Wph0u2IfaFaod00e302US4kl2v02F6+0ZxqLr98yyUcOxqIfN/f2gWaFzYHJq3cT\nZSVdwW7ZXHl4uEgOHv7Gl4F14C8Q7aVxjIC3AV8BPgHMdqdxgROxOTB45YX9DT4trVE4M9vq7Bu3\nDZaiYxzm0MYYjWB7ZPCqywd5lM7PNhbP3TUoxg9yMFuzbWMMBtCOGDy+GwunaNAuzbbf/8I9g3Ly\nYCysHWOm+0CtFvQTBq+8KHjEI3Ey8QyrMy4aVGEWyWGIaCudA74Lsccwji8C54HXAv8b8Ecz4LTA\nFGxtiQv/0XMHq7OUNtsF8YU1g0r6IIdZJwfTBDIGDy0f5JFdnm0sXjQM9Ox8Y3HnDoSyBudLB3nk\nV2cbi5csg5X8oVi0ZhuLF18UsVg9xKN47uVx1mGWUtYG8CfAG4HrY/8+fqbxT4EPAyUOtZ+efPLJ\nva+vXbvGtWvX1LBcABAXfiRnsJI7fOsuJJyzki3esQ0uXDq6IH7Hmdm1lW7ehFBGOICO8xiljZm2\ntqp1g9e/6mgsHp1hLG7cGDFKiZkS4zzCWXOmsbi/ZfDqytFYvGKGsXjuhQ6jaJNCsnCARyRvcv/+\nK2ZD4hCuX7/O9evXpbyW6uRQAfpAHUgBfw946tBzlgED0V56E2L/4ci+xHhyWEA9vvXCkEHCQssc\nbCvZbZOlJajXYRY2T+tbJt9ZObgQmS2TSgWqVfV/H+CbL3QYRdosJZb2eaR1Ngcmw6FoL6TT6nmY\nTZMrh+5enFjMylXlqy/UiZEmEU0c4LETNqjXZ1c02DsmD595/AAHs2ny9hnG4r/fsEiNNMKh/QaM\nltboxYyZcTiMw4XzU08dXm7dQ3VbaRX4c8Sew+eBPwY+BfzU7gPgh4Gv7j7ng8DxPhMLzBTP3qwT\nI0M8sm8S6FRn5TJYlnoOwyFsdPcVUwClVIlGu8FSqTcTDgBfu2mSDlUOnG53+v3l8mwWo25X7Htc\nPXswWRtNg1JpNLNYPPuSQTZ88KCZKBoMcjlRNKjG1hZ04wZXVo7GYlbXJsBzdwyWYgdjoWd0GgNx\nWHSWG+MqoDo5fBX4NvalrL+6++/P7D4Afh141e5z3gb8jWJOM8GlS5f48z//83nT8A2xEawf+Dcn\nOVQqs/kArq1BtHCwvx0OhSmny8QL1swWgeerwsNnHLOOxe3bkCgd7G+nYimxCVranFksXrhnUkke\njYXZNGcWixdfhGTJYHls/6WYKrLV3aJQnl3RcHPdQE8fFwtjpndzqrA4Ia0IoVDoxJGBp2E86I37\nJtpxF/4M2xg3bkC8YB7o9Ts8wllzZh++F9fNAwuRw2HWsYguHR+LSH52sXjJOpigHA5Ga3YL4o0b\nEM4ejEU4FKaSrhAvWDOLxZ2aydnifK8LlVgkBwX4x//4H3P79m3e+c53ksvl+NVf/VXC4TC/+Zu/\nycWLF/me7/kePv3pTx8x0bt06RKf+tSnAKaOD1WN2zWD1aVD7YPMbG/db94UapDxzU8QLYR+0phZ\nhVitG5wrHuUw61gMU8fHYpiaXSzWtgwuVOYfi37i+FiQmU0shkMwWwaXtPnGQiVOTXKYx4xav/jI\nRz7ChQsX+PjHP87W1hY/8iM/AsBnPvMZvvnNb/LJT37y2LuKUCi019eeND5UNQYDsFoGlyrzbaXc\nuAHdmHFstdyLzWYR2NmBzaHBRe3kWMyiQnzhxohO1DggEHB49BOz2QDd2BCL8nibz+Ewy1g8f6NH\nN9yglCod4TFMziYW9+5BvGhwtjDfz4hKnBpX1loNVla8/U7oKTkHr0fvD+bT4CSCJ598kpRLC89n\nnnmGX/u1X9sbEvT+97+fixcv8tu//dvKR4XevQupinls+8BsmjPbhH3hZo/e1S2KqYMWsHpGpzky\nabWg14NYTB2HW7cgv2KyclxbaYZ99udvbRN9bYx07KAsSs/odCImlqXeCfTmTcivmixnrx7hMNNY\n3LHJny0TCR+URekZnV7cnNndS1Y30TMPH+Fgtkweexm0lU5NcrAs78kh6KIuG15mMTjjQ8cTgTM+\ndHV1VQW9Pdy4AbkVAy3zyIF/z8QyDEYDcqUm3/pWRikHgOfuWiw9Xj4gFQTH28igWBQfQK/XhRfc\nuAFpzUBLH1wQy2kxYKZYGvDiTfXazW/dMyi/+agdtZbW2OgaxOOwvQ25nDoON26ITXEt/baDHDL7\nqinbVu+Ec2PNoJI+PhbbI4NmU33RcOMGxIrHtLZm3HpViVPTVjptgT481Ofwv2UyGVqt1t73g8EA\nc8zn96TxoaoTA4iqKF482s4JhULoGZ3o0mw2QF80jCMbwTDbNsbNmxBdOhqLaDhKIVkgUbSVX5uj\nEdw+ZiMYZtvGuHkTwrmjscjERKGQKzeVcxgMxHyPw+0ccKp2UTTUjnNwk4ibN4H00ViUU2Xq7Tql\n8uDU3zmcmuRw2gK9vLzMjQkGK4888gjtdptPfOIT9Ho9nn76aTqdzt7PJ40PVY1bt4DM0QsfxAeQ\nrPp+f6sldP1nlk5YEFuzqc5u3RIbwSfFIpxTH4taTSzKJyaHGcaiHz+qmBovGlRzuHcPsssHT+47\nmOU5nFu3oBM9el1EwhGKySLxgvqiQTVOTXI4bYH+uZ/7OZ5++mlKpRJ/+Id/eOROYmlpiQ9/+MP8\n5E/+JOfOnSObzR5oO00aH6oad+9CN3p0EYDdsZBJ9YtAtQrFs+aRDViYbY/77l1oR46PhZ7RIa3+\nLuruXVg6czIHJxaz4NEKnZwoQxn1m8F374p9jxNjMSMZ6d27YvDSsZ+RjEYkPzsFmSqcmj2H03bn\n8MQTT/DEE0/sff+zP/uzR57z7ne/m3e/+93HPmfa+FCVqFahefVoPxV2N0BnYA9QrYoK8fAhI9jv\n6z4+g0WgWoWtVx9VCTk8+gn1i0C1Chn9+PfDicWrZ5EoqwO2BzXK6aO+KVpGYzADSW21Csny5Fis\nzCAWd9aaDOmTjWeP/Mzx3Tpta9ZhLO4cFjiCu/cGbA82jl0ExAwBg40N0f9VhWpVbH6eVCHOqn1w\nZ70JodFeX/0Aj7TOTmQ2iTJWmB4L5dWyXSOfKBANH60p9YxON6b+LqpaPX4PyOEwi1iMRlCti7uG\n4/YWhWrq9N85LJLDAkdw17YpJIonLgJ221Tuo1OtQjR//G27M2BmqdxWel0Mh7C2OXkR2Oybyn10\nqtWjJ4IdVNIV7B2bUnmoNBadDjT6xhFJrwM9LYqGWk3ETRWqVSA9vcWmMhaNBoSyR0/N7/FI63Si\ns5HUqsSpSQ6n/RbttGB7G3pxAz179LYd9k+Aqu7rVqswTB/fznEGzMQLaitVy4KUNiEWMzLfq1ah\nnzw+FvFInGw8S6q0oXQxun8fiueP5wAiFnbbIJtVXzR0Y8fzyMVzdAYd8qUdpbGoVqE0JRaNvkG3\nC+22Oh6qcWqSw2nPwqcF1SqULxx/2w6za+k4i8AkHmHFm35370Lp3PRYqE6UYlN8Mo/Yktr2ltgU\nfzBicdKmuKOaihfVFg3VqjgHNCkWLwfzvUVyWOAAqtWTlTEwO0VItQotJvNQrRSqViG37C4WqhPl\n9nAyj1BWbRtDbIqbxwoEHA6zisXmYHIsInn1sUhX3MVikRxmgNMc5NOEahUy2vFqENhXhMxiEWj0\nJ/BIa8o3/apVSFYmc5jFBujd6pB6z6SSrpzIo6/YU6hahURxQitlBrEYjeDuWpvOYOfA4KXDPIYp\n9bGILrmLxWkuak+NlPW4I/HFYvHYjcK/rSgWi9OfNAV37wpbgJMqs70BM+URlqUm9oMB3Ld2CA87\n5BP5Y5+jZ3TaEfXJQShjjj+VPovTyTs70BzUycazBwYvHebRjaqPRahkoGdecyIHo2nwGoWx2NgQ\nFu65jHbi594ZZau63cglAz3zqhM5GE2D155y871Tc+dw3JH4Wq3GaDQK/PiX/3LEd/zP/4J//9l/\nf+Jzln91mf/5P9zjn/2z4H/vuEe9PiJdMSl+oHjicz70Nx/ivX/yXjKZEZubR39ek+AZUK0enZc8\njlQsRSKSIFfeVFadGQYsrZ6sEgLxAdwaGmIDvaeGR7UKoxNOR4MYMLPd3aZY6SqLxb17ULl0MgfY\nlReHRLV8wgiRwKhWYZg4uZ2jZTRhylgZKYtFteouFu2o+juHXnz++y+qcWqSg8rqrFqFYerkCx/E\nGx5V2MusVkG7NJ2D2TKV3q4KZcxkHlpGI1ZQG4vKBfPEdg6IWFg7plIfHbEInBwLZ8BMoqhuKl21\nCqVz06+LetckEhF32Kp4tI+xi3CQjCZJxVJkSg2lsShM2A8DEYvtocnmJqiaqVWtwk7oZB6FZIFW\nr0Wh3F3cOcwCqpPDSfI4B1pGg6y6iqRaheK56RxUVyTVKrTDk3k4nkIqOUxSxsBsJLXVKjQ5ec/B\n4RFdUtfGqFYhvzKdgzOJTSWP7eF0HvGi2licdFJ8nINq871qFRqDk3mEQiFRNJRmN6FPBVQmhyTw\neeDLwLPAvz3heR8CvgV8BXj9SS+mcqPLWQSmVSQDhVYJQhkznYPqja5qFbaG03monD5WrUJan38s\n7t4Vm+LTeKDQU+juXbEp7jYWKniMRuI9qfemV+0qx7fevXvyqflxDipj0e1CbWOE3Z5eQJ12fyWV\nyaENvAN4HfCa3a/ffug5PwA8DFwF/gnwGye9mOoLvzHtwk+rtQcQnjEny+NA/bCdfh9MEza6U9pK\naY1+Qm0s4sXpbSWVsWg2od0ZYbePN/8b5zFQHIvjZkcf5qAyFpYF6VyXre7RwUuHeQwVegpVqxDO\nuW+9quBx/z5oZ7eIR+JHBi8d5hHKLO4cJsEZWBAHIsDhG70ngN/a/frzQAFYPu6FMoWmkpOX9TpE\noiOsncmLkZbRaI4MZac/p8njQHjFb7Q3yBcGSnisr0NJ67Ld3aaQLJz4PGcDVGUswtkpbaXdFttS\nYaSER7UKqxc3SUQSJKPJk3mkNdoRtbEgPaWVshuLQkHN6eRqFZYvW5RTRwcvHeCR1uhE1cZikJx/\nLLRLkzk4PHpxdbGYBVQnhzCirbQO/AWivTSOs8Cdse/vAueOe6HokqnszT5zuS5UONHEic/TMzqN\nvsHWlhrvGMcuYtKCGAlHxICZgq1uEXhI6OknLQJi00/9IjApFo4RnqqiwVkEJnGA3VigNhaTlDGw\nP2AmX+gri8WkU/MOZlE0HDdDYRzOXpTKoqE44dS8A8eU8TQnB9XnHIaIttIS8H8D14Drh55zWKt4\nrBjvrz/7y/Tss8RicO3aNa5duyaFoLjwTYYuLnxrRxjObW5C4eTC2jePpdjkW2aHR3RgUrcnP88v\nh9I5E1xw+ELvC/R6wpAtcXJO9c2jcsIMBQfjVgn1+lHbZBkcls6YRF3E4kbtRep1NTOcq1U4M0EZ\nA6JoKKVKJIs29fqxN96BOeRXTFIuYvHs9g2lyeHcCTMUHGTiGSKhCNliU9l1kdVN8i5ica+jpqCd\nhOvXr3P9+nUprzWrQ3AN4E+AN3IwOVSB8cHK53b/7Qje9vf/B+5/+gd58km5xO7fh/yqQcjFmz1+\nuyo7Ody/D9Epm+IOj9DAoH7jcbkEdjlkdGPqguhUZ4WCcKjUJeep+/chMZzcYoPdDdC+Qf3OZbkE\ndjmkNYOMq6JBzHButSAjcbT2aARra5CZsinu8Ih0DSXJ4f59SJQNii44fK771zSb4iBjROJo7V5P\nfO4yXXexiBUMJcnh/n0xQrc07TOS0fim+cLMk8Phwvmpp57y/Voq20oVxB4CQAr4e8CXDj3nY8C7\ndr9+C1BHtKCOoJ9Qk4XX108eHjKO8QVRNo/hUGwE13vueAxSam5X19chXprO4XCilIlORyyytc70\nRUDLaIzS6mIRLbjrLauKRb0OqRSYO9MTpZbRIKMuFpG8u1iYLWPv7lomDAMq2gij6S4W4Zy6WJB1\n9xmptQ2Gw9PrzKoyOawCf47Yc/g88MfAp4Cf2n0AfAK4CbwAPAO856QXU7XRtbZ28vCQcahcEGs1\nyOXAbLnj0Yupi0XkmAHyx3FQFYv1ddCXdxcBFx/AfkJdLCadFB/noCoWa2uwvDqg3q5TTh0dvHSY\nx1BR0bC2BqMph0QdDmbLVBYL/aw44Xfc4KXDPFQVDWtr0/fDHA5Ga//u+jRCZXL4KvBt7EtZf3X3\n35/ZfTj4aYSc9bXAF096sR1FG11iEZh+4ecTeTqDDrliW9Ei0Gezs0kpVZr4XOEppOYuyu0i4AyY\nWSoMlS0C4VCYTHzKIrArL1a3CHhbEDc25HMon7MpJotEwpN7NHpapx83pXNweEzbFIeDiVJFLIrn\nJluq7PFI6wyS6q6Lk+arj0NLCzsRVaqpWeDUnJDeHim88BPTq9RQKISW1kiW5PNYW4PiWcvVIqCl\nNZohQ1ksOrHpsYhFYuTiOdLlDSWxmHY62oGW0WiF1cWiHZnewsjFc3QHXXKllpJEmV+dzgFELFRJ\natfWxAyFaTzKqTJ2S13RkNXdx6IbU3ddbI/c7YepSpSzwqlJDo2+ugt/0iCVcegZnWhBPo+1Nci7\nXBD1jM5+Xl3KAAAgAElEQVTWQO0i4JZHoqQmFpMGqRzmoOrsibMITOPhqKaSJfmV6tqa2BR3HQsF\nklpnU3xrwjwJB7FIjKXkEulyTUkspp0Ud6BndHbC8mMxGIiDdfXedB7ZeJbBaKCkaJgVTk1ysNsG\n/b7YsJSJ9XVoTpHHORBH4tUsApmKew6NnrknnZSFvUVgwiCVcWgZjaiiWCTLkw8kOtAzYoazbA69\nnugTTzs1P85DSGrl8lhfh0TRPYftkXwO29sQDovPn1seybL8hXl9HWJTToqPc2gqiIVlCXdoa2c6\nD6doSJVnL2eVhVOTHMalk7LQ6YiLf6Pr/nZVxUbX2pqQx7nlYO4YJBJyHTgdZYzlQhkDzvQxNbFw\nIxAA0WKrdQyaTbkOnIYBmoarTXGHhwp1zNoahF2ohBwO9Z4aDisr3mIRyavhEXKhEnI4bCq4u15b\ng+WVIVbLOnHw0mEeseLpPQh3apKD2TKln3pcX4flZXHhu6pI0sJ8T0VVFM4ZE32V9jgoUsesr+8v\nAm5joUIds74OuFAJwb4iJJ+XK510FgF7x3a1CKhSx6ytwXDCPInDHKwd+dLJtTXQzuzQHXRPHLx0\nmEc4q+aOsp9wH4tax6DRkHt3LQQCGxMHLx3mEVEkqZ0FTk1ySEQS5CqbUgO9tgb68oCN9obrRUCF\nOmZtDQYuVEIgvOKb3SZLpa70WFRWW/SHfXLx3NTn6xmdXlzRIjBhhsI4nAEzsouGtTUond0gn8gT\ni8SmPl/P6AyTaoQKPRen5h0OKtQxa2v7MxTcTF10JLUqYtGecmp+nIO1Y5JKic6ATA75FXccHB5k\nFm0l5dAyGqmK3ItubQ1K52osJZaIhqcfFnc2ulRc+N0pnjEOnAEzGc2SHovCWfeLgJYRJmtqFgF3\n7QNnwExOa0iPRX7V3fsB4rroKDh74kUg4AyYyZc60pNDdoqV/Dj0jE5Pwd312ho0XQgE4GDRIPu6\ncCsQgN0Dq0k1qqlZ4NQkBz2jk5C86be+vjtIxUWPHcRFt61AHeNWKjjOQ/amnxepIKgxWXM2xd2o\nhBxoaY2MJpfH+jqkK+4SlMOhLVkd4yhjGn13PJwBM1ld/mfEjYOAAxXOrK3W7hyFrjsejp12XqtL\nj4UbBwEHotOwaCspx75firzXXFuDlIdKQM/o0je6HM+Yugv/nHEecckbXWtrwj/HC4ctyc6s29vC\nuM6tMsbhEZcsqXUEAl44yJaROsoYN6fmx3mkKvJjMW2exGEOOyH5CcrLfpjDI63Lj0XYhYPAOAeV\ndu6qcXqSQ1qX7h2ztgbxgrcLv96Ve+Ebxu4I1JY3HuGcXB5raxDNu+egpbU9Sa1MDisrQnzg5Q4m\nJllSKxYBb+/H5kBdLLzwiBXk83ArEHA4yC4ahEBghNn0dl3I7jS4dRBwoGU0miz2HJRDyEjlv9lu\n5XGwP5+22RpJk06OK6a88JCdKNfXYTRlqMw4HEWIbA768u4i4CEWIcmKEMc/xzWHjMZGVz4HbaVL\ns9ucOHjpMA/ZMlLHOsNLLGQfWF1bg/KZBslocuLgpcM8VHQaOlFvnxEVktpZ4dQkB6GOUbMIuK0E\nMvEMoVCIfLkpTTq5tgb6aoed3o7rRUDP6AySahYBt7EopUo0Og2G9KVJJ9fWoHy2TjqWnjh4aRyO\nOkbFIuDlLsraMag3RtIGQTkqoUq64kogAPt317I3YTsuVULgFA1ylVteTs3v8UjLP4fjRSAATqdh\nkRyUQ8/o0je61tfdmWgd5pFdlncHI7yExO2y60Ugo9OTLKn1IhUEMWCmmCyytCJvKp0jFXTbOoD9\nGc6yr4udKQN2xpGJZ4iGo6Ty29Kkk+vrkF32fm0OJRrODYei7bk19FY0bHU32en26PXk8Fhfh7Tm\nPRYyOw3OgdnNvrfWq9022aiPpJ63mBVOTXLQ0hotyYZza2vQxP1tosMjrcnjsbYmBux45dCOyOMw\nGIgN0K2BNx4iUcqNRcqlf44D2ZLaVkssBG5PzY/zyK3IK17W1iBR8s5BpjpmYwOyWfen5kFIrUup\nEvllS5qbgRcHAQdaRqOfkHddGIYYauVmnoSDVCxFLBIjnNxiZ0cOj1ni1CQHPaOzPZRXCWxvC+mk\nm6Eyh3nINJxzFgGvHGTOLd5Txux455GUqI5ZW4NYwTsHmZLaPWWMB5WQwyMtUVK7tgYRlzYi4xxk\nqmP8bIo7PDISJbXO3qAbB4FxDl2JnYZxGxGvsZBZNMwSpyo5yNzoWlvb3Qj2sQjEluTyCOe9c5Dp\nzLoXCx8Xflzipt/aGuBjEZB59iRILGSePRHKGO+xkCmpFQ4C7gYvHeYhO1F62Rt0OMh0Zl1bA225\n72rw0mEeMhPlLHFqkkMlXaHetdmoy9nxc24Tzab3qigkUUZqGDByMVTmMAeZklrDAE33JhUEx2RN\nLo9BwvueQ0OiM6thQEV3N3jpAI+0TnRJLo+eSxuRPQ4ZnS2Jd9eGAaWVbSKhyNTBS4d5yDyHYxjQ\n8bE3KNOl1jBgacWmlCpNnbkyDjEDZnHnoBTOgJl6R04T0TShrHfZ6m5RTBVd/56W1hhJVMeYprsB\nO+PIxrP0Rz02tlvSOBSXt4iGo6Rjade/J7xj5MbC7WwNB+VUmUbXZqMxkMYht2xRSpUIh9x/PJy5\nxbJ63Kbp7dQ87DqzduVyyGjeODg8Inm5PJouBuwc5iCz02CaYj/MayxUHN6dFU5NcoB990sZ0kln\nESinyp4WAT0jd26xswh4WRAdr/jNgSlFOmma3jxjHMiWkZqmN+sMEEVDPrFEvV2TxsHrpjjIdWYd\nDsVc8c2BNx7ZeJYRQza25Xi5myYkyt4qdnDs3OVU7e22sM7Y6HosGtJltnobUouGmIdT8w7EgdVF\ncjgO54G/AL4OfA3458c85xrQAL60+/jFk15Mz+hkJR2JN01I+bzwu1E5F76zCGy7mLJ1HI9kyZQi\nnTRNSJa8c9AymjRn1p2dXSuRrvsDcA6WszqdqClFOmmaEHc5YGccMiW1jkrIdjFUZhyhUAgto1Pv\nmVKkk6YJUY/7YeBIauV9TisV75vi0XCUpUSBDYlFQ8TDqXkHWlr+4d1ZQXVy6AHvAx4H3gK8F3jl\nMc/7NPD63cfTJ72YcGaVc8DGqQQ83zJLnFtcq0E+L/xz/PCQJak1TaGM8XPLLEtSa5r7A3b8fAAz\nEouGsIdT8+McZDmzjsfCKw99t70lQzppmkDGXyxkHVgNFIusMMqUdXc9TPl5P/RT68yqOjmsAV/e\n/Xob+AZw5pjnuTr9paflbXQZhjcTrT0OEtUxQRZEmeoYZxHwooxxOLQkqWNMc19H7icWsgznTBOG\naX8cZKljgsZCZqIcehRLOBw6ku6uTRM0fYjdcjd46TCPVNmQ4mYgBAL+3o/T6sw6yz2HS4g7g88f\n+vcR8DbgK8AngMdOegE9oxORJCM1zV0TLY8LopbW2OpbbNSD37c7ycHrLTOIRBmTpI4xTaES8lOx\ny1LHmCZUNDF4qZx2LxUEuTOcTdP9sKHDHGTNLTZNKOotBqMB2XjWM4+kpLnFpgltDzYi4xyaks6e\nmCbkl2ssJZdcDV46zCNVkRgLDw4C4xza4dPZVpo+4UYOssBHgZ9B3EGM44uIvYkW8P3AHwGPHH6B\nJ598kv9W/W/UvmryuZVrfP/3XwtEyDThTMzgvMdWSiKaIBFJUms2AHdeSJM4FJebDEdDMjH3UkHY\nV8fIuvAvRw20zAVPv1dIFugMW9Q2O4A7L6RJHPIr7gcvjUNLa0QlGc6ZJuyEDbT0Gzz9XiVdYXNg\nUtsYErTmMk1hnaGl3VuqONDSwnBOVqtPOAh8mzcOGY2tgTwOac17OwdELGQcWB2NBI+toY8WW0aT\nemB1Gq5fv87169elvNYskkMM+EPgtxEL/2FsjX39p8CHgRJwYCfpySef5A++/gc899v/hTNnrgUm\n5SwCeuZNnn+3ktapdQ1kJIeMLiozr4uAntEZZb4ubUFsYqBn3ujp90KhEKWkhr1jAucCc0j7UAmB\no475mtRFwCuPRDRBKpLBbtYRl69/mKYYsOM3FuHcWuBY9PvQaHjzEnKwlFiiN2pT22wD7lxUT4IQ\nCPiPhYxOQ7Mp5ox4dVMAUTRsDazd81nqGzXXrl3j2rVre98/9dRTvl9LNdsQ8H8CzwIfPOE5y+zv\nObxp9+tjJQZ6Ro4za5BFAIQ6ZrNvBCOB6GMGWQQGEiS1vZ5YBBoehg2NQ0tr1HtyYuHVP8eBLEnt\n9jaEw96GDY2jktLZ6MqJRdSjdYYDPaODBEmtbUOh4G3YkINQKEQ5qe8WDcFgGBDxoZiC3UQpwZk1\nyN5gPBInE83tFg2nC6qTw3cA/wh4B/tS1e8Hfmr3AfDDwFcRG9cfBH70pBeTZTi3vQ2RCNQ63qsi\ngNWckLMGlU6aJsQ8TNkah9joCq7csm0olfztewCs5MR5i6DSSdOEiIdhQ+MQZ0+CxyLIHhCIoqHR\nD74gCsWU/1gMJDizBlkQAbS0LqVoME0g7T8Ww5TE68Kjm4KDclLDbgePxayhuq30V0xPQL+++5gK\noY6Re+H76mVmtD11jOb91w/wyD/mv5+6EzaoB5RxB43FSk4nkjdotSDjbdvkCI+VtHfFFIj3Q4bh\nnBOL5z04b45jJa/xBYR0Mhyg7DJNyHgYNjQOWc6sQiAw4lst07NKCGA5p/H8UE5yKCUMVn3Goi+h\n0yDcFDp8ped+8NI49KzON/oG8IpgRGaMU3VCupQq0R41qNWDjWELWhXpGZ2EBBmpaXo3FHOgZYSG\nO6hqSiwCQ6yW5bulI0NSa5r+pIIOBxnOrKYJJV0MXlpKLHn+/eXd6yKodNI0oRvzHwtZibKwXCcT\ny7gevDSO1Zw4FNjpBOfh1VLFgZ7RpZw9CSIQAFjNC/n7aZvpcKqSQyQcIRcrYTatQK8jFoEduoMu\n+UTe8+/rGZ2oBMM5sQj4u1VNx9JEwzGszWBHpE0TCit1svEs8Ujc8+9raY24hLnFjlTQT4IqpUp0\nRlvU6sH6fMJSxfQlEID9ucUy2hhehg2NQ0trNEcmtY3gRYMjlvADmUVDc+S/rbQTknNtpiv+OAAs\nZzWiSyZNOa4mM8OpSg4ApYSYrhQEhhGsEtDSmpQRhHvmaj5umQGKcQ2rFezWPYhUEHYVIRJkpH58\nlRyEQ2Fy0RKGhKLBj7maAy2jEQ2ojhmNxHyNzaE/HqlYimg4jhXw9sU0vQ8bGoeW0QIfWO12hVKo\n3vPHo5As0BltYde7/kkg1gs/bgoO9IzcGTCzwqlLDlpazGUNAr/mag5kqGP2FgGP5mrjqKQcSa1/\nOItAkFiMAjqzdjpiAlvdo7naOEpJPfCmn2l6HzY0Dhkma40GJJNi+ppfHsWYjimhaIj6FEvAbtEQ\n0NresqBc9t/+DYfC5KMVKZ2GcDbYdRG0aJgHTl1yWMnrbAbc6DJNiBeCXfj9gCZr9Tqk097N1Q7z\naPSC3UUJczX/HLSMxjBgLCxr31zN7x2MKBqCxyLsw1zNgZ7RGaWCxSKoMgagnNKpdYLHYuTDUsWB\nnglu5x5UPQZQSuhYASW1pgmjtHc3BQdaWiMsyaV2ljh1yeHMkuipBtncMU0I5YLdMncCSmoPqIR8\n8ljNa2xJSJQjH+ZqDvSMTjcuLxZB+rqNgGdP/JqrOdDSGr2AZ08clZBf9RgI8z0ZsRgkAnxG0hqD\ngHfXQiXUo9FueBq8NI5KWqPWCR6LbixYW2mUPn3me6cuOazmxK17K8CcG2cR8FsJVNIV2uEatbp/\nr3gZi8DZgk4najAIYFnvLAJBquV2QMM5v4OXxnG2IEZkBoFpQs+nSgjkzC12Bi/FIjFSsZSv11jN\n61KKBq/T18ahZ3R6seB3UfkVi3La28yVcSzndDYHwWMh3BT8x2IgycJ8ljh1yUGYrAX/AAZZBKLh\nKKnQEusN/4cMTBOKKw2S0aTvRWA5K6ZMBdl79Guu5iATyzAKDTHr/qUYpglLq94HL41jNS/2gYIM\ngjJN2PEpmwQxYKYd3sDeCFY05Fb8cwA4WxTS3qB31y0CFg0Rg1rNPwnTFJPoAsViSac5Cp4c/Iol\nQK5L7SxxKpNDUHWMqAT8V0UASzEdo+m/l+lop4Nw0DPBnVnFIuCfRygUIh/RWdsKFotUAKkgiEQZ\nL5o0Gr5fQiwCPgYvOYiGo6RDRdYadiAOSR9DqMaxmtOJ5P0PgnKGUPm1VAHIxDOEQiHMRrCiwc/g\npXGcLQgngb7Po1HOEKoNn24KIKTW3VAdeyPY+axZ49QlBy2jQcDJSnsOiz57iCAktdaO/4rENCEZ\nQCoIIhahAOqY4VBMHWv0g/EIqo4JYq7mwJlb7DcWOzvCbK7W8d/mA1iKaqw3g8UiuhSMg5bWiAVQ\nx2xsQC4H1o5/gQBALqwFLhoi+WCx0DNaoLvrvf2wln8ekXCEVLjI2qb/omEeOHXJQc/ogTa6Wq39\nRSDQYhTQZM00xfS1oHcOQeYW12piEfBjrjYOoY4JFgs/g5fGEVQdY5pCMRVkUxygGNexAxYNZILH\nIoikVlYsCjEdM2CiHKaCxyKIjFRWLJYiOuvbp8tf6VQmh17M/86/bfubSXsYyzmdzQAma7YNoYx/\neRzszy2edyy0jBZIRmrbYvBSsApRZ5h8AGKR1tkIICO1bX/T18Yhigb/d9e2DeWKv8FL4ygndewA\nRYNt+xu8NA5RNAS7Loq6mLnidfDSOIoJDasV3JRxlnCTHFYQttuf3P3+MeAnlDGagqXEEoPwDuaG\nP9MWy4JSOZhKCISkdjuAOsayoB9AKghCNdWJOgNm/HEoVfps7GxQTvlfBFZzwdQxlgVdn75KDrRM\nsLnFlgUFrcloNCIT9+8gqGc1GgHUMZYlvIQCtZUyWiB1jGVBbtn2NXjpMI8gzqyW5QxeChaLIAdW\nLQsyun83BQeVgHfX84Cb5PCfgD9jf/bzt4D3qSI0DaFQiDQa9+r+srBtQ3F5m3AoHGgROF8WEk6/\nsG3oBFAJgfCKj4+yrPm88m0b8ss2xVSRSDjim8e5XXWMX9g2tANIBUEUDcNwG3PDn1zJtiGzHIwD\nCHXMdgB1jG0LS5UgPCrpCt2ojV3zVzTYNqS1YBU77EpqB8HuorYDKKZg98BqgKLBtv3PXBnHSlYP\nVDTMA26SQwX4fcDR5/WAuW67C3WMv0DbNmQkXPhnl3SGadO3dFIsAsF5ZMM69xr+E2VQlRDA+bJG\nJ+r/YKJtC3O1IHdRomjQqQYoGpKl4LE4VxJmb35h27AVQDEFTtGQ477PXoptBxcIAJwLcPZkNBI8\n/EyiG0cunmMU7mFs7Pj6fdv2P3NlHKtLGs3hy6+ttA2M9xzeAgQQDAZHIaZh+uzfWZacSmA5qxPN\nG76lk0F9lRwsRf1vdFmWnEXAOZjoRzrpeEzVA8gmHeTDOmub/mMRxFfJwfmSTj9h+JJO9npiENVG\nQLEEQDakc6/hPxaRgAIBgAtlcUjTT9GwtQXxeHCxRCgUIj3SqW74Xy9CAXyVHJwr6rQCdBrmATfJ\n4WeBPwYeAj4HfAT45ypJTUM5gMmabYtFIEgfE4Rc0K86pt/fXwSC8ijG/UtqbTu4VBCCqWO2t8Ui\nEMRozsFSTMPwKam1bbEIBLl7AWHjEVnyVzTUamIqn9EKziMf0XwXDbYNZIMJBADOFDRGPu+uHYFA\nEHsZB9mwxn2fRYNtwzAd/DNyoazTjYlBUKcFbpLD/wf8HcTIz3+C2JD+ikpS06Bn/I8gdBaBoAtR\nEGfWWg2KRbEIBOVRSels+Nzosm0CyyZBbPr5ldTa9r7zZtAPYNCiIYiligM9oxPyWTTYNpTKYvCS\nn+lr4ygmdMwARUM/gKWKA+HM6j8WRa1Nu9/2NXhpHIWYjuFTUmvbwdwUHKzmhUut34OJ84Cb5PBu\n4B8Cb9h9/EPgXSpJTcNKTmfL5+aOZcEwFbyHWEwVGUa3MG3vA2aEYmpIbacWeBEIMrdYKKaCx0JL\nawySpi+rBMuCouZ/8NI49ADOrJYFvYCySQjmzGpZsLRcJxfP+Rq8NA5RNPiPRSeAjYiDIGdPhGLK\n/+ClcZQSOrZPZ1bLgp2InM9IKHu6zPfcJIdv3328EXg78CTwhMvXPw/8BfB14Guc3I76EEIF9RXg\n9dNe9GxBo+lz08+2xTjKoFVqOBQmMSxzp+bdK962obBaIxfPEYvEAvFYXdJ8q2NsG7rR4LFIxVJE\nRgnu1bwfQ7VtyK3IWQSWc5pvkzVHMRW0hVFIFhhGtzFs7wNmbBuyy8E5gDgZXPfpzGrbwl4mKI8g\nRYNQTMmJhZbW2AjQaWiOgvOQMQNm1nAjYv7pQ98XEOolN+ghZK9fBrKIFtX/A3xj7Dk/ADwMXAXe\nDPwGYtP7RFyo6HQi/t/sUthAz3ybr98fh9joMoBVzxyCjGAcx/mSzk74L339rm1DLKBs0kFyqHGn\nZgDeWgB7i0DABAWOpPabvn7XtiEdwFzNQTgUJj6ocNs2gbOeOcgQSwCcWdLZHj7r63dtG3ISxBKJ\naILIMEXVbiCWDW8cZIglQMyA+UKAoqEgQSxRSBYYRVsYtQ7gfSb3PODnhHQLuOzyuWuIxABC9fQN\n9s9LOHgC+K3drz+PuIqWJ73oJU2nF/engnBkkzIuulzYn+GcLNkkwKWKTjfq/y5qayCHRxad+z4k\ntWIRkMPhfFmnHfEfi0ZA2aQDv+oY2w42fW0c54o6O2HvHEYjsSe2EWAq3ziSQ323aPAGy4JIgCFU\n4zi7pNPCeyzabTGqtNYOziMUChHvV7hjBZtKN0u4uXP447Gvw4gN6T/w8bcuIVpGnz/072eBO2Pf\n3wXOAesnvdBqXiOUFZs7uZw3EpYFmYBGcw6WYpqvjS7L2jVXk8DhQkUMVen3IerhMKujI8915fDI\nR/2dPXFkk0UJi8DFikYvJooGLx2qblcY79ltOXcwOZ/qGMuCsAQlHYjrohP1zqHREBMKzQBGc+PI\noFFtGMAjnn7PtoFLcjicL2ns+JCRCoFAcDcFB+mRzt0NA693lPOCm+Xkfx37ug+8xMHF3A2ywEeB\nn0HcQRzG4Y/ykXuCJ598cu/rN3/HmyFt7BnHucX4IiCjIikndUwfVZFtQ3gpuDIGxIa0s9Glebh+\nNzchlQquI3dQjOsYdX+x4IKkFltRbIC2WpDxcPjdWQTMVvA+Owg7dz8yUtuG4Rk5sbisiwEzgwFE\nPBx+t20oaV3udrd9D14aRz6is7bp7y6q/6i8WHRj/t6P4vImzUjc98yVceTC+m6iVIfr169z/fp1\nKa/lJjkE/Usx4A+B3wb+6JifVxEb1w7O7f7bAYwnh9FoBJ8ZcXe9ycWL7leBWg0KxRFWy5JSCSxn\ndb7kQxFi2zBckXPLXE6VGSXqGOYATXO/CjiLQLXXpJD01g8+Dlpa486az0XgkeCaetg3WbOsEZmM\n+1sH24biyibtaJJkNBmYRyWpY/o4qS1kkyZ65hWBOazmdEK7hnMVD4I4yxLT1yrpiu/BS+MoJXTW\n/d5FReXE4kJZGBG2WuKuyC3GxRIyUIhpvhKlF1y7do1r167tff/UU0/5fq1J7/42sHXCw60sJYQw\n7XsW+OAJz/kY+9LYtwB1JrSUQPTvEn2NGx4XI8uC0mqddCxNIhp8U+hswZ9figyjOQeRcIRov8jN\nNW9e8ZYF+VWxKMtYBFbzOnUfFuayZJOwO2CGEHfWvQ2YEbJJORxAFA1+TNYc0z0ZPEqpEqNEgzXD\n21FtRzElKxZ6Rvd1SFOGx9Qeh6w4sGpZ3jYpLUuIJWTFopIKNvdk1pi0KmSB3AkPt4L07wD+EfAO\n4Eu7j+8Hfmr3AfAJ4CbwAvAM8B43L5wa6bxkeQu0bUN2RU6PHUQv088IQlmySQfJgcaLho9Y6PI4\nnCv6c2aVuQgAxPsaN9e9x0KWYgqEY++mDxmpbYtxlDJ4RMIRor0iN9e8bYAKxZScOzmAlZxGo+fv\nLmprIKnXH0sTJsKddW8n0BzFlKxY6D6LhnnBix+vDozfc9928Tt/hTtF1GG57FTkwjpVjz1u24Z0\nxSApaSG6pIs5uV5h25CRIJt0kMW7IsS2IVE2yEjicKGi+fKOsW1YCjiVbxzpvaLhIU8c4kU5m+Ig\nVFN+DOdsG0YSZJMOkgOdW6aBcN13B0csUZbE4WxRZ2v4155/z7IASYopgHhP5+a6wXfgfpPSsZeR\nxeHsks6n+y9Iea1ZwM3C/QTigNqLwKeBW8CfKuTkCsW47lkRYlmQkCQhBbi6qtOLe3cjtazgbpPj\nWIrqni3MLUuO26SDKyv+JLWWBfWuPB65sM5djzJSmbJJgId075JaZ2RrLcCs4sPIhvTd8xbuYdvB\np/KN45Lm3c59ZwcGwxHWjrxYiKLB+3VBRh6H8+VgM2BmDTfJ4WngrcDziPMNf5ejctSZo5z07sxq\n2xCWYDTn4GxB9DK3ttz/znAI9TrYEkz3HBQT3ucWO4uALA5XlsUJ0J4HN5F2G3r9EeaOPB6FmOZZ\nUut4TEmLxarm+RxOvQ7ZfJ96u04pVZLCIx/VPDuzOpPoZMXioWWNbsz757S0LPaNgsxcGUcurO3K\nSL3x6CfkXReXfXYa5gU3yaEHWLvPjSDsMN6okpQb+Nn0s20gLa8qyifyEO1wz3BvO9loQDrXo9Fu\nSFsE9Iz3ucV7RnOSYqFlKpCysWz3tpO2DaWV4IOXxlFOeZ9bLMtozsH5kpDUejFZs20onLEpJoMN\nXhpHKaFjeJTUCo8pebG4sqIzTHorGiwLliRJeh0U4t7P4cgYyDWOh1f9H96dB9wkhw3EJvRfAr+D\n8EGau7fg2YLuedPPsmAQcD7vOEKhELGuzgv33FdGlgWFVZtyuixtEVjN69Q9bvrJMppzEIvECPdz\n3Lzn3lnMsmBpVR4HEBO3ah7lxZYF3ajE1lY8B+E+d9Zanjg4RnOyoKd1LI+Gc7YtTzEFoGcrkKph\nWssm5e8AACAASURBVIPpTx7jkNHlxqKS0jGa3q+LHQkDuRycL2mQNml6E9PNDW6Sw18g1En/AjFH\n+gXgnSpJucG5kkbT45F4pxKQdZsIu0oh032Ssm3Ir8rlcLageVYK7SmmJPJI9HVueFAKyRrNOY7V\nJe/me7YNLYnqsVAoRKynceO+++tTptGcg+W89xnOe4opSTyi4Sjhfp6bazVPHJJlubHQM5pna3vb\nFgO5ZPHIxrOEwgPurJ2O7OAmOcQQM6SvI+Stvw94E9UrgJ/+nW1DK+BM2sPIhHTu2N4WxFRFLoeL\nFe+bfs4iIJNHeqRz24O8WHhMyeVwoax73vRzFgGZPJID3XPREJcci/NF7/OsLUuex5SDRE/nxXVv\nd9exJbmxOLPk/UySbUO9J49HKBQi2tU9n8+aF9wkhyeBx4H3IuxHPwN8SiEnV7h6RvTvvMC2YXMo\n96Jbino7Ei/TbdLBlVXv9gC2LWc05zhyYY07Hjb9ZE3lG8dlXaftUVJr21CXKJsEIS++7bFoiOTk\nWKo48Fo0OH5bNUn2Mg7SI0dS6w62DSHJsbhQ9pYo+33Y3BpSa9uBZ66MQ5xJOh3Jwcs5BwPhsmoD\n8j7NPnFJ0xilTNrtEcmkO6sEy4JwT25VJDb9vFVFMmWTICS1g4TpyXDOsiAiUTYJYuKWF5daMZ9X\nLoeHV3X6cfccBgOoN4aEO8EHL40jH/XmUitbNgnw0LI3eXGrBaH4Dr1hT+ybSIKQF3tLDqNlEz0j\nz6Dusq7T8SAvrtVgaWUDJAxeGkfWY6dhnnBz5/AeREvpU0AF+EngNQo5uUIqliQ0THBrzZ2Tx2AA\n9c0BG+0a5XRZGg8t7W2Gs2zZJICWK0C8iVlzN2Cm1YJRrEl/2Ccbz0rjUfZoD2DbMJKomAK4rDtz\ni91JQjY2IL9cI5/IEw17qZUmo5TwNsPZtmGQlNtnv3pGY5B0r46xLCicEeaDQQcvjWMprrHusWjo\nxuTGwpEXu8Xe3qBEDiCMCL3Ki+cFN8nhPGIz+jHg/QifpAcCsa7Ot+65C3S9DjndppAsSF0EhFLI\n4yIgUTYJopcZ6VR4vuruAyhkk3Kmr41jOatR8zDD2baFx5RUgUAsQaif4uZ9dyO3nEVA5vsBoKV1\nLI+xkCmbBNDzBYjtYNgd1xxUxKKS1DE8Fg0yFVMAV1Y0RimLTsddppTtMeWglNRZ99BpmCfcJIef\nY39gzwOF5EDnlktPIcdoTvabfa6gszX0VhV1JMomHcQ9bPpZlly3SQdnlnQ2B95i0Q7L5xHr6q6V\nQpYFWcmySRBFQ8PDPGvZsklwigaNb7mUWqsQS4D3M0kyB3I5SETjhHoZXlxzVzRYlryBXOPw2mmY\nJ4Lbcc4RGTTu1Nxf+BmJRnMOLlQ0T5t+jtGcbB7pkebaiFCFbBLEpp8XI0LbhqZk9RiIkaVuN0Bt\nG5IVuXcvAGeL3uTFe7JJyTziPfdGhJYFiaK809EOhBGht0TZ6MuPRayn8cJ999eFbLEEwErOW6dh\nnjjVyWEp6t58T1VVJDyFvC0CW5IVUwC5iO5aKaRCMQVwSdc8yYvFaE75SSrjQSlk2/Jlk7CrFPKg\nmpItm3SQHunc8lA0RBTE4oJHI0LLHlHryBm8NI7kQOdFl4lyTzElORbnfboXzwOnOjmUErprT6E9\nozmJ8jhwNv1MMYDIJQ+ZRnMOCjGddZeDRPYUU5Jj8fCuEaFbmNaIjY6cwUvjWIrq3HOpFLIsCOXk\nvx9ejAhHIzBrXXb6LSmDl8aRC+vcc2lEKNtexoEX9+JeD1qDBqlYSsrgpXFk0F13GiwLRhLdFByI\nTsPLZ8/hgUUlrWG7tAewbQhl5VepWiEDoxBmY/qpx9EIrHqb9mCHpcSSVB7llOZaKWTbEMrIj8VD\nKyVG8Qad3vQBM/0+bPflDV4aR9GDUshRTMlOUPtKoelFw/Y2xAomlXRFqkAAoBDXuO/SU8iyoJ+Q\n31a6sqK5LhpUOAg48GJEqEIsAbvyYh8jS+eBU50cVjxMH7NtGCqoikIhiLR1nq9O59FsiopdtlQQ\nYDmjY7vc9JNtNOcgEY8Qape4cX/6gJlaTY0yBoRSyK0RoW3LNZrb41BIwzCK0Zhu2WvbsKQoFuWk\neyNC2xYSUul3UWdKjGKbdFy476lSTIHoNKx5KBpkK6YArp7VGCTcFQ3zxqlODl76d5YFPQUXPkC8\nr7va9BNGc2o4eDEiFIopNTzcbvoJxZT8uxcQSqENl5t+lgU7YYVFgwuptWUJsYSK92PFg1JI9lQ+\nB4l4mFC7zA0XU+lU7Q2CMCJ0WzRYlnx7GQC9mIJBHHPTg8//nHCqk4OwB3B/u9qOyO8hgvtBIkI7\nrYbD+ZLOtksjQtuWL5t0IOTF7mKR0dRwOFfQ2XYpLxaKKTU84j2dmy58dMSCqIbDmSWdhkulkGXJ\n95hyINyL3SXKRFFNLESnwf11IXMglwMvnYZ541Qnh8vLmuv+ndBOq+lluh0k4ozmVMHBi1LI8ZhS\nwSODzm0XI0v3FFOSN8XBm7xYlWIK3MuLbVuM5lTxfpwra66VQpY9ot6TrxICSAw0bpnuEmVEUSy8\nuBdbtT5bPXmDl8bhttMwb6hODr8JrANfPeHn14AG8KXdxy96efGrZyoM4jbD0fQBMyqM5hwUYu5G\nlqqSTYLwV+q7tAew7BEbXTULYj6qcc+FvNiZz6uCw5UVnY7LosHa6NHsbSpZBHIRd55CskdzjuMh\nD0ohe3ObaDhCOpaWzsOtEaEqxRS4H1k6HMJGx6KUKkmbuTKO9NCbEeG8oDo5/Efg+6Y859PA63cf\nT3t5cb0Sg06eam26V7yQCm5TTBW9/Al3PLLuzPcsC8KSjeYcXD6bZcSArfb0ATPW5haJSFzJIqCl\ndO67kNRaFpBWE4tXXqwwjG3QH0weMDMagd0Sg5fCIfkfhVLC3Wxvy4JhSlEsLriTF3c66vahQExi\nu+PijtKyoK9AQgrw6Dmdjgt5caMBybIaDgD5mOZ5tvc8oDo5/CViktwk+JbthEIQ7Wk8+9LkQI9G\nUGtbyhaBc0V3MlJHMaXiljmRCBFua3zz9uRYdLtiA1ZFxQ5wpqBjuFDHOEZzSlQphSh087xkTC4a\nNjchUVIXi5Wcu3nWjmJKBY9LZzLAkNrWZKm1UAmpaSmBGLbj5uyJbUM3qiYWj10qM4xPLxpsG/KK\nxBIgCiiv86zngXnvOYyAtwFfAT6BMPfzhPRQ57k7kwO9tSWOwquqBC5rOg0XSiHbVqeYAkgMdJ69\nPZmHSgkpwIWyRs2FvFjFVL5xxLs6X781mYdtC8WUqlicL+mufHScqXwqeEQiISIdd7FQpZgCoaZz\nI6lVpZgCyGYihLoFnr87eVaZbUNKUxeL1bzOusd51vOAPHtSf/giwvW1BXw/8EfAI8c98cknn9z7\n+tq1a1y7dg0QJ0BvTjHfU2U05+DqGZ3myF37oH1WHY8s0w3nLEudSghEv3/7K+5i0bqqjkdqpE81\nnLMsSCtSCYGYIbD5nLtYqFJMAST7Os/dNfnOV1+eyCFZViMQAKEs/K9TCheHx9ZAXSziXZ1v3DZ5\n7OLJr29ZEC/KdxBwcK6k8cX1Lyh57evXr3P9+nUprzXv5DAu9v1T4MNACTjSDxhPDuMoJaf371QZ\nzTl45UXN1Qao7Pm8h1GITzecU2U05+AV53V2XGyAqvKYcrAUnW44Z9u7bSVFsbh6VqPpYgN0TzGl\niEc2PP3siW1DvKCurXRlVXMlL7ZqAzb7NuWUvJkr40ij7cpIHz/xObYNUUViCRCnpDe/pubOYbxw\nBnjqqad8v9a820rL7O85vGn3a/eTyBF2wPenHIm3bUgokk0CPHJWTKVrtSaferTsEQ1FiikQJ4On\nGRE6bpOqODx2UZwAndLWxaoN2OrLHbw0jnJy+gaoo5hSFYvHL+r0YtOH7ZiNJkMGUgcvjaMY16dK\nalUZzTl45QWdtguDSmu7Rj6+RCwSU8JjKarz4pROgzOQS1UsHj3rfeb7PKA6Ofwe8DngUeAO8OPA\nT+0+AH4YIXP9MvBB4Ee9/oGzBR1zSl/XsiCscBFIxhKEBmm+eWuyV7xZbxIKQSaWUcLjTF6f6ikk\nRnMqTFA5MWDmzv3JA2bMbZulhNzBS+NYzk6XF1sWjBQuApeXxYCZemOy1NpqiRaGbEsVB3pm+vQx\noZhSF4tXnNMZJg06Ey6LwQAaA4PlrBoOABUXm8HCY0phLC4Ir6kH3UFDdXL4h8AZII7YW/hN4Jnd\nB8CvA68CXofYmP4br3/gsjb91KMwmlPXxwRI9EQvcyKPtvzpa+O4UNapdabHYqRINgliwEysq/H1\nF0/mMRxCQ/Is78M4V9SnmjLaNgwVySYB4pE44UF2YtHQbguzu+WculisLukYzemxUOEx5aCYzkO0\nw6277ROfU6/v7gEpTA4rOZ21KVJr4TGl7ro4X65AysIwp5/Pmifm3VYKjCur2tQBM7YNfcnzeQ8j\nE9Im+ui027umZll1HC4va2wNpsdClWzSQWqo89zdk3kIHbnaCvGSplGfoiBTrZgCSPQ1vjFhI9ZR\nTKnkcLGssTHFX0kopuQ7sjpwioZJsvO9gVwKY3GuqE0d32rb0EKhki4SJzLI8Y1b01T+88WpTw6v\nvKDTiU7u61qW0E6rrFQLUZ2XJmwGq5ZNwu5m8JQBM5alxm1yHLnI5M1gy4LMstoEdfXs9AEzlqVO\nNukgG9InbgYLxZRaDldWpxtUqprKN470SOf5CUWDbe8qphRyuLw83aDSsoS9jEoeyYHON6dI8OeN\nU58cLlZ0yBhMOiQttNNq2xiVtM7dCUNVbFutbBKEpHaQNNnZOfk5KubzHkY5qXNngoLMtnfn8yoS\nCIBIlN2oOXFjXCim1MZCbAZPjkVcwazicTx6TqcdmdzjNq0Rm31LacJeik6WnVuWmGuhMhaPnNVp\nTjGoNDc6dIc70gcvjSMb0lzPOZ8XTn1yKKVKjBKb3L578oAZ24YtBfN5x7GSmzxgRiwCajnoGQ2y\nBtXqyauAZQ/ZHFhU0hWFPCZvBqtWTIGYWxzKGkwSppgbbXqjNvlEXhmPSkqjOmEDdE82qfC6uKxr\njNIGm5snP8fcqpOKpolH4sp4lJKTZ77bNoSzamPx/7d37sGRXfWd/7Ra3VL3lUav7qt5aR4Zz4AN\nCzupiQ0pdpgNxGBI2UXiinFMsUAWT5FlyYMk4EDC8EeqWMgulYQlcRFMbBxjgyEOVEyeFRkqG1iM\nh8m8/JqxPaOZ2+qWNHp169FSd/44faWr7tsazYzuOcfy71OlmqvbPepv/e7t8zvnd37399u7NctC\nW575+ebvGSkV6G1f/8ZLQXqSLi+tsZWtKV72zqEl1kJyoZfTLzWvFX8xP8MC85EOAjv6XEZXiWXm\ncpCMeEBMJVK0VBM8d655rfiLly7hJDoiHQS29WRXzSDL5WqVNyOcpfameqkmpzg31LzBjDdRoC+1\n/o2XgmzpWr2VbS4XbfYYoAbbdGHVScPwVLQaQPWWyK0yacjlos0eA/V0cqwjj+eFv16pwOhsns0R\nJggAZB13TQUqTfKydw4AaVavj+5NFsimossSgtqDLavUzc/loiu6FyRVcXnmfLiOahWGp6LXsOsy\nGWS5HMQiKrrn0xJroW2xj9PnwicNi4twab7A5gg3xQF29rmMzTa3hedFmz0G/qShjefOhS8dpqdV\nwkbUA+L2y5QTyeVgsS1aW3S3d0OiyIvnw5cOfm+NKJMlQK1s11Ks0yQbwjl0tTavFT8/D1PV6G/8\nfbUHW5rFdT0vukJzQTpbXM402QyenFSloaO2xd4tq28Gex6UI8wj93Fo3mAmn4eO/mgzpkBNGlbb\nDM7lYC7Cels+qYrLM00mULkcdG/VM2mYKK/uKKPoyhdETRoyPHM+fNLgearoXtS22NHncmmNLY5N\nsSGcQyblMtTkaVh140cbwgAY6FUx7mYb456nBoEo46kAvW1ZzjV5GtbzoGtr9Bp+arOK6zbbGPcH\ngah1dCWyvNAkg8zzao3sI74v9m5TTZiabYx7Xi1tMmIdm+JZzuaa26KjP/rrsXerajy02gQqyvIy\nPk4sy3NNJg2eB+mI02kBrtviMrnGxkOm2BDOYXOni9ekyqHnRZ9CCmoTNtaR58KF8Nc9T3Wi06Hj\nQpOnYf1BIGoN/R0uLZtWt0WUdZV8Vnsa1vNUva0oM6ZAtels6Wy+MX7RqzIRcbIEqN4SzZrteF70\nKaSgMgtX2xi/mCszszgVSeOlID0JlxdXmUBFvTcIagJVThRWfWLcNBvCOQz0uoyUwperuRykImzc\n4dOXVrXiXzwXPkX0clUmFqIrbOazrbt546FcLrr+vEFcx6WaKnD+fPjrXn6e2cVoGi8F2bqp+dOw\nuVz0aZNQmzQ4zW1xcWSKtngbqUQqUh39nS4XmjQeyuUgvil6W/R3uLR0rnJfTI7Qm4qm50qQrOMy\n1CRrSiUIRG+LLZ0u8VUmUDawIZzDqwayjM6FL909T6VNRj0za21ppY0ujj4dHle6ODpBe2s77a3t\nkerYtz1Lvhi+dPe8WmvOiG3hJBxisSrHTjc2mKlWwZsYoS+diXwQ2LMl2zSl1vNUllDUzrov1cdi\n8hInTzemWi8swKX5vEpBjpjdbrZpUUbPg2o6eltk0yql9vTpxptzehoW26KtIOCzM5NddRVVSUVv\nCz/S8PTTkX7MNbEhnMPOPpdkd54XXmh8zfOAiFMFfXqSLkefbbzp5uZULDXqzU+APf3qocCwVD1/\nEIjaFrFYjE3xLD8+3WiLiQm/Emr0g8DebeqJ8fGQ0ka6EgTiLXFSsR6ePNnYYCafrzVe0nBfvGq7\ny3g5z2xIaSPPi7auko+TdGiJxTh6snHS4HnQM6Dne7pvu0t+uvlkMsp2qT69qV4WWyc4drz581mm\n2RDOwXVc2nrznDzZ+JqO9DifzZ1uaJvO4WHojrDJTxDXcUlnCk1tEWVBsSBZx+Xki422yOX02WJz\nh0tHf3NbzLXq0dHX7nL8bKMtPE9PlhCovQ/HLYTOVHM5mIm4jIhPdyJ8ApXLQWe/HlsM9Li09xU4\nc6bxtVwu2sZLPvGWOE68h6PPrN6VziQbwjlknSw4BU6caHzN81QtoaiXiQA7MqrZTqWu2OJSlpAG\nDVknS8umfFNbRNk/OshAr6opVB/e0pUgACqMkegOnzT4CQJRh9hA5bSHFSL0vOgLzflk01na+5rf\nF1OV6IruBenvzHI6pPie50EqwiZUQbLpLI7b3BYTZV06XE6ctTdjaUM4B9dxmYs3v9jTGrKEALZ1\nuaQyeV58sVGDjswYULYoJ5vbYnJRjy2292SppPIMDzdq0DUIuI7qIdDMFuNlPbYY6FU9xuuzdHI5\nSPbo0eA6KtwYZouLuUWmFi5F1ngpyECvy8XJxvCWvzeoyxbxJhOoiyNFqlQia7wUZHuPeibpco2x\nTLEhnENXWxdlZvj3U415YV6uynhZz6zIdVwyOxpXMGoQ0LNkzqQzlKqjHD/RWCveG15gemEishaM\nQVzHxd0dbotWDZkxvoaZlkYN1Sp4o0VaWmI4yWgaLwXp71C2qF/BqAQBfbaYb220RbkMl2ZH6W6P\nrvFSkM2dLpmdeZ55ZuX5XA6IuOeKj+u4LLQ12kJtiqt+ElFWU/DZvCnLps0Fzp6N/KOuig3hHGKx\nGFlHVTksB0rpVCowfGma1pa4lkHAdVyc/sYwhudBPMIWjEGS8SQdyQ5OnR1fEd6am4OpxVF62nuI\nt8Qj1+E6Lpu2hNtCV4LAprZNLFTnOH565dN4ExOQ6NKjAZQteraH2yLK7mtBMukM04ujnDi5ctKQ\nz+vbA4LlCVSYLRY1PDXva5iuhl+Pvh0a74u0i7s7fAVjAxvCOYA/O8vz3HPL55aah2iIsYOK97d2\nNV5sPzNGlw63Q8VUz51bPpfLQd+ARluks7T1hNtioU2PDn/SUE4WVjyE5nnQu0NPaAuULVKZcFvM\na3hqHiART9DZ1snw5BhTgbqMngc92/XaoqM/3BazcT06OpIdLFbLnDlXWvEQmq4KAj6u49K1NXxP\nzAY2jHNwHZeBV6+86XI56N2ud4a4GBLjVllCenXsvKHRFt3b9GqohsS4czmYjbh+Tr2O3a9ttIWu\nTXFfQ0tnuC2ibjZUr2P3a/OcOrVSg46n5oMaEt3httC1NxiLxXAdl+37Cjz77EoN6aw+W2SdLO19\n4Yk0NhC1c7gPGAaOr/KePwGeA44B+6/2g1zHJbtrpaFVZozeJXMJdcMtBNKXVf0cvTo272m0hePq\n1TAXV+GDYMaSShDQq2Pr3hBbZPVqWEg2DgIqQUCvjoFXN9qiPeJmQ/UaKu3hthiPuK94vY6dNzTa\nQtfeoK+B9Cs3rPQV4O2rvP4O4DpgL3A38GdX+0HZdJaurXl+8IPlc54HqazeJXOhlGfnTjh6dKWO\niQW9OnoHGm3R3qd3yTw6m6e7mxUzVc/znwrWNzvL7mq0RaJH4/VwsoyX8ywssJTJVq2Cl6twaS7a\nxkv1OjbvabRFa5deW0xX84yM1DahUZviY1MzzFfmIu25Uq9j275GW7R06v2OzMTzvPTSysmkLUTt\nHL4PrNZF+1bg/trxD4FuoP9qPkhtdOV56il46SV1TlcRLZ+eVA9T81O8+1fK3HefOlepwHC+wqW5\nUW2DgOu4bL0uzxNPLH8B/dIZOgflQqnAr9xVXbLF7CxMzc5QrszTmezUosNNu+y6Ic/jj8Ol2p3o\neRCLuKnMCg2OS76Y56674MtfVufGxyHZdYnOZCeJeEKPjrTLvv15vvlNlZkDtafmdduilOeOO+Ar\nX1Hnhoehb0BlFOrIEvJ1vPamPA89xFJaredBRcNT8z7ZdJaRGVXJuTX6RLErxvSewzYgWIZrCNh+\nNX/IdVzG5tUX8C/+ovbHhiCmKT0OVK34TDrDrXeO8Mgj6gs4PAwd2TG62rv0DQKOy+RigV/6peUv\n4NAQVCNusBOkvbWdtngb737vJA88oL6AFy5AZofSoHMQKMUKvOMd8MAD6tzQEFQibrATpLu9m2K5\nyPv/+zz33admiefPL9tCF67jUk4UOHgQHn5YnRsa0lM6wyebzlIoFvjgB6t86Utq8jQ0BD0aM6ZA\nOcqYU2D/fvjWt9S5oSF9FQRAXY9CsUBCz7Bwxdjgr+pHidBq70eOHFk6PnToEIcOHVrxun/T/fbd\ncPPN8Ja3wCOPwE2fzZNN//Q6S25ONp0l3pnn4MEtPPggfOc7cPO78hzTtFT1NXyv+D1+5zDccQcc\nOAB/+7fw+jfpWzJDLbXXzbN/fxcPP6wG57fcmue0xkEg62Q5PXKaw4fh134N9uyBJ56AfW/Vl7nl\nTxqyOwvs3r2NRx+FP/1TOHhLnrOaNICyxanCKQ4fhj/4A+juVuHP7b8QfbVgn7ZWVYF273+aoLu7\nm7/5G/jDP4Q3vivPRc22yBfz3H23uhaLi3DmDHQl9d0X3e3dlMol5hbmaGttW5e/OTg4yODg4Lr8\nLdMrhwvAQOD37bVzDRw5cmTpp94xwPLS/TWvgd274Z3vhAcf1FNEK0zH4cPwkY+om+6Dv2FGw4ED\nagD4xV+Eb3wDiujV4X8BDx+Gu++GTZvgjl/V76DyxTwHD6pr8Z73wGOP6XtSvF7H4cPw3vfCjh3w\nzl82o+Hmm6FQgMOH1eTlkqYnxYM6CiVlizvugNe9Dt78TgO2KOW57TZ49ln46Efh8cdV/2hdOvxU\n60KTdgNXw6FDh1aMldeCaefwbeC9teM3AOOo7KYrxr/xAT7zGfjqV+Ftb4N80dwX8JOfVIPy2JwZ\nDbEYfO5zKoRw8KA5W9x6K3ziE/DQQzA6Y84Wn/+8uh433WTOFrffru6Lv/xLGJnRU1KlXkM8Dn/8\nxyqcsn+/OVvcdRf8/u/DvfdCoWjGFomEWjk89hhcf32VQklPNQUfP+JhI1GHlb4GvBnIoPYWPgX4\nEbZ7gcdRGUvPA0Xg/Vf7QWo2ooz8pjctny8U9cd1C6UC8bhaupvUACq85qNdR1rpSCTgU58ypCFg\ni1tuUeeq1SojpRHtK5hCqUAqZcd9cdtt6tz84jzF+SLd7d16dRQLdOxQzgGgUDJgi9qgfPvt6tzE\n7KSWxkv1OvxJrW1E7RzuXMN7PrweH+QkHarVKsX54lKpjEq1QqFU0JYlBGomUH+x80W9oZTeVC/j\ns+MsVBaW6uXMLcxRLOsdBPywUhDdtvCvR7VaXdoEn5hTjZfWK857JTqC5It5rs9eb1TDSGmEvnT0\n3dcupyNfzPPqzKuNa9C13+Bjs3MwHVZaV+oNPT47jpNwtA4CYRdb97I93hKnp72H0dJyrXh/uawr\nSwia2KKk1xaqwUwL0/PTyxo0Xw+wwxa9qV4mZicoLy4XILPGFpp1+BOXauAJTRO2UM9G2RlW2nDO\nIWho3cv2MA2gf8kcpsMaW1igw5iGollbxFvi9KX7GJ0JTBosuB6g/zuSTqRJxBMrJg2mvqeyctBA\nfRjDxDKxaSjFsA4jGixZutfr0B3aWtJQMhtiW9Jhgy0MhxvDdJjQIM5BE/WGfqUumcN02KDBFh02\naLBFhw0aqtWqFTqMhJVCJpO2sLGcQ3rl0r1QKmhNj4Mm4QMTy1ULbVGt6k8VDNNhLMwX0LBQWWBi\nboLeVK9RHTYMysVykZZYi5aeK/U6rAg3yp5D9NgQSulMdjK3OMdMWTWYKS+WmZjVPwjYYItMOsPo\nzCiVqmowMz0/TTymp/FSEBvCB/XXY7Skr/HSCh11tjDhrOsf/DJxPSDkvihJWCnIhnIO/lOPPiZm\nRX6teP/mN5EqCHYsmRPxBJ3JTsZmxpY06HZQYIctOpOdLFQWKM4XjWkAO2yRSWcYmxljsbJoTAPY\nYQtxDpqw4WLX6zCqwbCjXNIhtmiYNNhwPUzpaG1ppauta8Wk4ZVqCyfh8Ec//0dLq2ub2HDOeNCH\nPAAADENJREFUwXRsuV6HDRps0WGDBlt0GNVQssQWNR0mYv31GkzpiMVifOhnPqQ9srAW7FN0DdgQ\nW67XYYMGozocC2xhwf5LvQ6xhV22qFQrjM7o67nycmBjOYfaRpf/1KMNy1UbNBjVkbbLFpVqhbGZ\nMSODgG33xUx5hvJiWVvjpWY6bLDF2MyY1sZLLwc2lHNob22nvbWdyblJFiuLjM+O05fu067DhiWz\nXyveL6xWqVboSHZo12GDLbLpLCOlEarVKmMzY3S1dS3VnNKJX4gQ7Ail+CElnSVVlnSkLQmxFc1e\nD5vZUM4BlsMpozOjxgYBG8JKsViMTDpDoVgwUlfJZ0X4wECqICw3mBmfHTcWRoEQWxjQ0dXWxUx5\nhtmFWXtsYUhHJp2hUCpQqVaM2sJWNpxz8JeKppaqQQ2gv7hamA5rbGGBDhs0gDlbLDWYKRZe8bZI\nxpN0JDuWJg2ycliJDW1C1xV/2Ty/OG/0xjcdPgjqKC+WjWsAO2xhgwYQW4SFt4zpqK2udVcQsJ0N\n5xz8kM7cwtwreskc1FFeLBvTYMMMEZbvC1NhvqAGMBduDOqwQUO1WqVQ1P+Udr0OCSs1suGcgz8Y\nzS3MGZsJBG98o0v3WqZQebFs3BYmGi8FsSmsNLcwR6lc0tp4KUyHDbYYnx0nlUhp7bkSpiNfzHND\n9gYjGmxF9hwiwEk6xGNxRkojzC7M0tXWZUSHDbbwG8yMlEa0N14KYoMt/JVcoVQg65hJEICALV7h\n+2E26bCRDekcCqWC0Timr+NU4ZSxVEFfw1I81ZAt/AYzpwunjV8P07ZIJ9Ik40nOjJ2xwxYG9xx6\nUj1MzU9xceqieVtYMF7YiA7n8HbgaeA54GMhrx8CJoCjtZ9PXsuH+bMz0zHErJPlRP6EcQ35kgW2\nSFtgi3TAFobi276OE/kTxjWYtkVLrIW+VB+nCqfM28Lw/outRL3nEAe+ALwVuAD8CPg2cLrufU8A\nt67HB67YczA8IzlZOGlcw9Keg9jCivCB2GKlDhts8f1z3zduCxuJeuVwI/A88CJQBh4Gbgt537rF\nXWwIH4DaDLbhxrfCFv4gYDBV0DpbWOAc/L0PkzpssIU37TE5N6m954rtRO0ctgHnA78P1c4FqQI/\nCxwDHgeuKWWgL6UaqOemc2aXq44d4YPh4rDxJbMVYSUny4WpC0zOTdKT6jGnw4awkpPl7KWzxGNx\n0om0UR022OJU4ZSRxku2E3VYqbqG9zwFDAAl4BbgMWBf/ZuOHDmydHzo0CEOHToU+scS8QSb2jYx\nMTthdBBwHZexmTGjs6KOZAeVaoVkPEkqkTKmwwZbZNIZxmfH6Xf6jZZHtsEWvobd3buNaQC1urbF\nFq/JvsaYhvVkcHCQwcHBdflbUTuHC6iB32cAtXoIMhU4/i7wRaAXGAu+KegcLofruCTjSeODQPBf\nE/gNZkzUlwpigy1aW1rpS/UZjyvbYAsn4ZBqTYktUJGGGDHjtlgv6ifOn/70p6/6b0U9ajwJ7AV2\nAReBO4A7697TD+RRq4wbUfsPY1wDvnMwiQ03vv/54hyWddigIfivCfxJg9hCpVpn0hnjtrCRqEeN\nBeDDwN+jMpe+jMpUOlx7/V7gduBDtfeWgHdf64dm01kSLWbrsvtxVNPpcdl01rhz8PcajNvCyRov\nkbBkCwt02HA9gv+a1GHaFjaiY9T4bu0nyL2B4/9b+1k3ZOWwUodp52CTLUwXV7PKFhZoAIx3X7PB\nFjay4WorgR3OIetkiREzPiuyxTnEiBlpvLRCR9r8IOA6LqnWFE7CMa7DBlv0pfqsuD9N28JGzNR1\nuHKqfuvPtZCbzlFeLDPQNXD5N0fIkxef5MDWA0Y1XJi8QCwWY2vnVqM6bLDFuYlztMXb6O/oN6ah\nWq3yY+/Hxm3xwqUX2NS2yajDtsUWz489TyadMVYIMUpqpXuuapzfkM5BEARBuDbnsOEK7wmCIAjX\njjgHQRAEoQFxDoIgCEID4hwEQRCEBsQ5CIIgCA2IcxAEQRAaEOcgCIIgNCDOQRAEQWhAnIMgCILQ\ngDgHQRAEoQFxDoIgCEID4hwEQRCEBsQ5CIIgCA2IcxAEQRAaEOcgCIIgNBC1c3g78DTwHPCxJu/5\nk9rrx4D9EesRBEEQ1kCUziEOfAHlIG4A7gSur3vPO4DrgL3A3cCfRahnXRkcHDQtoQEbNYGdukTT\n2hBNa8dWXVdLlM7hRuB54EWgDDwM3Fb3nluB+2vHPwS6AXM9HK8AG28EGzWBnbpE09oQTWvHVl1X\nS5TOYRtwPvD7UO3c5d6zPUJNgiAIwhqI0jmstelzfX9TaRYtCIJgmKtqPL1G3gAcQe05ANwDVID/\nFXjPnwODqJATqM3rNwPDdX/reWBPRDoFQRA2KmdQ+7pW0YoStgtIAj8hfEP68drxG4Af6BInCIIg\nmOMW4BnUzP+e2rnDtR+fL9RePwb8tFZ1giAIgiAIgiBsHNbyIF3UDAD/ApwETgAfqZ3vBf4ReBb4\nB1Qqrm7iwFHgO5Zo6gYeBU4Dp4CbLNB0D+raHQceAtoMaLoPtZd2PHBuNQ33oO75p4GbNev6HOr6\nHQO+BXRp1hWmyeejqL3LXks0/U+UrU6wcj/VlKYbgf+PGhN+BPyMZk3aiKNCTruABOH7FjrYDPzn\n2nEHKlR2PfBZ4Hdr5z8GfEa/NH4L+Cvg27XfTWu6H/hA7bgVNbCY1LQLOItyCACPAP/NgKb/gqoA\nEPwiN9NwA+peT6D0P090mYVhun4+8HmfMaArTBOoSdrfAS+w7BxMavqvKOeeqP2etUDTIPC22vEt\nqEmtTk3aeCPqZvD5eO3HNI8Bb0V5YP+hvc2133WyHfgn1E3qrxxMaupCDcT1mNTUi3LmPShn9R3U\n4GdC0y5WfpGbabiHlavkv0MlbOjSFeRdwIO1Y526wjR9A3gdK52DSU1fB34u5H0mNX0N+OXa8Z1c\nw7Wz3XOs5UE63exCeesfor7YftrtMPqf7v488DuoZbaPSU27gQLwFeAp4EuAY1jTGPC/gXPARWAc\nNdszfe1YRcNW1L3uY/K+/wDLGYUmdd1W+7x/rztvUtNe4CAqy3IQOGCBpo+zfL9/juVEoCvWZLtz\nsO2BuA7gm8CvA1N1r1XRq/cXgDwqttjseRXdmlpRGWdfrP1bpHGlp1vTHuA3UE59K+oavsewpjAu\np8GEvk8A86h9mmbo0JUGfg/4VODcas9o6bJVK2pF+gbUJO3rq7xXl6Yvo/ZEdwC/idqXaMaqmmx3\nDhdQcUafAVZ6P50kUI7hq6iwEqjZ3uba8RbUYK2Ln0XVpnoBtZT8uZo2k5qGaj8/qv3+KMpJ5Axq\nOgD8P2AUWEBtsL7RsCafZteq/r7fXjunk/ehnkO6K3DOlK49KOd+DHW/bwd+jFppmbTVEOp+AnXP\nV4CMYU03An9dO3609juGNUXCWh6k00EMeAAVxgnyWZbjeB/HzIY0qKfK/T0H05q+B+yrHR+p6TGp\n6fWoTJIU6jreD/wPQ5p20bghHabB3zxMokJ1Z4i2mkG9rrejsrsyde/TqateU5CwDWkTmg4Dn64d\n70OFckxrego1HgC8heWJmu57SgthD9Lp5k2oWcFPUGGco6gvUC9qQ9hkKiuom8HPVjKt6fWoGzKY\nBmla0++ynMp6P2oVqFvT11B7HvOofbT3X0bD76Hu+adZzj7RoesDqHTHl1i+17+oWZevaY5lWwU5\ny8pUVlOaEqjV+nHUSuaQIU3Be+oAaj/0J8C/sbJHjq57ShAEQRAEQRAEQRAEQRAEQRAEQRAEQRAE\nQRAEQRAEQRAEQVh/uoAP1Y63oIq+CYIgCK9wdtH8CV1BEAThFcrDQAn1hPDXWXYU70PV1voHVBmH\nDwO/jSpb8G+oQmyg6gF9F3gSVVLkVZp0C4IgCBGyk2WHEDx+H6q8hIOqPTQB3F177f+gKvYC/DNw\nXe34ptrvgvCyodW0AEGwlFiTY1DdtYq1n3GWix4eRzWjcVBVc4P7FMloZApCNIhzEIQrZy5wXAn8\nXkF9p1qAS6wseiYILyts7+cgCKaYAjqv8P/4K4wp1H7E7YHzr1snXYKgBXEOghDOKPCvqFDRZ1nu\nmlXfsa3+2P/9LuBXUaWTT6AaMwmCIAiCIAiCIAiCIAiCIAiCIAiCIAiCIAiCIAiCIAiCIAiCIAiC\nIAiCIAjXyn8ACbzP1Qgga2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83a2190a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARBEARBEARBEARBEARBEARB+FX5f84BGbk+xUNeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8386a4b990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tmpPre= [ i[0] for i in predicted  ]\n",
    "tmpY= [ i[0] for i in y_test  ]\n",
    "plt.plot(tmpPre, label = 'pred')\n",
    "plt.plot( tmpY, label = 'true' )\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.legend( loc='upper left',fontsize=12 )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tmpPre= [ i[1] for i in predicted  ]\n",
    "tmpY= [ i[1] for i in y_test  ]\n",
    "plt.plot(tmpPre, label = 'pred')\n",
    "plt.plot( tmpY, label = 'true' )\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.legend( loc='upper left',fontsize=12 )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt = len(predicted)\n",
    "plt.plot(range(0, cnt  ), predicted[:,0])\n",
    "tmpplt= plt.plot(range(0, cnt  ),y_test[:,0])\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# backup code \n",
    "\n",
    "max_lag = mini_batch = 50\n",
    "significance_level = 0.05\n",
    "\n",
    "cur_batch_cnt=0\n",
    "cur_seg_stPos=0\n",
    "cur_seg_cnt=0\n",
    "total_len=len(ts) \n",
    "x=ts\n",
    "\n",
    "# data instances for training RNN\n",
    "xtrain=[]\n",
    "ytrain=[]\n",
    "# detected change-points\n",
    "detect_cp_list=[]\n",
    "\n",
    "\n",
    "ini_flag=1\n",
    "ini_model=1\n",
    "\n",
    "#  residual statistics\n",
    "resi_mean=0.0\n",
    "resi_sqr = 0.0\n",
    "resi_var=0.0\n",
    "\n",
    "\n",
    "# initialize the network structure\n",
    "in_dim = 1\n",
    "hidden_neurons = 100\n",
    "\n",
    "\n",
    "cp_model = Sequential()\n",
    "cp_model.add(LSTM(hidden_neurons, return_sequences=True, stateful= True,\\\n",
    "               batch_input_shape = (1,timesteps,input_dim )   ))\n",
    "cp_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "cp_model.add(Activation(\"linear\"))\n",
    "cp_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "# seg_model = Sequential()\n",
    "# seg_model.add(LSTM(hidden_neurons, input_dim=in_dim, return_sequences=False  ))\n",
    "# seg_model.add(Dense(in_dim, input_dim=hidden_neurons))\n",
    "# seg_model.add(Activation(\"linear\"))\n",
    "# seg_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "for i in range(total_len):\n",
    "    \n",
    "    if ini_flag==0 and ini_model ==0:\n",
    "        \n",
    "        xtest=[ []  ]\n",
    "        for dta in x[i-1-max_lag: i]:\n",
    "            tmplist=[]\n",
    "            tmplist.append(dta  )\n",
    "            xtest[0].append( tmplist ) \n",
    "         \n",
    "        print seg_model.predict( np.array (xtest) )[0][0],  x[i]\n",
    "\n",
    "        tmpresi =  seg_model.predict( np.array(xtest) )[0][0] - x[i]\n",
    "        \n",
    "#       z-value\n",
    "        tmp_zval = (tmpresi -  resi_mean)*1.0 / sqrt(resi_var)\n",
    "        tmp_pro =  st.norm.cdf( tmp_zval)\n",
    "        \n",
    "        print tmp_pro\n",
    "        \n",
    "        if tmp_pro <= significance_level or tmp_pro >= 1.0-significance_level:\n",
    "            #initialize a new segment \n",
    "            cur_seg_stPos =i\n",
    "            cur_seg_cnt = 1\n",
    "            cur_batch_cnt =1\n",
    "            \n",
    "            resi_mean= x[i]\n",
    "            resi_sqr = x[i]*x[i]*1.0\n",
    "            resi_var =  0.0\n",
    "            \n",
    "            detect_cp_list.append(i)\n",
    "            \n",
    "            del xtrain[:]\n",
    "            del ytrain[:]\n",
    "            seg_model.clear_previous(reset_weights=True)\n",
    "            \n",
    "            ini_flag =1\n",
    "            ini_model ==1\n",
    "            \n",
    "        else:\n",
    "            #stay in the current segment and update the residual statistics \n",
    "            resi_mean= ( resi_mean * cur_seg_cnt*1.0 + tmpresi)/cur_seg_cnt\n",
    "            cur_seg_cnt = cur_seg_cnt+1\n",
    "            resi_sqr = resi_sqr + tmpresi*tmpresi\n",
    "            resi_var= resi_sqr/cur_seg_cnt - resi_mean* resi_mean \n",
    "            \n",
    "            cur_batch_cnt =cur_batch_cnt+1\n",
    "        \n",
    "    \n",
    "    if cur_batch_cnt < mini_batch:\n",
    "        \n",
    "        if ini_flag==0:\n",
    "            \n",
    "            xtrain.append( [])\n",
    "            tmpcnt= len(xtrain)\n",
    "            \n",
    "#             print i, max_lag\n",
    "            for dta in x[ i- max_lag: i-1]:\n",
    "                tmplist=[]\n",
    "                tmplist.append(dta)\n",
    "                xtrain[tmpcnt-1].append( tmplist )\n",
    "                \n",
    "            tmplist=[]\n",
    "            tmplist.append(x[i])\n",
    "            ytrain.append( tmplist )\n",
    "            \n",
    "        cur_batch_cnt =cur_batch_cnt+1\n",
    "            \n",
    "    else:\n",
    "        if ini_flag==1:\n",
    "            ini_flag=0\n",
    "            \n",
    "            cur_batch_cnt=0\n",
    "            continue\n",
    "            \n",
    "#         print len(xtrain),len(xtrain[0]), len(ytrain)\n",
    "            \n",
    "            \n",
    "        seg_model.train_on_batch(np.array( xtrain),np.array( ytrain), nb_epoch=10  )\n",
    "        ini_model=0\n",
    "        \n",
    "        cur_batch_cnt=0\n",
    "        del xtrain[:]\n",
    "        del ytrain[:]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# backup code\n",
    "\n",
    "\n",
    "#  tensorFlow\n",
    "\n",
    "# '''\n",
    "# A Reccurent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "# This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "# Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "# Author: Aymeric Damien\n",
    "# Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "# '''\n",
    "\n",
    "# Import MINST data\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import numpy as np\n",
    "\n",
    "# '''\n",
    "# To classify images using a reccurent neural network, we consider every image row as a sequence of pixels.\n",
    "# Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 steps for every sample.\n",
    "# '''\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "# Tensorflow LSTM cell requires 2x n_hidden length (state & cell)\n",
    "istate = tf.placeholder(\"float\", [None, 2*n_hidden])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, n_steps, _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(lstm_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']\n",
    "\n",
    "pred = RNN(x, istate, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_steps, n_input))\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                       istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                                istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                             istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    test_len = 256\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print \"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                                             istate: np.zeros((test_len, 2*n_hidden))})\n",
    "\n",
    "print ts[6426]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-61d5cc106070>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-61d5cc106070>\"\u001b[1;36m, line \u001b[1;32m29\u001b[0m\n\u001b[1;33m    print a\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# backup code\n",
    "\n",
    "#  pybrain\n",
    "\n",
    "# from __future__ import print_function\n",
    "data = [1] * 3 + [2] * 3\n",
    "data *= 3\n",
    "print(data)\n",
    "\n",
    "from pybrain.datasets import SequentialDataSet\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "\n",
    "# flow = (list(range(1,10,1)) + list(range(10,1,-1)))*100\n",
    "# pdata = pd.DataFrame({\"a\":flow, \"b\":flow})\n",
    "# pdata.b = pdata.b.shift(9)\n",
    "# data = pdata.iloc[10:] * random()  # some noise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ds = SequentialDataSet(1, 1)\n",
    "for sample, next_sample in zip(data, cycle(data[1:])):\n",
    "    ds.addSample(sample, next_sample)\n",
    "    \n",
    "print (ds)\n",
    "\n",
    "# from pybrain.tools.shortcuts import buildNetwork\n",
    "# from pybrain.structure.modules import LSTMLayer\n",
    "\n",
    "# net = buildNetwork(1, 5, 1, \n",
    "#                    hiddenclass=LSTMLayer, outputbias=False, recurrent=True)\n",
    "\n",
    "\n",
    "# from pybrain.supervised import RPropMinusTrainer\n",
    "# from sys import stdout\n",
    "\n",
    "# trainer = RPropMinusTrainer(net, dataset=ds)\n",
    "# train_errors = [] # save errors for plotting later\n",
    "# EPOCHS_PER_CYCLE = 5\n",
    "# CYCLES = 100\n",
    "# EPOCHS = EPOCHS_PER_CYCLE * CYCLES\n",
    "# for i in xrange(CYCLES):\n",
    "#     trainer.trainEpochs(EPOCHS_PER_CYCLE)\n",
    "#     train_errors.append(trainer.testOnData())\n",
    "#     epoch = (i+1) * EPOCHS_PER_CYCLE\n",
    "#     print(\"\\r epoch {}/{}\".format(epoch, EPOCHS), end=\"\")\n",
    "#     stdout.flush()\n",
    "\n",
    "# print()\n",
    "# print(\"final error =\", train_errors[-1])\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(range(0, EPOCHS, EPOCHS_PER_CYCLE), train_errors)\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('error')\n",
    "# plt.show()\n",
    "\n",
    "# for sample, target in ds.getSequenceIterator(0):\n",
    "#     print(\"               sample = %4.1f\" % sample)\n",
    "#     print(\"predicted next sample = %4.1f\" % net.activate(sample))\n",
    "#     print(\"   actual next sample = %4.1f\" % target)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# backup code\n",
    "\n",
    "# keras\n",
    "# https://github.com/Vict0rSch/deep_learning/tree/master/keras\n",
    "# https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "def data_power_consumption(path_to_dataset,\n",
    "                           sequence_length=50,\n",
    "                           ratio=1.0):\n",
    "\n",
    "    max_values = ratio * 2049280\n",
    "\n",
    "    with open(path_to_dataset) as f:\n",
    "        data = csv.reader(f, delimiter=\";\")\n",
    "        power = []\n",
    "        nb_of_values = 0\n",
    "        for line in data:\n",
    "            try:\n",
    "                power.append(float(line[2]))\n",
    "                nb_of_values += 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "            # 2049280.0 is the total number of valid values, i.e. ratio = 1.0\n",
    "            if nb_of_values >= max_values:\n",
    "                break\n",
    "\n",
    "    print \"Data loaded from csv. Formatting...\"\n",
    "\n",
    "    result = []\n",
    "    for index in range(len(power) - sequence_length):\n",
    "        result.append(power[index: index + sequence_length])\n",
    "    result = np.array(result)  # shape (2049230, 50)\n",
    "\n",
    "    result_mean = result.mean()\n",
    "    result -= result_mean\n",
    "    print \"Shift : \", result_mean\n",
    "    print \"Data  : \", result.shape\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:row, :]\n",
    "    np.random.shuffle(train)\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = result[row:, :-1]\n",
    "    y_test = result[row:, -1]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    layers = [1, 50, 100, 1]\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print \"Compilation Time : \", time.time() - start\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_network(model=None, data=None):\n",
    "    global_start_time = time.time()\n",
    "    epochs = 1\n",
    "    ratio = 0.5\n",
    "    sequence_length = 50\n",
    "    path_to_dataset = 'household_power_consumption.txt'\n",
    "\n",
    "    if data is None:\n",
    "        print 'Loading data... '\n",
    "        X_train, y_train, X_test, y_test = data_power_consumption(\n",
    "            path_to_dataset, sequence_length, ratio)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = data\n",
    "\n",
    "    print '\\nData Loaded. Compiling...\\n'\n",
    "\n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "\n",
    "    try:\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=512, nb_epoch=epochs, validation_split=0.05)\n",
    "        predicted = model.predict(X_test)\n",
    "        predicted = np.reshape(predicted, (predicted.size,))\n",
    "    except KeyboardInterrupt:\n",
    "        print 'Training duration (s) : ', time.time() - global_start_time\n",
    "        return model, y_test, 0\n",
    "\n",
    "    try:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(y_test[:100, 0])\n",
    "        plt.plot(predicted[:100, 0])\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print str(e)\n",
    "    print 'Training duration (s) : ', time.time() - global_start_time\n",
    "    \n",
    "    return model, y_test, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# block3: real-time rnn training on keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "\n",
    "# parameters\n",
    "timesteps =1\n",
    "input_dim=1\n",
    "\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 500\n",
    "trn_size= dtax.shape[1]-10\n",
    "\n",
    "trnx = dtax\n",
    "trny = dtay\n",
    "print trnx.shape, trny.shape\n",
    "\n",
    "rl_model = Sequential()\n",
    "# model.add(LSTM(hidden_neurons,input_shape=trnx.shape[1:],return_sequences=True  ))\n",
    "\n",
    "rl_model.add(LSTM(hidden_neurons, return_sequences=True, stateful= True,\\\n",
    "               batch_input_shape = (1,timesteps,input_dim )   ))\n",
    "\n",
    "rl_model.add(TimeDistributedDense(output_dim=1 ) )\n",
    "# rl_model.add(Dense(  1 , input_dim = hidden_neurons))\n",
    "rl_model.add(Activation(\"linear\"))\n",
    "rl_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "for i in range(trn_size):\n",
    "    cur_trnx= trnx[:,i:i+1,:]\n",
    "    cur_trny= trny[:,i:i+1,:]\n",
    "#     print 'data instance:', i, 'of size:', cur_trnx.shape, cur_trny.shape\n",
    "    rl_model.train_on_batch(cur_trnx,cur_trny) \n",
    "     \n",
    "    if i%500 ==0:\n",
    "        vali_testx=  trnx[:, i+1:i+2,:]\n",
    "        print \"at time step:\",i,\":\", rl_model.predict_on_batch( vali_testx )\n",
    "    \n",
    "    if i == trn_size-1:\n",
    "        vali_testx=  trnx[:, i+1:i+2,:]\n",
    "        print \"at time step:\",i,\":\", rl_model.predict_on_batch( vali_testx )\n",
    "#     rl_model.fit(cur_trnx, cur_trny, batch_size=1, nb_epoch=10) \n",
    "#     validation_split=0.05)\n",
    "\n",
    "\n",
    "\n",
    "# predicted = model.predict(X_test)\n",
    "# rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "\n",
    "# model.predict( X_test[0:10] )\n",
    "\n",
    "# and maybe plot it\n",
    "# pd.DataFrame(predicted).to_csv(\"predicted.csv\")\n",
    "# pd.DataFrame(y_test).to_csv(\"test_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  build online-rnn learning framework\n",
    "\n",
    "\n",
    "#  state-full lstm \n",
    "#  https://github.com/fchollet/keras/blob/master/examples/stateful_lstm.py\n",
    "\n",
    "# Q&A:\n",
    "#  stateful lstm\n",
    "#  variational\n",
    "#  time steps: maximum time lag?\n",
    "#  if residula is not white gaussian \n",
    "\n",
    "#  septerate modeling on conditions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
